{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import bitsandbytes as bnb\n",
    "from bitsandbytes.nn import Linear4bit\n",
    "import bitsandbytes as bnb\n",
    "import tqdm\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig,PeftConfig, PeftModel, PeftModelForCausalLM\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "import safetensors\n",
    "import torch.nn as nn\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "safetensor_path = \"/scratch/tathagato/redo_adapter_experiments/length/length/adapter_model.safetensors\"\n",
    "adapter_path = \"/scratch/tathagato/redo_adapter_experiments/length/length/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor name: base_model.model.model.layers.0.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0347, -0.0062,  0.0624, -0.0074,  0.0427])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 5.5706e-04, -8.3941e-04, -1.4668e-05,  2.8237e-03, -1.2521e-03])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0120,  0.0225, -0.0087,  0.0140,  0.0249])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0048, -0.0169, -0.0033, -0.0135,  0.0060])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0306,  0.0323,  0.0319,  0.0392, -0.0165])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0311,  0.0010, -0.0095,  0.0151,  0.0016])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0085, -0.0181,  0.0189, -0.0115, -0.0376])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([0.0001, 0.0049, 0.0086, 0.0016, 0.0013])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0069,  0.0350, -0.0145, -0.0309, -0.0271])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0369, -0.0178,  0.0330, -0.0261,  0.0270])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0132,  0.0083, -0.0204,  0.0225, -0.0409])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0102, -0.0092,  0.0066, -0.0043,  0.0094])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0024, -0.0491, -0.0247, -0.0188, -0.0022])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0016,  0.0137, -0.0175,  0.0018, -0.0182])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0081, -0.0223,  0.0415,  0.0303,  0.0255])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0022, -0.0005,  0.0044,  0.0108, -0.0041])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0006, -0.0055,  0.0302, -0.0132,  0.0027])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0305,  0.0070, -0.0043, -0.0743,  0.0003])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0324,  0.0046, -0.0011, -0.0033, -0.0232])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0008, -0.0319,  0.0275, -0.0141,  0.0071])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0064,  0.0103,  0.0070, -0.0105,  0.0367])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0020,  0.0496,  0.0244,  0.0514, -0.0342])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0044, -0.0417,  0.0572,  0.0161,  0.0012])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0113, -0.0013, -0.0160, -0.0166,  0.0174])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0296, -0.0023, -0.0170, -0.0022,  0.0204])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0300,  0.0918, -0.0384, -0.0553, -0.0068])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0301, -0.0047,  0.0200,  0.0286, -0.0021])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0160, -0.0261,  0.0131, -0.0133,  0.0110])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0201, -0.0264,  0.0460,  0.0199,  0.0507])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0150, -0.0328, -0.0392, -0.0024,  0.0683])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0374, -0.0472, -0.0238,  0.0599,  0.0733])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0076, -0.0045,  0.0054,  0.0020, -0.0089])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0463, -0.0117,  0.0280,  0.0036,  0.0162])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0268, -0.0755, -0.0214, -0.0054, -0.0070])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0219,  0.0077, -0.0058, -0.0088,  0.0038])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0022, -0.0023, -0.0315,  0.0179,  0.0105])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0526, -0.0392, -0.0008,  0.0011,  0.0602])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0010, -0.0059, -0.0547, -0.0264,  0.0030])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0361, -0.0134,  0.0236, -0.0328,  0.0281])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0036,  0.0122, -0.0018, -0.0106, -0.0141])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0220, -0.0540,  0.0436, -0.0150,  0.0119])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0446, -0.0004,  0.0377,  0.0420, -0.0057])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0105,  0.0318, -0.0145, -0.0075, -0.0311])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0237,  0.0227, -0.0039, -0.0146, -0.0227])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0094,  0.0669,  0.0111, -0.0123, -0.0288])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0122,  0.0143, -0.0238, -0.0343, -0.0016])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0264,  0.0211,  0.0243, -0.0101, -0.0144])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0301, -0.0041, -0.0075,  0.0026,  0.0008])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0086,  0.0105, -0.0109, -0.0515, -0.0040])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0750, -0.0158,  0.0477, -0.0153, -0.0293])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0186, -0.0211, -0.0148, -0.0337, -0.0337])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0047, -0.0166, -0.0295,  0.0115, -0.0281])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0002,  0.0239, -0.0086,  0.0490, -0.0361])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0082,  0.0082,  0.0162, -0.0221, -0.0130])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0050,  0.0143, -0.0650, -0.0234,  0.0078])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0263, -0.0050, -0.0330,  0.0228,  0.0205])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0074,  0.0017,  0.0127,  0.0414,  0.0091])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0135, -0.0193, -0.0094, -0.0395,  0.0075])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0182,  0.0392,  0.0322, -0.0454, -0.0569])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0214, -0.0134,  0.0002,  0.0095, -0.0280])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0127,  0.0120,  0.0323, -0.0624, -0.0594])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0487, -0.0701, -0.0069,  0.0116, -0.0699])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0520,  0.0227,  0.0076,  0.0137, -0.0423])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0028,  0.0110, -0.0022, -0.0133,  0.0370])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0735,  0.0320, -0.0156,  0.0135,  0.0038])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0144, -0.0264,  0.0510,  0.0155,  0.0176])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([0.0401, 0.0736, 0.0582, 0.0620, 0.0403])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0113, -0.0170,  0.0019,  0.0091, -0.0006])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0355, -0.0078,  0.0374, -0.0521,  0.0064])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0088,  0.0429,  0.0803, -0.0054, -0.0215])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0242,  0.0985, -0.0056,  0.0673,  0.0404])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0075,  0.0241, -0.0093, -0.0097,  0.0054])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0420, -0.0446, -0.0372, -0.0010,  0.0152])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0437, -0.0084,  0.1078,  0.1051, -0.0002])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0604,  0.0090,  0.0244, -0.0110,  0.0505])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0109, -0.0267, -0.0326,  0.0073,  0.0300])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0599, -0.0016,  0.0045,  0.0067,  0.0251])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0316,  0.0206, -0.0123,  0.0440, -0.0562])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0415, -0.0127,  0.0668, -0.0187,  0.0303])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0142,  0.0004, -0.0062, -0.0210, -0.0084])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0531,  0.0470, -0.0142, -0.0026, -0.0025])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0411,  0.0389,  0.0096,  0.0641, -0.0459])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0185, -0.0471, -0.0314, -0.0218, -0.0431])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0007,  0.0133, -0.0196,  0.0221,  0.0409])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0029, -0.0192,  0.0016, -0.0495,  0.0065])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0459,  0.0140, -0.0190,  0.0340,  0.0523])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0484,  0.0414,  0.0215,  0.0216, -0.0425])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0088, -0.0122,  0.0357, -0.0014, -0.0059])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0193, -0.0215,  0.0701,  0.0403,  0.0055])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0073, -0.0110,  0.0299,  0.0346,  0.0283])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0145, -0.0257,  0.0229,  0.0080, -0.0088])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0206, -0.0057,  0.0101, -0.0189,  0.0237])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0431,  0.0108, -0.0342, -0.0304, -0.0458])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0020,  0.0186, -0.0282, -0.0657, -0.0163])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([0.0242, 0.0337, 0.0525, 0.0286, 0.0154])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0290,  0.0067, -0.0313, -0.0076,  0.0020])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0042, -0.0767,  0.0621, -0.0011, -0.0268])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0105,  0.0084, -0.0286, -0.0036, -0.0247])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0040,  0.0046,  0.0189,  0.0262, -0.0044])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0043, -0.0023,  0.0090,  0.0163,  0.0177])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0263,  0.1097, -0.0238, -0.0644, -0.0256])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0224, -0.0125,  0.0033, -0.0107,  0.0359])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0062, -0.0134, -0.0052, -0.0102, -0.0091])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0018, -0.0068,  0.0193, -0.0177, -0.0042])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0366, -0.0325,  0.0150, -0.0029,  0.0190])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0104,  0.0282, -0.0438, -0.0068, -0.0019])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0004,  0.0523, -0.0156, -0.0228, -0.0417])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0032, -0.0068, -0.0126, -0.0515,  0.0149])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0345,  0.0020, -0.0240, -0.0020, -0.0017])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0220, -0.0133, -0.0168, -0.0203, -0.0128])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0016,  0.0086,  0.0105, -0.0408, -0.0118])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0040, -0.0372,  0.0573,  0.0236,  0.0201])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0575, -0.0125, -0.0172, -0.0516,  0.0150])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0999, -0.0729, -0.0467, -0.0107, -0.0949])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0488,  0.0036, -0.0125, -0.0342,  0.0777])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0017,  0.0200, -0.0259, -0.0155,  0.0042])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0265,  0.0551,  0.0344, -0.0634, -0.0227])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0285,  0.0095,  0.0633, -0.0429, -0.0213])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0429,  0.0443,  0.0085,  0.0746, -0.0348])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0064, -0.0251,  0.0273,  0.0559,  0.0155])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0658,  0.0484, -0.0122, -0.0032, -0.0081])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0252, -0.0625, -0.0107,  0.0170,  0.0169])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0092,  0.0184,  0.0146,  0.0084, -0.0295])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0017,  0.0060,  0.0388,  0.0086, -0.0375])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0347,  0.0059, -0.0446, -0.0077, -0.0203])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0031,  0.0177, -0.0019,  0.0226, -0.0081])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0375, -0.0099,  0.0227, -0.0118, -0.0018])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0109,  0.0135,  0.0059, -0.0416,  0.0074])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0172,  0.0017,  0.0260, -0.0150, -0.0066])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0130,  0.0316,  0.0183, -0.0352,  0.0041])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0257, -0.0234,  0.0002, -0.0547,  0.0589])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0065, -0.0058, -0.0095,  0.0197,  0.0432])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0315,  0.0171, -0.0351,  0.0242,  0.0396])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([0.0123, 0.0085, 0.0165, 0.0433, 0.0328])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0041,  0.0364, -0.0346, -0.0269, -0.0109])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0045,  0.0191, -0.0012, -0.0026, -0.0201])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-2.6529e-02, -4.2454e-03,  9.4593e-03, -1.5777e-05, -6.1194e-03])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0528, -0.0427,  0.0344, -0.0169, -0.0245])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0272, -0.0222, -0.0048, -0.0373, -0.0026])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0096, -0.0065,  0.0052,  0.0071,  0.0058])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0274,  0.0535, -0.0122,  0.0056,  0.0065])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0482, -0.0153,  0.0087,  0.0218,  0.0122])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0057, -0.0300,  0.0393, -0.0052,  0.0145])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0119, -0.0075, -0.0029,  0.0066, -0.0068])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0159, -0.0315, -0.0324, -0.0142,  0.0263])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0490,  0.0076, -0.0161, -0.0363, -0.0794])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0159, -0.0083, -0.0162,  0.0666, -0.0222])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0332, -0.0197, -0.0298, -0.0007, -0.0077])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0073,  0.0234,  0.0118, -0.0463, -0.0195])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0460, -0.0186, -0.0008, -0.0123,  0.0201])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0091, -0.0259,  0.0245,  0.0039,  0.0253])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0220, -0.0070, -0.0070, -0.0061,  0.0255])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0019,  0.0329,  0.0337, -0.0080, -0.0004])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0398,  0.0157,  0.0217,  0.0521,  0.0034])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0131, -0.0120, -0.0148, -0.0306,  0.0101])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0106,  0.0212, -0.0135, -0.0027,  0.0178])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0250, -0.0061,  0.0510,  0.0124, -0.0514])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0032, -0.0100,  0.0103, -0.0206,  0.0119])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0017, -0.0742, -0.0303, -0.0129,  0.0128])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0026, -0.0168,  0.0135,  0.0086,  0.0024])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0194, -0.0053,  0.0386, -0.0359, -0.0214])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0104, -0.0238, -0.0121, -0.0519, -0.0062])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0087, -0.0122,  0.0198, -0.0170,  0.0126])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0001, -0.0473, -0.0097,  0.0154,  0.0075])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0047, -0.0337, -0.0238, -0.0796,  0.0163])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0014, -0.0315,  0.0185,  0.0490, -0.0135])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0237,  0.0159,  0.0022, -0.0197, -0.0002])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0275,  0.0102, -0.0046,  0.0130,  0.0004])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.k_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0133, -0.0465, -0.0303,  0.0029,  0.0383])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.k_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0101, -0.0199,  0.0245, -0.0055, -0.0074])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.o_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0092, -0.0174,  0.0158, -0.0061,  0.0081])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.o_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0024, -0.0163,  0.0070, -0.0034, -0.0461])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 0.0334, -0.0263, -0.0284,  0.0481,  0.0577])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "Shape: torch.Size([2048, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-2.1649e-02,  6.8019e-05,  4.2006e-02,  1.6122e-02, -5.8683e-04])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "Shape: torch.Size([16, 2048])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([-0.0421,  0.0620, -0.0199,  0.0351, -0.0256])\n",
      "\n",
      "Tensor name: base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "Shape: torch.Size([256, 16])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Tensor data (first few elements): tensor([ 8.5963e-03,  9.4843e-03,  6.9421e-03, -2.8871e-05, -2.7476e-02])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_tensors = safetensors.torch.load_file(safetensor_path)\n",
    "\n",
    "# Inspect the structure and shape of the tensors\n",
    "for tensor_name, tensor_data in loaded_tensors.items():\n",
    "    print(f\"Tensor name: {tensor_name}\")\n",
    "    print(f\"Shape: {tensor_data.shape}\")\n",
    "    print(f\"Data type: {tensor_data.dtype}\")\n",
    "    print(f\"Device: {tensor_data.device}\")\n",
    "    print(f\"Tensor data (first few elements): {tensor_data.flatten()[:5]}\")  # Print first few elements for inspection\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "base_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "model_kwargs = dict(\n",
    "        use_cache=False,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=None,\n",
    "        cache_dir = \"/scratch/tathagato\",\n",
    "        attn_implementation = \"eager\",\n",
    "        quantization_config = nf4_config, \n",
    "\n",
    "    )\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(base_model, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model,cache_dir = \"/scratch/tathagato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.Size([2097152, 1])\n",
      "cuda:0\n",
      "torch.Size([1, 32, 2048])\n"
     ]
    }
   ],
   "source": [
    "y = model.model.layers[0].self_attn.q_proj\n",
    "#should 2048,2048\n",
    "print(y.weight.device)\n",
    "print(y.weight.shape)\n",
    "#get a random matrix of shape (1,32,2048)\n",
    "x = torch.randn(1,32,2048).to(y.weight.device)\n",
    "print(x.device)\n",
    "z = y(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-21): 22 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
      "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
      ")\n",
      "torch.Size([256, 2048])\n"
     ]
    }
   ],
   "source": [
    "non_quantized_model = AutoModelForCausalLM.from_pretrained(base_model, trust_remote_code=True, use_cache=False, cache_dir = \"/scratch/tathagato\")\n",
    "print(non_quantized_model)\n",
    "print(non_quantized_model.model.layers[0].self_attn.k_proj.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load safetensors from a path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear4bit(in_features=32, out_features=64, bias=False)\n",
      "torch.Size([256, 1]) cuda:0 torch.float32\n",
      "cpu torch.Size([32, 64])\n",
      "cuda:0\n",
      "torch.Size([1024, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Initialize W1_a and move it to the desired device (e.g., GPU)\n",
    "W1_a = torch.nn.Parameter(torch.randn(64, 32) * 1)\n",
    "#W1_a = bnb.nn.Params4bit(data = W1_a, \"nf4\")\n",
    "W1_a = W1_a.to(0)  # Move to GPU (device 0)\n",
    "\n",
    "# Step 2: Determine input and output features\n",
    "input_features = W1_a.shape[1]\n",
    "output_features = W1_a.shape[0]\n",
    "\n",
    "# Step 3: Instantiate the Linear4bit layer without bias\n",
    "linear4bit_layer = bnb.nn.Linear4bit(input_features, output_features, bias=False)\n",
    "\n",
    "# Step 4: Assign the pre-existing weight to the Linear4bit layer's weight\n",
    "# Note: This assignment is done correctly for initialization purposes,\n",
    "# but quantization might affect the internal representation.\n",
    "with torch.no_grad():\n",
    "    linear4bit_layer.weight = bnb.nn.Params4bit(W1_a,requires_grad=True, quant_type=\"nf4\", quant_storage= torch.float)\n",
    "# Step 5: Move the Linear4bit layer to the same device as W1_a (if not already done)\n",
    "# This is already done in Step 3\n",
    "\n",
    "linear4bit_layer = linear4bit_layer.to(0)\n",
    "\n",
    "print(linear4bit_layer)\n",
    "print(linear4bit_layer.weight.shape, linear4bit_layer.weight.device, linear4bit_layer.weight.dtype)\n",
    "\n",
    "\n",
    "# Additional check for another Linear4bit layer\n",
    "x2 = bnb.nn.Linear4bit(64, 32, bias=False)\n",
    "print(x2.weight.device, x2.weight.shape)\n",
    "x2 = bnb.nn.Linear4bit(64, 32, bias=False).to(0)\n",
    "print(x2.weight.device)\n",
    "print(x2.weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0 11.0\n",
      "128.0\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "print(math.log(262144,2), math.log(2048,2))\n",
    "print(2**(math.log(262144,2) - math.log(2048,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adapter_model \u001b[38;5;241m=\u001b[39m PeftModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel\u001b[49m, adapter_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "adapter_model = PeftModelForCausalLM.from_pretrained(model, adapter_path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([262144, 1]) torch.Size([16, 2048]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(adapter_model.base_model.model.model.layers[0].self_attn.k_proj.base_layer.weight.shape,adapter_model.base_model.model.model.layers[0].self_attn.k_proj.lora_A.test.weight.shape,adapter_model.base_model.model.model.layers[0].self_attn.k_proj.lora_A.test.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lora.Linear4bit(\n",
       "  (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (test): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict(\n",
       "    (test): Linear(in_features=2048, out_features=16, bias=False)\n",
       "  )\n",
       "  (lora_B): ModuleDict(\n",
       "    (test): Linear(in_features=16, out_features=256, bias=False)\n",
       "  )\n",
       "  (lora_embedding_A): ParameterDict()\n",
       "  (lora_embedding_B): ParameterDict()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].self_attn.k_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lora.Linear4bit(\n",
       "  (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (test): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict(\n",
       "    (test): Linear(in_features=2048, out_features=16, bias=False)\n",
       "  )\n",
       "  (lora_B): ModuleDict(\n",
       "    (test): Linear(in_features=16, out_features=256, bias=False)\n",
       "  )\n",
       "  (lora_embedding_A): ParameterDict()\n",
       "  (lora_embedding_B): ParameterDict()\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_model.base_model.model.model.layers[0].self_attn.k_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (test): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (test): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (test): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (test): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (test): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (test): Linear(in_features=16, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (test): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (test): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (test): Linear(in_features=16, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (test): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (test): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (test): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "torch.Size([11, 10])\n",
      "torch.Size([3, 5])\n",
      "torch.Size([3, 11])\n"
     ]
    }
   ],
   "source": [
    "a = nn.Linear(5,10)\n",
    "print(a.weight.shape)\n",
    "b = nn.Linear(10,11)\n",
    "print(b.weight.shape)\n",
    "c = torch.randn(3,5)\n",
    "print(c.shape)\n",
    "r = b(a(c))\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadedLoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank_1, rank_2, alpha_1, alpha_2, dropout = None, adapter_name = \"test\"):\n",
    "        super().__init__()\n",
    "        std_dev_1 = 1 / torch.sqrt(torch.tensor(rank_1).float())\n",
    "        std_dev_2 = 1 / torch.sqrt(torch.tensor(rank_2).float())\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.ModuleDict(torch.nn.Dropout(dropout), inplace = False)\n",
    "        self.W1 = nn.ModuleDict(\n",
    "            {\n",
    "                \"A\" : torch.nn.Linear(in_dim, rank_1, bias = False),\n",
    "                \"B\" : torch.nn.Linear(rank_1, out_dim, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.W1['A'].weight = torch.nn.Parameter(torch.randn(rank_1, in_dim) * std_dev_1)\n",
    "        self.W1['B'].weight = torch.nn.Parameter(torch.zeros(out_dim, rank_1))\n",
    "        self.W2 = nn.ModuleDict(\n",
    "            {\n",
    "                \"A1\" : torch.nn.Linear(in_dim, rank_2, bias = False),\n",
    "                \"A2\" : torch.nn.Linear(rank_2, rank_1, bias = False),\n",
    "                \"B1\" : torch.nn.Linear(rank_1, rank_2, bias = False),\n",
    "                \"B2\" : torch.nn.Linear(rank_2, out_dim, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.W2['A1'].weight = torch.nn.Parameter(torch.randn(rank_2, in_dim) * std_dev_2)\n",
    "        self.W2['A2'].weight = torch.nn.Parameter(torch.zeros(rank_1, rank_2))\n",
    "        self.W2['B1'].weight = torch.nn.Parameter(torch.zeros(rank_2, rank_1))\n",
    "        self.W2['B2'].weight = torch.nn.Parameter(torch.zeros(out_dim, rank_2) * std_dev_2)\n",
    "        self.alpha_1 = alpha_1\n",
    "        self.alpha_2 = alpha_2\n",
    "        self.is_second_layar_being_trained = False\n",
    "        self.is_first_layer_being_trained = False\n",
    "        self.is_first_layer_being_used_for_inference = True\n",
    "        self.is_first_layer_being_used_for_inference = True\n",
    "        self.scaling_1 = self.alpha_1 / self.rank_1\n",
    "        self.scaling_2 = self.alpha_2 / self.rank_2\n",
    "\n",
    "\n",
    "\n",
    "    def set_gradients_for_all_layer(self):\n",
    "        if self.is_second_layar_being_trained:\n",
    "            self.W2_a1.requires_grad = True\n",
    "            self.W2_a2.requires_grad = True\n",
    "            self.W2_b1.requires_grad = True\n",
    "            self.W2_b2.requires_grad = True\n",
    "        else:\n",
    "            self.W2_a1.requires_grad = False\n",
    "            self.W2_a2.requires_grad = False\n",
    "            self.W2_b1.requires_grad = False\n",
    "            self.W2_b2.requires_grad = False\n",
    "            \n",
    "        if self.is_first_layer_being_trained:\n",
    "            self.W1_a.requires_grad = True\n",
    "            self.W1_b.requires_grad = True\n",
    "        else:\n",
    "            self.W1_a.requires_grad = False\n",
    "            self.W1_b.requires_grad = False\n",
    "    \n",
    "    def tune_the_first_adapter(self):\n",
    "        self.is_first_layer_being_trained = True\n",
    "    \n",
    "    def freeze_the_first_adapter(self):\n",
    "        self.is_first_layer_being_trained = False\n",
    "    \n",
    "    def tune_the_second_adapter(self):\n",
    "        self.is_second_layar_being_trained = True\n",
    "    \n",
    "    def freeze_the_second_adapter(self):\n",
    "        self.is_second_layar_being_trained = False\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.set_gradients_for_all_layer()\n",
    "        if self.is_first_layer_being_used_for_inference and self.is_second_layer_being_used_for_inference:\n",
    "            #x = self.scaling_1 * (x @ self.W1_a @ self.W1_b) + self.scaling_2 * (x @ self.W2_a1 @ self.W2_a2 @ self.W2_b1 @ self.W2_b2)\n",
    "            x = self.scaling_1 * (self.W1['A'](self.W1['B'](x))) + self.scaling_2 * (self.W2['B2'](self.W2['A2'](self.W2['B1'](self.W2['A1'](x)))))\n",
    "        if self.is_first_layer_being_used_for_inference and not self.is_second_layer_being_used_for_inference:\n",
    "            #x = self.scaling_2 * (x @ self.W2_a1 @ self.W2_a2) \n",
    "            x = self.scaling_1 * (self.W1['A'](self.W1['B'](x))) \n",
    "        return x\n",
    "\"\"\"\n",
    "(base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
    "                (lora_dropout): ModuleDict(\n",
    "                  (test): Dropout(p=0.05, inplace=False)\n",
    "                )\n",
    "                (lora_A): ModuleDict(\n",
    "                  (test): Linear(in_features=2048, out_features=16, bias=False)\n",
    "                )\n",
    "                (lora_B): ModuleDict(\n",
    "                  (test): Linear(in_features=16, out_features=2048, bias=False)\n",
    "                )\n",
    "                (lora_embedding_A): ParameterDict()\n",
    "                (lora_embedding_B): ParameterDict()\n",
    "              )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CascadedLoRALinear4bit(torch.nn.Module):\n",
    "    def __init__(self, linear, in_dim, out_dim, rank_1 = 64, rank_2 = 32, alpha_1 = 16, alpha_2 = 16, adapter_name = \"default\" , dropout = None):\n",
    "        super().__init__()\n",
    "        self.base_layer = linear\n",
    "        std_dev_1 = 1 / torch.sqrt(torch.tensor(rank_1).float())\n",
    "        std_dev_2 = 1 / torch.sqrt(torch.tensor(rank_2).float())\n",
    "        if dropout is not None:\n",
    "            self.lora_dropout = nn.ModuleDict(\n",
    "                {\n",
    "                    adapter_name : torch.nn.Dropout(dropout)\n",
    "                }\n",
    "            )\n",
    "        #first dimension\n",
    "        self.lora_A = nn.ModuleDict(\n",
    "            {\n",
    "                adapter_name : torch.nn.Linear(in_dim, rank_1, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.lora_B = nn.ModuleDict(\n",
    "            {\n",
    "                adapter_name : torch.nn.Linear(rank_1, out_dim, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.lora_A[adapter_name].weight = torch.nn.Parameter(torch.randn(rank_1, in_dim) * std_dev_1)\n",
    "        self.lora_B[adapter_name].weight = torch.nn.Parameter(torch.zeros(out_dim, rank_1))  \n",
    "\n",
    "        self.lora_A1 = nn.ModuleDict(\n",
    "            {\n",
    "                adapter_name : torch.nn.Linear(in_dim, rank_2, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.lora_A2 = nn.ModuleDict(\n",
    "            {\n",
    "                adapter_name : torch.nn.Linear(rank_2, rank_1, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.lora_B1 = nn.ModuleDict(\n",
    "            {\n",
    "                adapter_name : torch.nn.Linear(rank_1, rank_2, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.lora_B2 = nn.ModuleDict(\n",
    "            {\n",
    "                adapter_name : torch.nn.Linear(rank_2, out_dim, bias = False)\n",
    "            }\n",
    "        )\n",
    "        self.lora_A1[adapter_name].weight = torch.nn.Parameter(torch.randn(rank_2, in_dim) * std_dev_2)\n",
    "        self.lora_A2[adapter_name].weight = torch.nn.Parameter(torch.zeros(rank_1, rank_2))\n",
    "        self.lora_B1[adapter_name].weight = torch.nn.Parameter(torch.zeros(rank_2, rank_1))\n",
    "        self.lora_B2[adapter_name].weight = torch.nn.Parameter(torch.zeros(out_dim, rank_2) * std_dev_2)  \n",
    "        self.alpha_1 = alpha_1\n",
    "        self.alpha_2 = alpha_2\n",
    "        self.rank_1 = rank_1\n",
    "        self.rank_2 = rank_2\n",
    "        self.is_second_layar_being_trained = False\n",
    "        self.is_first_layer_being_trained = False\n",
    "        self.is_first_layer_being_used_for_inference = True\n",
    "        self.is_first_layer_being_used_for_inference = True\n",
    "        self.scaling_1 = self.rank_1 / self.alpha_1\n",
    "        self.scaling_2 = self.rank_2 / self.alpha_1\n",
    "        self.adapter_name = adapter_name\n",
    "\n",
    "\n",
    "\n",
    "    def set_gradients_for_all_layer(self):\n",
    "        if self.is_second_layar_being_trained:\n",
    "            self.lora_A1[self.adapter_name].requires_grad = True\n",
    "            self.lora_A2[self.adapter_name].requires_grad = True\n",
    "            self.lora_B1[self.adapter_name].requires_grad = True\n",
    "            self.lora_B2[self.adapter_name].requires_grad = True\n",
    "\n",
    "\n",
    "        else:\n",
    "            self.lora_A1[self.adapter_name].requires_grad = False\n",
    "            self.lora_A2[self.adapter_name].requires_grad = False\n",
    "            self.lora_B1[self.adapter_name].requires_grad = False\n",
    "            self.lora_B2[self.adapter_name].requires_grad = False\n",
    "            \n",
    "        if self.is_first_layer_being_trained:\n",
    "            self.lora_A[self.adapter_name].requires_grad = True\n",
    "            self.lora_B[self.adapter_name].requires_grad = True\n",
    "        else:\n",
    "            self.lora_A[self.adapter_name].requires_grad = False\n",
    "            self.lora_B[self.adapter_name].requires_grad = False  \n",
    "    \n",
    "    def tune_the_first_adapter(self):\n",
    "        self.is_first_layer_being_trained = True\n",
    "    \n",
    "    def freeze_the_first_adapter(self):\n",
    "        self.is_first_layer_being_trained = False\n",
    "    \n",
    "    def tune_the_second_adapter(self):\n",
    "        self.is_second_layar_being_trained = True\n",
    "    \n",
    "    def freeze_the_second_adapter(self):\n",
    "        self.is_second_layar_being_trained = False\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self.set_gradients_for_all_layer()\n",
    "        if self.is_first_layer_being_used_for_inference and self.is_second_layer_being_used_for_inference:\n",
    "            #x = self.scaling_1 * (x @ self.W1_a @ self.W1_b) + self.scaling_2 * (x @ self.W2_a1 @ self.W2_a2 @ self.W2_b1 @ self.W2_b2)\n",
    "            output  = self.linear(x) + self.scaling_1 * (self.W1['A'](self.W1['B'](x))) + self.scaling_2 * (self.W2['B2'](self.W2['A2'](self.W2['B1'](self.W2['A1'](x)))))\n",
    "        if self.is_first_layer_being_used_for_inference and not self.is_second_layer_being_used_for_inference:\n",
    "            #x = self.scaling_2 * (x @ self.W2_a1 @ self.W2_a2) \n",
    "            output  =  self.linear(x)  + self.scaling_1 * (self.W1['A'](self.W1['B'](x))) \n",
    "        return output\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_1 = 64\n",
    "rank_2 = 32\n",
    "alpha_1 = 16\n",
    "alpha_2 = 16\n",
    "adapter_name = \"test\"\n",
    "dropout = 0.05\n",
    "target_modules = [\n",
    "                    'q_proj',\n",
    "                    'k_proj',\n",
    "                    'v_proj',\n",
    "                    'o_proj',\n",
    "                    'gate_proj',\n",
    "                    'up_proj',\n",
    "                    'down_proj'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m replace_with_cascaded_lora(quantized_model)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#print(quantized_model)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mprint_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcascaded_lora_structure.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 27\u001b[0m, in \u001b[0;36mprint_device_and_dtype\u001b[0;34m(model, file)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo parameters\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Print the name, device, and dtype of the module\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModule: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, file \u001b[38;5;241m=\u001b[39m file)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, file \u001b[38;5;241m=\u001b[39m file)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "def replace_with_cascaded_lora(module, target_modules = target_modules, rank_1 = 64, rank_2 = 32, alpha_1 = 16 , alpha_2 = 16 , adapter_name = \"default\" , dropout = None):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, bnb.nn.Linear4bit) and name in target_modules:\n",
    "            #setattr(module, name, CascadedLoRALinear4bit(child, in_dim, out_dim, **kwargs))\n",
    "            #print(name)\n",
    "            #print(child.in_features, child.out_features)\n",
    "            setattr(module, name, CascadedLoRALinear4bit(child, child.in_features, child.out_features, rank_1, rank_2, alpha_1, alpha_2, adapter_name , dropout = dropout))\n",
    "        else:\n",
    "            replace_with_cascaded_lora(child, target_modules, rank_1, rank_2, alpha_1, alpha_2, adapter_name , dropout = None)\n",
    "def print_device_and_dtype(model, file = sys.stdout):\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # Get the device and dtype of the module's parameters\n",
    "        #file = open(file, \"a\")\n",
    "        try:\n",
    "            param = next(module.parameters())\n",
    "            device = param.device\n",
    "            dtype = param.dtype\n",
    "            type = param.type()\n",
    "        except StopIteration:\n",
    "            device = 'No parameters'\n",
    "            dtype = 'No parameters'\n",
    "            type = 'No parameters'\n",
    "\n",
    "        \n",
    "        # Print the name, device, and dtype of the module\n",
    "        print(f\"Module: {name}\", file = file)\n",
    "        print(f\"  Device: {device}\", file = file)\n",
    "        print(f\"  Dtype: {dtype}\", file = file)\n",
    "        print(f\"  Type: {type}\", file = file)\n",
    "        print(\" \",file = file )\n",
    "\n",
    "\n",
    "\n",
    "replace_with_cascaded_lora(quantized_model)\n",
    "#print(quantized_model)\n",
    "print_device_and_dtype(quantized_model, file = \"cascaded_lora_structure.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "print_device_and_dtype() got an unexpected keyword argument 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m adapter_model \u001b[38;5;241m=\u001b[39m PeftModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model_quantized, adapter_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#print(adapter_model)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mprint_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./peft_structure.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: print_device_and_dtype() got an unexpected keyword argument 'file'"
     ]
    }
   ],
   "source": [
    "base_model_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "base_model_quantized = AutoModelForCausalLM.from_pretrained(base_model_path, **model_kwargs)\n",
    "adapter_model = PeftModelForCausalLM.from_pretrained(base_model_quantized, adapter_path, \"test\")\n",
    "#print(adapter_model)\n",
    "print_device_and_dtype(adapter_model, file = \"./peft_structure.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/microsoft/LoRA/blob/main/loralib/layers.py#L12\n",
    "class LoRALayer():\n",
    "    def __init__(\n",
    "        self, \n",
    "        rank_1 : int,\n",
    "        rank_2 : int, \n",
    "        lora_alpha_1: int,\n",
    "        lora_alpha_2: int, \n",
    "        lora_dropout: float,\n",
    "        merge_weights: bool,\n",
    "    ):\n",
    "        self.rank_1 = rank_1\n",
    "        self.rank_2 = rank_2\n",
    "        self.lora_alpha_1 = lora_alpha_1\n",
    "        self.lora_alpha_2 = lora_alpha_2\n",
    "        # Optional dropout\n",
    "        if lora_dropout > 0.:\n",
    "            self.lora_dropout = nn.Dropout(p=lora_dropout)\n",
    "        else:\n",
    "            self.lora_dropout = lambda x: x\n",
    "        # Mark the weight as unmerged\n",
    "        self.merged = False\n",
    "        self.merge_weights = merge_weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
