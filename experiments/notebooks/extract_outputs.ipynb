{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home2/tathagato/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home2/tathagato/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/tathagato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize, ngrams\n",
    "import sys\n",
    "from pyrouge import Rouge155\n",
    "from multiprocessing import Pool\n",
    "import nltk\n",
    "import shutil\n",
    "import time\n",
    "import tempfile\n",
    "import pwd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "st_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rouge evaluation\n",
    "def get_rouge_score(cand, ref, keys, output_dir = None):\n",
    "    cand = [line.strip() for line in cand]\n",
    "    ref = [line.strip() for line in ref]\n",
    "\n",
    "    assert len(cand) == len(ref) and len(cand) == len(keys)\n",
    "\n",
    "    candidates_chunks = list(chunks(cand, 1))\n",
    "    references_chunks = list(chunks(ref, 1))\n",
    "    keys_chunks = list(chunks(keys, 1))\n",
    "\n",
    "    n_pool = 36\n",
    "    arg_lst = []\n",
    "    # print(\"number of chunks: \", len(candidates_chunks))\n",
    "    for i in range(len(candidates_chunks)):\n",
    "        arg_lst.append((candidates_chunks[i], references_chunks[i], keys_chunks[i], i, output_dir))\n",
    "    pool = Pool(n_pool)\n",
    "    final_results = {}\n",
    "    results = pool.map(process, tqdm.tqdm(arg_lst))\n",
    "    for i, r in enumerate(results):\n",
    "        final_results[keys_chunks[i][0]] = r\n",
    "    pool.close()\n",
    "    #cleanup_tmp_dir(tmp_dir)\n",
    "    cleanup_tmp_dir(output_dir)\n",
    "    return final_results\n",
    "\n",
    "\n",
    "def get_average_rouge_scores(cand, ref, output_dir = None):\n",
    "    #keys can be empty not stictly required \n",
    "    keys = [str(i) for i in range(len(cand))]\n",
    "    results = get_rouge_score(cand, ref, keys, output_dir)\n",
    "    rouge_1 = 0\n",
    "    rouge_2 = 0\n",
    "    rouge_l = 0\n",
    "    for k in results:\n",
    "        rouge_1 += results[k]['rouge_1_f_score']\n",
    "        rouge_2 += results[k]['rouge_2_f_score']\n",
    "        rouge_l += results[k]['rouge_l_f_score']\n",
    "    rouge_1 = rouge_1 / len(results)\n",
    "    rouge_2 = rouge_2 / len(results)\n",
    "    rouge_l = rouge_l / len(results)\n",
    "    return rouge_1, rouge_2, rouge_l\n",
    "\n",
    "\n",
    "\n",
    "def get_current_process_owner():\n",
    "    return pwd.getpwuid(os.getuid()).pw_name\n",
    "\n",
    "def get_directory_owner(directory):\n",
    "    return pwd.getpwuid(os.stat(directory).st_uid).pw_name\n",
    "\n",
    "def cleanup_tmp_dir(tmp_dir):\n",
    "    print(\"cleaning tmp\")\n",
    "    all_dirs = [os.path.join(tmp_dir,f) for f in os.listdir(tmp_dir) if f.startswith(\"tmp\")]\n",
    "    current_process_owner = get_current_process_owner()\n",
    "    for d in tqdm.tqdm(all_dirs):\n",
    "        directory_owner_name = get_directory_owner(d)\n",
    "        if directory_owner_name == current_process_owner:\n",
    "            shutil.rmtree(os.path.join(\"/tmp\", d))\n",
    "    \n",
    "def process(data):\n",
    "    temp_dir = tempfile.mkdtemp(dir = \"/tmp\")\n",
    "    candidates, references, keys, pool_id, output_dir = data\n",
    "    cnt = len(candidates)\n",
    "    current_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())\n",
    "    tmp_dir = \"rouge-tmp-{}-{}\".format(current_time, pool_id)\n",
    "    if output_dir is not None:\n",
    "\n",
    "        tmp_dir = os.path.join(output_dir, tmp_dir)\n",
    "    if not os.path.isdir(tmp_dir):\n",
    "        os.mkdir(tmp_dir)\n",
    "        os.mkdir(tmp_dir + \"/candidate\")\n",
    "        os.mkdir(tmp_dir + \"/reference\")\n",
    "    try:\n",
    "        for i in range(cnt):\n",
    "            if len(references[i]) < 1:\n",
    "                continue\n",
    "            with open(tmp_dir + \"/candidate/cand.{}.txt\".format(i), \"w\",\n",
    "                      encoding=\"utf-8\") as f:\n",
    "                f.write(candidates[i])\n",
    "            with open(tmp_dir + \"/reference/ref.{}.txt\".format(i), \"w\",\n",
    "                      encoding=\"utf-8\") as f:\n",
    "                f.write(references[i])\n",
    "\n",
    "        r = Rouge155()\n",
    "        r.model_dir = tmp_dir + \"/reference/\"\n",
    "        r.system_dir = tmp_dir + \"/candidate/\"\n",
    "        r.model_filename_pattern = 'ref.#ID#.txt'\n",
    "        r.system_filename_pattern = r'cand.(\\d+).txt'\n",
    "        rouge_results = r.convert_and_evaluate(rouge_args=\"-e /home2/tathagato/summarization/ROUGE/pyrouge/tools/ROUGE-1.5.5/data -c 95 \"\n",
    "                                                          \"-m -n 3 -a\")\n",
    "        # print(rouge_results)\n",
    "        results_dict = r.output_to_dict(rouge_results)\n",
    "        final_res = {\"rouge_1_f_score\": results_dict[\"rouge_1_f_score\"], \"rouge_2_f_score\": results_dict[\"rouge_2_f_score\"],\"rouge_l_f_score\": results_dict[\"rouge_l_f_score\"],\"rouge_3_f_score\" : results_dict[\"rouge_3_f_score\"],\n",
    "                     \"rouge_1_recall\": results_dict[\"rouge_1_recall\"], \"rouge_2_recall\": results_dict[\"rouge_2_recall\"],\"rouge_l_recall\": results_dict[\"rouge_l_recall\"], \"rouge_3_recall\": results_dict[\"rouge_3_recall\"],\n",
    "                     \"rouge_1_precision\": results_dict[\"rouge_1_precision\"], \"rouge_2_precision\": results_dict[\"rouge_2_precision\"],\"rouge_l_precision\": results_dict[\"rouge_l_precision\"], \"rouge_3_precision\": results_dict[\"rouge_3_precision\"],\n",
    "                    }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error in processing\")\n",
    "        final_res = {\"rouge_1_f_score\": 0, \"rouge_2_f_score\": 0, \"rouge_l_f_score\": 0,\n",
    "                     \"rouge_1_recall\": 0, \"rouge_2_recall\": 0, \"rouge_l_recall\": 0,\n",
    "                     \"rouge_1_precision\": 0, \"rouge_2_precision\": 0, \"rouge_l_precision\": 0\n",
    "                    }\n",
    "    finally:\n",
    "        pass\n",
    "        if os.path.isdir(tmp_dir):\n",
    "            shutil.rmtree(tmp_dir)\n",
    "        shutil.rmtree(temp_dir)\n",
    "        \n",
    "    return final_res\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "def get_rouge(predictions, references):\n",
    "    #keys can be empty not stictly required \n",
    "    results = {}\n",
    "    print(\"computing rouge\")\n",
    "    rouge_1, rouge_2, rouge_l = get_average_rouge_scores(predictions, references)\n",
    "    results['rouge_1'] = rouge_1\n",
    "    results['rouge_2'] = rouge_2\n",
    "    results['rouge_l'] = rouge_l\n",
    "    print(\"done computing rouge\")\n",
    "    return results\n",
    "\n",
    "# def get_extractive_control_function(predictions, references, articles):\n",
    "#     \"\"\" computes the f_r for r extractiveness as defined  as defined by the https://arxiv.org/pdf/2211.05041 \"\"\"\n",
    "#     indexes = [i for i in range(len(articles))]\n",
    "\n",
    "#     #first compute f_r for predictions \n",
    "#     for prediction, article in tqdm.tqdm(zip(predictions, articles)):\n",
    "\n",
    "#         results.append(f_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_attribute(filepath):\n",
    "    basename = os.path.basename(filepath)\n",
    "    #find the part of string between evaluate_on and . in basename\n",
    "    attribute = basename.split(\"evaluate_on_\")[1].split(\"_\")[0]\n",
    "    #filename = os.path.splitext(basename)[0]\n",
    "    #attribute = filename.split(\"_\")[-1]\n",
    "    return attribute\n",
    "def get_fragment_density(article, summary):\n",
    "    \"\"\"\n",
    "    Calculates the fragment density of a summary on an article.\n",
    "\n",
    "    Density is defined as the average squared length of extracted fragments.\n",
    "\n",
    "    Args:\n",
    "        article (str): The article text.\n",
    "        summary (str): The summary text.\n",
    "\n",
    "    Returns:\n",
    "        float: The fragment density of the summary on the article.\n",
    "    \"\"\"\n",
    "\n",
    "    frags, article_tokens, summary_tokens = get_extractive_fragments(article, summary)\n",
    "    if len(summary_tokens) == 0:\n",
    "        print(\"fragment density sumary_tokens is zero\")\n",
    "        print(article)\n",
    "        print(summary)\n",
    "        return 0\n",
    "    density = float(sum([len(f)**2 for f in frags])) / float(len(summary_tokens))\n",
    "    return density\n",
    "def get_overlap(inp, out, ngram = 2):\n",
    "    grams_inp = set(ngrams(word_tokenize(inp.lower()), ngram))\n",
    "    grams_out = set(ngrams(word_tokenize(out.lower()), ngram))\n",
    "\n",
    "    total = len(grams_out)\n",
    "    common = len(grams_inp.intersection(grams_out))\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(common) / float(total)\n",
    "def get_extractive_fragments(article, summary):\n",
    "    \"\"\"\n",
    "    Extracts fragments from an article that match sequences of words in a summary.\n",
    "\n",
    "    Args:\n",
    "        article (str): The article text.\n",
    "        summary (str): The summary text.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists, where each sublist represents a sequence of word indexes\n",
    "            in the article that match a sequence in the summary.\n",
    "        list: The tokenized article.\n",
    "        list: The tokenized summary.\n",
    "    \"\"\"\n",
    "\n",
    "    article_tokens = word_tokenize(article.lower())\n",
    "    summary_tokens = word_tokenize(summary.lower())\n",
    "\n",
    "    F = []  # List to store the extracted fragments\n",
    "    i, j = 0, 0  # Indexes for iterating over article and summary tokens, respectively\n",
    "\n",
    "    while i < len(summary_tokens):\n",
    "        f = []  # List to store the current fragment\n",
    "        while j < len(article_tokens):\n",
    "            if summary_tokens[i] == article_tokens[j]:\n",
    "                i_, j_ = i, j  # Store starting indexes of potential fragment\n",
    "                #print(len(summary_tokens), len(article_tokens), i, j, i_, j_, summary_tokens[i_], article_tokens[j_])\n",
    "                while (i_ < len(summary_tokens) and j_ < len(article_tokens)) and summary_tokens[i_] == article_tokens[j_]:\n",
    "                    i_, j_ = i_ + 1, j_ + 1  # Update indexes while words match\n",
    "                if len(f) < (i_ - i):  # Update fragment if a longer match is found\n",
    "                    f = list(range(i, i_))\n",
    "                j = j_  # Set j to the next position after the matched sequence\n",
    "            else:\n",
    "                j += 1  # Move to the next article token if no match found\n",
    "        i += max(len(f), 1)  # Update i by the length of the extracted fragment or 1\n",
    "        j = 1  # Reset j for the next iteration\n",
    "\n",
    "        F.append(f)  # Append the extracted fragment to the list\n",
    "\n",
    "    return F, article_tokens, summary_tokens\n",
    "\n",
    "\n",
    "def get_control_value_for_length(predictions, summaries):\n",
    "    \"\"\"\n",
    "    CER for length as defined by https://arxiv.org/pdf/2211.05041\n",
    "\n",
    "    Args:\n",
    "        summaries (Lis): the list of gold_summaries\n",
    "        predictions (List): the list of predicted summaries\n",
    "\n",
    "    Returns:\n",
    "        str: average of cer scores\n",
    "    \"\"\"\n",
    "    length_cers = []\n",
    "    eta = 0.1\n",
    "    for prediction, summary in zip(predictions, summaries):\n",
    "        prediction_tokens = len(word_tokenize(prediction.lower()))\n",
    "        summary_tokens = len(word_tokenize(summary.lower()))\n",
    "        if summary_tokens == 0:\n",
    "            cer = abs(prediction_tokens - summary_tokens) / (summary_tokens + eta)\n",
    "        else:\n",
    "            cer = abs(prediction_tokens - summary_tokens) / summary_tokens\n",
    "        length_cers.append(cer)\n",
    "    return sum(length_cers) / len(length_cers)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_extractive_coverage(article, summary):\n",
    "    \"\"\"\n",
    "    Calculates the extractive coverage of a summary on an article.\n",
    "\n",
    "    Coverage is defined as the ratio of words in the summary covered by fragments\n",
    "    extracted from the article.\n",
    "\n",
    "    Args:\n",
    "        article (str): The article text.\n",
    "        summary (str): The summary text.\n",
    "\n",
    "    Returns:\n",
    "        float: The extractive coverage of the summary on the article.\n",
    "    \"\"\"\n",
    "\n",
    "    frags, article_tokens, summary_tokens = get_extractive_fragments(article, summary)\n",
    "    if len(summary_tokens) == 0:\n",
    "        print(\"sumary_tokens is zero\")\n",
    "        print(article)\n",
    "        print(summary)\n",
    "        return 0\n",
    "\n",
    "    coverage = float(sum([len(f) for f in frags])) / float(len(summary_tokens))\n",
    "    return coverage\n",
    "\n",
    "def clean_and_process_data(file):\n",
    "    data = json.load(open(file,\"r\"))\n",
    "    keys = list(data.keys())\n",
    "    for key in tqdm.tqdm(keys):\n",
    "        #print(data[key].keys())\n",
    "        if 'generated_text' not in data[key]:\n",
    "            #remove the element from dict\n",
    "            print(\"popping key\", key)\n",
    "            data.pop(key)\n",
    "            continue\n",
    "        summary = data[key]['generated_text'].split(\"\\n\")[-1]\n",
    "        data[key]['predicted_summary'] = summary\n",
    "    with open(file, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "    return data\n",
    "\n",
    "def get_length_stats(data):\n",
    "    output_dict = {}\n",
    "    controlled_attribute = \"length\"\n",
    "    keys = list(data.keys())\n",
    "    for key in keys:\n",
    "        control_value = data[key]['control_value']\n",
    "        article = data[key]['input']\n",
    "        summary = data[key]['predicted_summary']\n",
    "        reference = data[key]['output']\n",
    "        if control_value not in output_dict:\n",
    "            output_dict[control_value] = {\"article\":[], \"summary\":[], \"reference\":[]}\n",
    "        output_dict[control_value]['article'].append(article)\n",
    "        output_dict[control_value]['summary'].append(summary)\n",
    "        output_dict[control_value]['reference'].append(reference)\n",
    "    for key in output_dict:\n",
    "        output_dict[key]['prediction_summary_length'] = [get_summary_length(summary) for summary in output_dict[key]['summary']]\n",
    "        output_dict[key]['prediction_compression_ratio'] = [get_compression_ratio(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['summary'])]\n",
    "        output_dict[key]['reference_summary_length'] = [get_summary_length(summary) for summary in output_dict[key]['reference']]\n",
    "        output_dict[key]['reference_compression_ratio'] = [get_compression_ratio(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['reference'])]\n",
    "        print(\"control_value\", key, len(output_dict[key]['article']), len(output_dict[key]['summary']))\n",
    "        print(\"Prediction Summary Length\", sum(output_dict[key]['prediction_summary_length'])/ len(output_dict[key]['prediction_summary_length']))\n",
    "        print(\"Reference Summary Length\", sum(output_dict[key]['reference_summary_length'])/ len(output_dict[key]['reference_summary_length']))\n",
    "        print(\"Prediction Compression Ratio\", sum(output_dict[key]['prediction_compression_ratio'])/ len(output_dict[key]['prediction_compression_ratio']))\n",
    "        print(\"Reference Compression Ratio\", sum(output_dict[key]['reference_compression_ratio'])/ len(output_dict[key]['reference_compression_ratio']))\n",
    "    \n",
    "    print(\"------------------------------\")\n",
    "    #print(output_dict.keys())\n",
    "\n",
    "def get_summary_length(summary):\n",
    "    return len(word_tokenize(summary.lower()))\n",
    "\n",
    "def get_compression_ratio(article, summary):\n",
    "    if len(word_tokenize(article.lower())) == 0:\n",
    "        print(\"article_tokens is zero\")\n",
    "        print(article)\n",
    "        print(summary)\n",
    "        return 0\n",
    "    return float(len(word_tokenize(summary.lower()))) / float(len(word_tokenize(article.lower())))\n",
    "\n",
    "def get_abstractive_data(data):\n",
    "    keys = list(data.keys())\n",
    "    output_dict = {}\n",
    "    controlled_attribute = \"extractiveness\"\n",
    "    for key in tqdm.tqdm(keys):\n",
    "        control_value = data[key]['control_value']\n",
    "        article = data[key]['input']\n",
    "        summary = data[key]['predicted_summary']\n",
    "        reference = data[key]['output']\n",
    "        if control_value not in output_dict:\n",
    "            output_dict[control_value] = {\"article\":[], \"summary\":[], \"reference\":[]}\n",
    "        output_dict[control_value]['article'].append(article)\n",
    "        output_dict[control_value]['summary'].append(summary)\n",
    "        output_dict[control_value]['reference'].append(reference)\n",
    "    #print(output_dict.keys())\n",
    "    \n",
    "\n",
    "    for key in tqdm.tqdm(output_dict):\n",
    "        print(key, len(output_dict[key]['article']), len(output_dict[key]['summary']), len(output_dict[key]['reference']))\n",
    "        output_dict[key]['prediction_density'] = [get_fragment_density(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['summary'])]\n",
    "        output_dict[key]['prediction_coverage'] = [get_extractive_coverage(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['summary'])]\n",
    "        output_dict[key]['prediction_overlap'] = [get_overlap(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['summary'])]\n",
    "        output_dict[key]['reference_density'] = [get_fragment_density(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['reference'])]\n",
    "        output_dict[key]['reference_coverage'] = [get_extractive_coverage(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['reference'])]\n",
    "        output_dict[key]['reference_overlap'] = [get_overlap(article, summary) for article, summary in zip(output_dict[key]['article'], output_dict[key]['reference'])]\n",
    "\n",
    "        print(\"control_value\", key, len(output_dict[key]['article']), len(output_dict[key]['summary']))\n",
    "        print(\"Prediction Density\", sum(output_dict[key]['prediction_density'])/ len(output_dict[key]['prediction_density']))\n",
    "        print(\"Prediction Coverage\", sum(output_dict[key]['prediction_coverage'])/ len(output_dict[key]['prediction_coverage']))\n",
    "        print(\"Prediction Overlap\", sum(output_dict[key]['prediction_overlap'])/ len(output_dict[key]['prediction_overlap']))\n",
    "\n",
    "\n",
    "        print(\"Reference Density\", sum(output_dict[key]['reference_density'])/ len(output_dict[key]['reference_density']))\n",
    "        print(\"Reference Coverage\", sum(output_dict[key]['reference_coverage'])/ len(output_dict[key]['reference_coverage']))\n",
    "        print(\"Reference Overlap\", sum(output_dict[key]['reference_overlap'])/ len(output_dict[key]['reference_overlap']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def output_length_metrics(data):\n",
    "    keys = list(data.keys())\n",
    "    for key in tqdm.tqdm(keys):\n",
    "        if 'generated_text' not in data[key]:\n",
    "            #remove the element from dict\n",
    "            print(\"popping key\", key)\n",
    "            data.pop(key)\n",
    "            continue\n",
    "        summary = data[key]['generated_text'].split(\"\\n\")[-1]\n",
    "        data[key]['predicted_summary'] = summary\n",
    "\n",
    "    get_length_stats(data)\n",
    "    segregrated_data = {}\n",
    "    keys = list(data.keys())\n",
    "    summaries = []\n",
    "    references = []\n",
    "    for key in keys:\n",
    "        control_value = data[key]['control_value']\n",
    "        if control_value not in segregrated_data:\n",
    "            segregrated_data[control_value] = {\"summaries\" : [], \"articles\" : [], \"references\" : []}\n",
    "        segregrated_data[control_value]['summaries'].append(data[key]['predicted_summary'])\n",
    "        segregrated_data[control_value]['articles'].append(data[key]['input'])\n",
    "        segregrated_data[control_value]['references'].append(data[key]['output'])\n",
    "        summaries.append(data[key]['predicted_summary'])\n",
    "        references.append(data[key]['output'])\n",
    "\n",
    "    for control_value in segregrated_data:\n",
    "        print(\"control value \", control_value)\n",
    "        cer = get_control_value_for_length(segregrated_data[control_value]['summaries'], segregrated_data[control_value]['references'])\n",
    "        print(\"CER\", cer)\n",
    "    print(\"Overall\")\n",
    "    cer = get_control_value_for_length(summaries, references)\n",
    "    print(\"CER\", cer)\n",
    "    \n",
    "\n",
    "    # elif attribute == \"extractiveness\":\n",
    "    #     data = clean_and_process_data(file)\n",
    "    #     get_abstractive_data(data)\n",
    "        \n",
    "    \n",
    "def get_summaries_articles_and_references(data):\n",
    "    keys = list(data.keys())\n",
    "    summaries = []\n",
    "    articles = []\n",
    "    references = []\n",
    "    keys = list(data.keys())\n",
    "    for key in tqdm.tqdm(keys):\n",
    "        summaries.append(data[key]['generated_text'].split(\"\\n\")[-1])\n",
    "        articles.append(data[key]['input'])\n",
    "        references.append(data[key]['output'])\n",
    "    return summaries, articles, references, keys\n",
    "\n",
    "def get_control_error_for_extractiveness(data):\n",
    "    \"\"\" computes the f_r for r extractiveness as defined  as defined by the https://arxiv.org/pdf/2211.05041 \"\"\"\n",
    "    summaries, articles, references, keys = get_summaries_articles_and_references(data)\n",
    "    output_tmp_dir = \"/tmp/rouge_output\"\n",
    "    if not os.path.isdir(output_tmp_dir):\n",
    "        os.mkdir(output_tmp_dir)\n",
    "    generated_rouge = get_rouge_score(summaries, articles, keys, output_tmp_dir)\n",
    "    reference_rouge = get_rouge_score(references, articles, keys, output_tmp_dir)\n",
    "\n",
    "    control_errors = []\n",
    "    generated_frs = []\n",
    "    reference_frs = []\n",
    "    for index,key in enumerate(keys):\n",
    "        generated_fr = (generated_rouge[key]['rouge_2_precision'] + generated_rouge[key]['rouge_3_precision']) / 2\n",
    "        reference_fr = (reference_rouge[key]['rouge_2_precision'] + reference_rouge[key]['rouge_3_precision']) / 2\n",
    "        if reference_fr == 0:\n",
    "            control_error = abs(generated_fr - reference_fr) / (reference_fr + 0.1)\n",
    "        else:\n",
    "            control_error = abs(generated_fr - reference_fr) / reference_fr\n",
    "            \n",
    "        control_errors.append(control_error)\n",
    "        generated_frs.append(generated_fr)\n",
    "        reference_frs.append(reference_fr)\n",
    "    return sum(control_errors) / len(control_errors), control_errors, generated_frs, reference_frs\n",
    "\n",
    "def output_extractiveness_metrics(data):\n",
    "    segregrated_data = {}\n",
    "    keys = list(data.keys())\n",
    "    for key in keys:\n",
    "        control_value = data[key]['control_value']\n",
    "        if control_value not in segregrated_data:\n",
    "            segregrated_data[control_value] = {}\n",
    "        segregrated_data[control_value][key] = data[key]\n",
    "    for control_value in segregrated_data:\n",
    "        print(\"control value \", control_value)\n",
    "        control_error, control_errors, generated_frs, reference_frs = get_control_error_for_extractiveness(segregrated_data[control_value])\n",
    "        print(\"Control Error\", control_error)\n",
    "        print(\"num examples : \", len(control_errors))\n",
    "        print(\"prediction F score : \",sum(generated_frs) / len(generated_frs))\n",
    "        print(\"gold F score : \",sum(reference_frs) / len(reference_frs))\n",
    "\n",
    "    overall_cer, control_errors, generated_frs, reference_frs = get_control_error_for_extractiveness(data)\n",
    "    print(\"Overall Control Error\", overall_cer)\n",
    "    print(\"num examples : \", len(control_errors))\n",
    "    print(\"prediction F score : \",sum(generated_frs) / len(generated_frs))\n",
    "    print(\"gold F score : \",sum(reference_frs) / len(reference_frs))\n",
    "\n",
    "    get_abstractive_data(data)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_values(topic, prediction):\n",
    "    return [get_topic_value(x, y) for x, y in zip(topic, prediction)]\n",
    "\n",
    "def get_topic_value(topic, prediction):\n",
    "    topic_scores = []\n",
    "    tokens = nltk.word_tokenize(topic)\n",
    "    cnt_all = 0\n",
    "    cnt_hit = 0\n",
    "    for token in tokens:\n",
    "        if not token.isalpha():\n",
    "            continue\n",
    "        cnt_all += 1\n",
    "        if token.lower() in prediction.lower():\n",
    "            cnt_hit += 1\n",
    "\n",
    "    if cnt_all == 0:\n",
    "        return 0\n",
    "\n",
    "    topic_scores.append(1.0 * cnt_hit / cnt_all)\n",
    "    return sum(topic_scores)/len(topic_scores)\n",
    "\n",
    "\n",
    "def get_topic_score(data):\n",
    "    topic_scores = []\n",
    "    gold_scores = []\n",
    "    for key in data:\n",
    "        gold_summary = data[key]['output']\n",
    "        prediction = data[key]['generated_text'].split(\"\\n\")[-1]\n",
    "        topic_value = data[key]['control_value']\n",
    "        topic_scores.append(get_topic_value(topic_value, prediction))\n",
    "        gold_scores.append(get_topic_value(topic_value, gold_summary))\n",
    "    abs_score = sum(topic_scores) / len(topic_scores)\n",
    "    relative_score = cal_diff(gold_scores, topic_scores)\n",
    "    return relative_score, abs_score\n",
    "\n",
    "def cal_diff(gold_list, pred_list, relative=True):\n",
    "    diffs = []\n",
    "    for gold, pred in zip(gold_list, pred_list):\n",
    "        diff = math.fabs(gold - pred)\n",
    "        if relative:\n",
    "            diff /= gold if gold else 0.1\n",
    "        diffs.append(diff)\n",
    "    ret = sum(diffs) / len(diffs)\n",
    "    return ret\n",
    "\n",
    "def output_topic_metrics(data):\n",
    "    relative_score, abs_score = get_topic_score(data)\n",
    "    print(\"Relative Score: \", relative_score)\n",
    "    print(\"Absolute Score: \", abs_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specificity_value(target):\n",
    "\n",
    "    num_sent = len(nltk.sent_tokenize(target))\n",
    "    target = nltk.word_tokenize(target.lower())\n",
    "    target = [x for x in target if x not in st_words]\n",
    "    target_pos = nltk.pos_tag(target)\n",
    "    tot = len(target_pos)\n",
    "    nn_words = [x for x, y in target_pos if y == 'NN']\n",
    "    vb_words = [x for x, y in target_pos if y == 'VB']\n",
    "    vbg_words = [x for x, y in target_pos if y == 'VBG']\n",
    "    cd_words = [x for x, y in target_pos if y == 'CD']\n",
    "    nn = len(nn_words)\n",
    "    vb = len(vb_words)\n",
    "    cd = len(cd_words)\n",
    "    vbg = len(vbg_words)\n",
    "    if num_sent == 0:\n",
    "        return 0\n",
    "    metrics = (0.1 * vbg + 0.2 * tot + 0.3 * nn + 0.4 * cd) / num_sent\n",
    "    return metrics\n",
    "def cal_intra(bucket_gold, bucket_pred, relative=True):\n",
    "    diffs = []\n",
    "    for prediction_specificity, gold_specificity in zip(bucket_pred, bucket_gold):\n",
    "        diff = math.fabs(gold_specificity - prediction_specificity)\n",
    "        if relative:\n",
    "            diff /= gold_specificity\n",
    "        diffs.append(diff)\n",
    "    ret = sum(diffs) / len(diffs)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_spe(data):\n",
    "    bucket_len = []\n",
    "    bucket_gold = []\n",
    "    for key in tqdm.tqdm(data):\n",
    "        gold_summary = data[key]['output']\n",
    "        if 'generated_text' not in data[key]:\n",
    "            continue\n",
    "        prediction = data[key]['generated_text'].split(\"\\n\")[-1]\n",
    "        if len(prediction) == 0:\n",
    "            continue\n",
    "\n",
    "        bucket_len.append(get_specificity_value(prediction))\n",
    "        bucket_gold.append(get_specificity_value(gold_summary))\n",
    "        \n",
    "\n",
    "    intra_score = cal_intra(bucket_gold, bucket_len)\n",
    "    f_pred = sum(bucket_len) / len(bucket_len)\n",
    "    f_gold = sum(bucket_gold) / len(bucket_gold)\n",
    "    return intra_score, f_pred, f_gold\n",
    "\n",
    "def output_specificity_metrics(data):\n",
    "    segregrated_data = {}\n",
    "    for key in data:\n",
    "        control_value = data[key]['control_value']\n",
    "        if control_value not in segregrated_data:\n",
    "            segregrated_data[control_value] = {}\n",
    "        segregrated_data[control_value][key] = data[key]\n",
    "    print(segregrated_data.keys())\n",
    "    for key in segregrated_data:\n",
    "        print(\"control key \", key)\n",
    "        intra_score, f_pred, f_gold = get_spe(segregrated_data[key])\n",
    "        print(\"CER : \", intra_score)\n",
    "        print(f\"Prediction Specificity : {f_pred}\")\n",
    "        print(f\"Gold Specificity : {f_gold}\")\n",
    "        print(\"\\n--\")\n",
    "    intra_score, f_pred, f_gold = get_spe(data)\n",
    "    print(\"overall CER : \", intra_score)\n",
    "    print(f\"Overall Prediction Specificity : {f_pred}\")\n",
    "    print(f\"Overall Gold Specificity : {f_gold}\")\n",
    "    print(\"\\n\\n-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_values(topic, prediction):\n",
    "    return [get_topic_value(x, y) for x, y in zip(topic, prediction)]\n",
    "\n",
    "def get_topic_value(topic, prediction):\n",
    "    topic_scores = []\n",
    "    tokens = nltk.word_tokenize(topic)\n",
    "    cnt_all = 0\n",
    "    cnt_hit = 0\n",
    "    for token in tokens:\n",
    "        if not token.isalpha():\n",
    "            continue\n",
    "        cnt_all += 1\n",
    "        if token.lower() in prediction.lower():\n",
    "            cnt_hit += 1\n",
    "\n",
    "    if cnt_all == 0:\n",
    "        return 0\n",
    "\n",
    "    topic_scores.append(1.0 * cnt_hit / cnt_all)\n",
    "    return sum(topic_scores)/len(topic_scores)\n",
    "\n",
    "def load_folder():\n",
    "    path_dict = []\n",
    "    for path_name in os.listdir(folder):\n",
    "        if 'predictions_eval' in path_name:\n",
    "            path_dict.append(os.path.join(folder, path_name))\n",
    "    return path_dict\n",
    "\n",
    "def order_results(results_dict):\n",
    "    return sorted(results_dict.items(), key=lambda x:x[0])\n",
    "\n",
    "def get_topic_score(data):\n",
    "    topic_scores = []\n",
    "    gold_scores = []\n",
    "    for sample in data:\n",
    "        if len(sample['topic']) == 0:\n",
    "            continue\n",
    "        topic_scores.append(get_topic_value(sample['topic'], sample['prediction']))\n",
    "        gold_scores.append(get_topic_value(sample['topic'], sample['summary']))\n",
    "    abs_score = sum(topic_scores) / len(topic_scores)\n",
    "    relative_score = cal_diff(gold_scores, topic_scores)\n",
    "    return relative_score\n",
    "\n",
    "def cal_diff(gold_list, pred_list, relative=True):\n",
    "    diffs = []\n",
    "    for gold, pred in zip(gold_list, pred_list):\n",
    "        diff = math.fabs(gold - pred)\n",
    "        if relative:\n",
    "            diff /= gold if gold else 0.1\n",
    "        diffs.append(diff)\n",
    "    ret = sum(diffs) / len(diffs)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "./../inference_results//length_evaluate_on_length_final.json length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 234318.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_value short 116 116\n",
      "Prediction Summary Length 38.48275862068966\n",
      "Reference Summary Length 31.939655172413794\n",
      "Prediction Compression Ratio 0.06016157006056852\n",
      "Reference Compression Ratio 0.046145859439786684\n",
      "control_value normal 278 278\n",
      "Prediction Summary Length 46.884892086330936\n",
      "Reference Summary Length 44.76618705035971\n",
      "Prediction Compression Ratio 0.06367751911383362\n",
      "Reference Compression Ratio 0.06283865459897035\n",
      "control_value long 126 126\n",
      "Prediction Summary Length 44.26984126984127\n",
      "Reference Summary Length 88.97619047619048\n",
      "Prediction Compression Ratio 0.0675287644770482\n",
      "Reference Compression Ratio 0.1293584876307417\n",
      "------------------------------\n",
      "control value  short\n",
      "CER 0.868616140186337\n",
      "control value  normal\n",
      "CER 1.025096060058648\n",
      "control value  long\n",
      "CER 0.6457811579957207\n",
      "Overall\n",
      "CER 0.8982780824334233\n",
      "./../inference_results//length_evaluate_on_length_1500.json length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 298241.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_value short 116 116\n",
      "Prediction Summary Length 38.06896551724138\n",
      "Reference Summary Length 31.939655172413794\n",
      "Prediction Compression Ratio 0.06393441009638956\n",
      "Reference Compression Ratio 0.046145859439786684\n",
      "control_value normal 278 278\n",
      "Prediction Summary Length 43.298561151079134\n",
      "Reference Summary Length 44.76618705035971\n",
      "Prediction Compression Ratio 0.05946682016576045\n",
      "Reference Compression Ratio 0.06283865459897035\n",
      "control_value long 126 126\n",
      "Prediction Summary Length 42.26984126984127\n",
      "Reference Summary Length 88.97619047619048\n",
      "Prediction Compression Ratio 0.06897168820398489\n",
      "Reference Compression Ratio 0.1293584876307417\n",
      "------------------------------\n",
      "control value  short\n",
      "CER 1.0060439576593334\n",
      "control value  normal\n",
      "CER 0.8862571405528854\n",
      "control value  long\n",
      "CER 0.6791718920163567\n",
      "Overall\n",
      "CER 0.8628004664543177\n",
      "./../inference_results//length_evaluate_on_length_1000.json length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 319706.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_value short 116 116\n",
      "Prediction Summary Length 39.03448275862069\n",
      "Reference Summary Length 31.939655172413794\n",
      "Prediction Compression Ratio 0.06215148062205984\n",
      "Reference Compression Ratio 0.046145859439786684\n",
      "control_value normal 278 278\n",
      "Prediction Summary Length 44.73021582733813\n",
      "Reference Summary Length 44.76618705035971\n",
      "Prediction Compression Ratio 0.0643017024296815\n",
      "Reference Compression Ratio 0.06283865459897035\n",
      "control_value long 126 126\n",
      "Prediction Summary Length 47.642857142857146\n",
      "Reference Summary Length 88.97619047619048\n",
      "Prediction Compression Ratio 0.07281768351026098\n",
      "Reference Compression Ratio 0.1293584876307417\n",
      "------------------------------\n",
      "control value  short\n",
      "CER 0.9479126501402185\n",
      "control value  normal\n",
      "CER 0.8980759790862917\n",
      "control value  long\n",
      "CER 0.6275469224403392\n",
      "Overall\n",
      "CER 0.84364211890334\n",
      "./../inference_results//length_evaluate_on_length_1.json length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 223535.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_value short 116 116\n",
      "Prediction Summary Length 136.16379310344828\n",
      "Reference Summary Length 31.939655172413794\n",
      "Prediction Compression Ratio 0.2399182409243472\n",
      "Reference Compression Ratio 0.046145859439786684\n",
      "control_value normal 278 278\n",
      "Prediction Summary Length 137.13309352517985\n",
      "Reference Summary Length 44.76618705035971\n",
      "Prediction Compression Ratio 0.21611378194551553\n",
      "Reference Compression Ratio 0.06283865459897035\n",
      "control_value long 126 126\n",
      "Prediction Summary Length 143.8015873015873\n",
      "Reference Summary Length 88.97619047619048\n",
      "Prediction Compression Ratio 0.2502755318764583\n",
      "Reference Compression Ratio 0.1293584876307417\n",
      "------------------------------\n",
      "control value  short\n",
      "CER 4.758791049316162\n",
      "control value  normal\n",
      "CER 3.401314912434915\n",
      "control value  long\n",
      "CER 1.4192213882308273\n",
      "Overall\n",
      "CER 3.2238600044128165\n",
      "./../inference_results//length_evaluate_on_length_500.json length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 305040.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_value short 116 116\n",
      "Prediction Summary Length 35.69827586206897\n",
      "Reference Summary Length 31.939655172413794\n",
      "Prediction Compression Ratio 0.056160495405240415\n",
      "Reference Compression Ratio 0.046145859439786684\n",
      "control_value normal 278 278\n",
      "Prediction Summary Length 42.485611510791365\n",
      "Reference Summary Length 44.76618705035971\n",
      "Prediction Compression Ratio 0.05588689320143202\n",
      "Reference Compression Ratio 0.06283865459897035\n",
      "control_value long 126 126\n",
      "Prediction Summary Length 36.1031746031746\n",
      "Reference Summary Length 88.97619047619048\n",
      "Prediction Compression Ratio 0.05729233578665565\n",
      "Reference Compression Ratio 0.1293584876307417\n",
      "------------------------------\n",
      "control value  short\n",
      "CER 0.7559768666761243\n",
      "control value  normal\n",
      "CER 0.7939506178217723\n",
      "control value  long\n",
      "CER 0.5787428179638017\n",
      "Overall\n",
      "CER 0.7333330449083113\n"
     ]
    }
   ],
   "source": [
    "dirname = \"./../inference_results//\"\n",
    "files = [os.path.join(dirname, f) for f in os.listdir(dirname) if os.path.isfile(os.path.join(dirname, f))]\n",
    "files = [(file, get_evaluation_attribute(file)) for file in files]\n",
    "print(len(files))\n",
    "for file, attribute in files:\n",
    "    if attribute == 'length':\n",
    "        print(file, attribute)\n",
    "        data = json.load(open(file, \"r\"))\n",
    "        output_length_metrics(data)\n",
    "    #     print(file)\n",
    "    #     output_metrics(file, attribute)\n",
    "    #     print(\"\\n---------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "./../inference_results//topic_evaluate_on_topic_1.json topic\n",
      "Relative Score:  0.4219870071684589\n",
      "Absolute Score:  0.6653785842293907\n",
      "./../inference_results//topic_evaluate_on_topic_500.json topic\n",
      "Relative Score:  0.6092629928315412\n",
      "Absolute Score:  0.38502464157706096\n",
      "./../inference_results//topic_evaluate_on_topic_final.json topic\n",
      "Relative Score:  0.6560259856630825\n",
      "Absolute Score:  0.3842965949820789\n"
     ]
    }
   ],
   "source": [
    "dirname = \"./../inference_results//\"\n",
    "files = [os.path.join(dirname, f) for f in os.listdir(dirname) if os.path.isfile(os.path.join(dirname, f))]\n",
    "files = [(file, get_evaluation_attribute(file)) for file in files]\n",
    "print(len(files))\n",
    "for file, attribute in files:\n",
    "    if attribute == 'topic':\n",
    "        print(file, attribute)\n",
    "        data = json.load(open(file, \"r\"))\n",
    "        output_topic_metrics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "./../inference_results/specificity_evaluate_on_specificity_full.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/455 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 299.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47943345626659184\n",
      "Prediction Specificity : 4.556125868336754\n",
      "Gold Specificity : 4.722160403844076\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 371.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5246252817679886\n",
      "Prediction Specificity : 4.997395833333333\n",
      "Gold Specificity : 5.031629464285714\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 315.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.4851607371222142\n",
      "Overall Prediction Specificity : 4.61204919063335\n",
      "Overall Gold Specificity : 4.761380245167371\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_1200.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 320.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.4788574048744652\n",
      "Prediction Specificity : 4.699338713113883\n",
      "Gold Specificity : 4.700455417066154\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 399.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.43169712308018676\n",
      "Prediction Specificity : 4.725128205128205\n",
      "Gold Specificity : 5.0526813186813175\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 322.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.47287025972480073\n",
      "Overall Prediction Specificity : 4.702612769717266\n",
      "Overall Gold Specificity : 4.745171595982138\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 318.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.4788574048744652\n",
      "Prediction Specificity : 4.699338713113883\n",
      "Gold Specificity : 4.700455417066154\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 393.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.43169712308018676\n",
      "Prediction Specificity : 4.725128205128205\n",
      "Gold Specificity : 5.0526813186813175\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 328.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.47287025972480073\n",
      "Overall Prediction Specificity : 4.702612769717266\n",
      "Overall Gold Specificity : 4.745171595982138\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_600.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 304.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47450939855409546\n",
      "Prediction Specificity : 4.818628066378062\n",
      "Gold Specificity : 4.7173134920634885\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 359.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.42769156639762734\n",
      "Prediction Specificity : 4.112121212121211\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 312.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.4685210711852447\n",
      "Overall Prediction Specificity : 4.728260910601021\n",
      "Overall Gold Specificity : 4.759719684385378\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 304.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47450939855409546\n",
      "Prediction Specificity : 4.818628066378062\n",
      "Gold Specificity : 4.7173134920634885\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 361.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.42769156639762734\n",
      "Prediction Specificity : 4.112121212121211\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 308.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.4685210711852447\n",
      "Overall Prediction Specificity : 4.728260910601021\n",
      "Overall Gold Specificity : 4.759719684385378\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 305.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47450939855409546\n",
      "Prediction Specificity : 4.818628066378062\n",
      "Gold Specificity : 4.7173134920634885\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 360.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.42769156639762734\n",
      "Prediction Specificity : 4.112121212121211\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 309.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.4685210711852447\n",
      "Overall Prediction Specificity : 4.728260910601021\n",
      "Overall Gold Specificity : 4.759719684385378\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 305.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47450939855409546\n",
      "Prediction Specificity : 4.818628066378062\n",
      "Gold Specificity : 4.7173134920634885\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 360.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.42769156639762734\n",
      "Prediction Specificity : 4.112121212121211\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 312.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.4685210711852447\n",
      "Overall Prediction Specificity : 4.728260910601021\n",
      "Overall Gold Specificity : 4.759719684385378\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 304.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47450939855409546\n",
      "Prediction Specificity : 4.818628066378062\n",
      "Gold Specificity : 4.7173134920634885\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 364.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.42769156639762734\n",
      "Prediction Specificity : 4.112121212121211\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 311.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.4685210711852447\n",
      "Overall Prediction Specificity : 4.728260910601021\n",
      "Overall Gold Specificity : 4.759719684385378\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_1600.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 313.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.48023051283947593\n",
      "Prediction Specificity : 4.6490665584415565\n",
      "Gold Specificity : 4.710888798701298\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 339.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.43098574258304617\n",
      "Prediction Specificity : 4.488008547008548\n",
      "Gold Specificity : 5.048065934065933\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 315.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.47389207706389597\n",
      "Overall Prediction Specificity : 4.62833631934622\n",
      "Overall Gold Specificity : 4.754287835926445\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_1800.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 320.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5274671445907735\n",
      "Prediction Specificity : 4.860406993389751\n",
      "Gold Specificity : 4.717372468527639\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 323.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5524809358577395\n",
      "Prediction Specificity : 4.4089890109890115\n",
      "Gold Specificity : 5.048065934065933\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 322.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.530718937455479\n",
      "Overall Prediction Specificity : 4.8017226556776516\n",
      "Overall Gold Specificity : 4.760362619047615\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 321.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5274671445907735\n",
      "Prediction Specificity : 4.860406993389751\n",
      "Gold Specificity : 4.717372468527639\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 321.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5524809358577395\n",
      "Prediction Specificity : 4.4089890109890115\n",
      "Gold Specificity : 5.048065934065933\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 320.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.530718937455479\n",
      "Overall Prediction Specificity : 4.8017226556776516\n",
      "Overall Gold Specificity : 4.760362619047615\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_200.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:02<00:00, 158.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5529236282471223\n",
      "Prediction Specificity : 5.937957227138646\n",
      "Gold Specificity : 4.721292930889166\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 165.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5431764360285314\n",
      "Prediction Specificity : 6.125844155844157\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:03<00:00, 159.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5516817080030547\n",
      "Overall Prediction Specificity : 5.961896488325063\n",
      "Overall Gold Specificity : 4.763028359992641\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:02<00:00, 157.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5529236282471223\n",
      "Prediction Specificity : 5.937957227138646\n",
      "Gold Specificity : 4.721292930889166\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 164.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5431764360285314\n",
      "Prediction Specificity : 6.125844155844157\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:03<00:00, 159.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5516817080030547\n",
      "Overall Prediction Specificity : 5.961896488325063\n",
      "Overall Gold Specificity : 4.763028359992641\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_400.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 285.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5102400782608535\n",
      "Prediction Specificity : 4.611256496698978\n",
      "Gold Specificity : 4.7213877475769035\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 304.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47887533023653345\n",
      "Prediction Specificity : 4.4779279609279605\n",
      "Gold Specificity : 5.018835164835164\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 289.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5062967346988019\n",
      "Overall Prediction Specificity : 4.594493721408613\n",
      "Overall Gold Specificity : 4.75878442479506\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 285.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5102400782608535\n",
      "Prediction Specificity : 4.611256496698978\n",
      "Gold Specificity : 4.7213877475769035\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 306.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47887533023653345\n",
      "Prediction Specificity : 4.4779279609279605\n",
      "Gold Specificity : 5.018835164835164\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 288.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5062967346988019\n",
      "Overall Prediction Specificity : 4.594493721408613\n",
      "Overall Gold Specificity : 4.75878442479506\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 271.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5102400782608535\n",
      "Prediction Specificity : 4.611256496698978\n",
      "Gold Specificity : 4.7213877475769035\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 296.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47887533023653345\n",
      "Prediction Specificity : 4.4779279609279605\n",
      "Gold Specificity : 5.018835164835164\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 280.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5062967346988019\n",
      "Overall Prediction Specificity : 4.594493721408613\n",
      "Overall Gold Specificity : 4.75878442479506\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 283.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5102400782608535\n",
      "Prediction Specificity : 4.611256496698978\n",
      "Gold Specificity : 4.7213877475769035\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 304.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47887533023653345\n",
      "Prediction Specificity : 4.4779279609279605\n",
      "Gold Specificity : 5.018835164835164\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 286.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5062967346988019\n",
      "Overall Prediction Specificity : 4.594493721408613\n",
      "Overall Gold Specificity : 4.75878442479506\n",
      "\n",
      "\n",
      "\n",
      "./../inference_results/specificity_evaluate_on_specificity_800.json specificity\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 296.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5539802798460222\n",
      "Prediction Specificity : 4.96312838052816\n",
      "Gold Specificity : 4.713640099692436\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 318.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47740823391485626\n",
      "Prediction Specificity : 4.947947330447331\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 299.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5441671632800865\n",
      "Overall Prediction Specificity : 4.961182847896441\n",
      "Overall Gold Specificity : 4.75659939898289\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 293.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5539802798460222\n",
      "Prediction Specificity : 4.96312838052816\n",
      "Gold Specificity : 4.713640099692436\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 313.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47740823391485626\n",
      "Prediction Specificity : 4.947947330447331\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 300.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5441671632800865\n",
      "Overall Prediction Specificity : 4.961182847896441\n",
      "Overall Gold Specificity : 4.75659939898289\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 296.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5539802798460222\n",
      "Prediction Specificity : 4.96312838052816\n",
      "Gold Specificity : 4.713640099692436\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 322.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47740823391485626\n",
      "Prediction Specificity : 4.947947330447331\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 298.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5441671632800865\n",
      "Overall Prediction Specificity : 4.961182847896441\n",
      "Overall Gold Specificity : 4.75659939898289\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['normal', 'high'])\n",
      "control key  normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455/455 [00:01<00:00, 295.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.5539802798460222\n",
      "Prediction Specificity : 4.96312838052816\n",
      "Gold Specificity : 4.713640099692436\n",
      "\n",
      "--\n",
      "control key  high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:00<00:00, 317.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER :  0.47740823391485626\n",
      "Prediction Specificity : 4.947947330447331\n",
      "Gold Specificity : 5.048852813852813\n",
      "\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 521/521 [00:01<00:00, 297.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall CER :  0.5441671632800865\n",
      "Overall Prediction Specificity : 4.961182847896441\n",
      "Overall Gold Specificity : 4.75659939898289\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dirname = \"./../inference_results/\"\n",
    "files = [os.path.join(dirname, f) for f in os.listdir(dirname) if os.path.isfile(os.path.join(dirname, f))]\n",
    "files = [(file, get_evaluation_attribute(file)) for file in files]\n",
    "print(len(files))\n",
    "for file, attribute in files:\n",
    "    if attribute == 'specificity':\n",
    "        print(file, attribute)\n",
    "        data = json.load(open(file, \"r\"))\n",
    "    output_specificity_metrics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
