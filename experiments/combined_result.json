{"/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-1000_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.338467705242593, "prediction_coverage": 0.8442345546176068, "prediction_overlap": 0.349811755781676, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.3741697107465416, "prediction_f_score": 0.2520727777777778, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.607843137254902, "prediction_coverage": 0.8235294117647058, "prediction_overlap": 0.3049645390070922, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8107779358580318, "prediction_f_score": 0.17423, "gold_f_score": 0.92077}, "overall_cer": 1.3178305332576907, "overall_prediction_f_score": 0.24428850000000005, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-1200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.4591801586558266, "prediction_coverage": 0.8177618753911909, "prediction_overlap": 0.3419109494348398, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.1698580787317525, "prediction_f_score": 0.22833444444444448, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 3.375, "prediction_coverage": 0.9583333333333334, "prediction_overlap": 0.4782608695652174, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.5633545836636727, "prediction_f_score": 0.40205, "gold_f_score": 0.92077}, "overall_cer": 1.1092077292249445, "overall_prediction_f_score": 0.24570599999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-1400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.178592461386126, "prediction_coverage": 0.8338456116560968, "prediction_overlap": 0.36817739560951723, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.137248519417046, "prediction_f_score": 0.3068988888888889, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.675, "prediction_coverage": 0.925, "prediction_overlap": 0.3333333333333333, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7621935988357571, "prediction_f_score": 0.218965, "gold_f_score": 0.92077}, "overall_cer": 1.0997430273589173, "overall_prediction_f_score": 0.2981055, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-1600_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 7.103139841078067, "prediction_coverage": 0.8435390882344592, "prediction_overlap": 0.414242439031232, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.4274013106173526, "prediction_f_score": 0.33299944444444446, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.2564102564102564, "prediction_coverage": 0.8205128205128205, "prediction_overlap": 0.3157894736842105, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.6667788915798734, "prediction_f_score": 0.30682, "gold_f_score": 0.92077}, "overall_cer": 1.3513390687136047, "overall_prediction_f_score": 0.3303815, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-1800_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.3295661550226954, "prediction_coverage": 0.7871508138649163, "prediction_overlap": 0.32972763288193807, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 2.1797723936991846, "prediction_f_score": 0.2733211111111111, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.0, "prediction_coverage": 1.0, "prediction_overlap": 1.0, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 1.0, "prediction_f_score": 0.0, "gold_f_score": 0.92077}, "overall_cer": 2.0617951543292663, "overall_prediction_f_score": 0.245989, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-2000_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.7194921782329358, "prediction_coverage": 0.8269483671750538, "prediction_overlap": 0.4016545577115554, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 2.021710943806553, "prediction_f_score": 0.31864722222222225, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 5.071428571428571, "prediction_coverage": 0.8571428571428571, "prediction_overlap": 0.48148148148148145, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.5169803533998718, "prediction_f_score": 0.44475, "gold_f_score": 0.92077}, "overall_cer": 1.871237884765885, "overall_prediction_f_score": 0.33125750000000004, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.2002575340624793, "prediction_coverage": 0.7629001548299769, "prediction_overlap": 0.2979013590627212, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.5218446393208206, "prediction_f_score": 0.24944777777777777, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.5120481927710843, "prediction_coverage": 0.7771084337349398, "prediction_overlap": 0.21153846153846154, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.861137960619916, "prediction_f_score": 0.12786, "gold_f_score": 0.92077}, "overall_cer": 0.5557739714507303, "overall_prediction_f_score": 0.237289, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-2200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.097611914697095, "prediction_coverage": 0.8009837952273159, "prediction_overlap": 0.35467970230000007, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.3114071685680815, "prediction_f_score": 0.2259005555555556, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.2, "prediction_coverage": 0.8, "prediction_overlap": 0.20689655172413793, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8913952452838385, "prediction_f_score": 0.1, "gold_f_score": 0.92077}, "overall_cer": 1.2694059762396572, "overall_prediction_f_score": 0.21331050000000004, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-2400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 3.1868649340128767, "prediction_coverage": 0.8673247432392941, "prediction_overlap": 0.3842329865039936, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 2.4855781143244116, "prediction_f_score": 0.3327177777777777, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.3225806451612903, "prediction_coverage": 0.8064516129032258, "prediction_overlap": 0.3, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8406333829295046, "prediction_f_score": 0.14674, "gold_f_score": 0.92077}, "overall_cer": 2.321083641184921, "overall_prediction_f_score": 0.31412, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.9722867606116925, "prediction_coverage": 0.7924085199148974, "prediction_overlap": 0.29212902298558463, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.4750829108865849, "prediction_f_score": 0.20683777777777776, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.051282051282051, "prediction_coverage": 0.8717948717948718, "prediction_overlap": 0.36936936936936937, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7780553232620524, "prediction_f_score": 0.20436, "gold_f_score": 0.92077}, "overall_cer": 0.5053801521241317, "overall_prediction_f_score": 0.20659, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-600_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.5025885205165272, "prediction_coverage": 0.7653491247625838, "prediction_overlap": 0.2331641282776547, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.0650114237258237, "prediction_f_score": 0.16418833333333335, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.1818181818181819, "prediction_coverage": 0.8181818181818182, "prediction_overlap": 0.19047619047619047, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8913952452838385, "prediction_f_score": 0.1, "gold_f_score": 0.92077}, "overall_cer": 1.0476498058816253, "overall_prediction_f_score": 0.15776950000000003, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_checkpoint-800_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 5.674763792575768, "prediction_coverage": 0.8492793220437703, "prediction_overlap": 0.41163593310013963, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.428799927503682, "prediction_f_score": 0.34318333333333334, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.1346153846153846, "prediction_coverage": 0.8942307692307693, "prediction_overlap": 0.35106382978723405, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.777756660186583, "prediction_f_score": 0.20463499999999998, "gold_f_score": 0.92077}, "overall_cer": 1.363695600771972, "overall_prediction_f_score": 0.3293285, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0001_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 3.173876250885305, "prediction_coverage": 0.8556220683421747, "prediction_overlap": 0.38369242509235607, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 2.4898204170416083, "prediction_f_score": 0.33091944444444443, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.3225806451612903, "prediction_coverage": 0.8064516129032258, "prediction_overlap": 0.3, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8406333829295046, "prediction_f_score": 0.14674, "gold_f_score": 0.92077}, "overall_cer": 2.324901713630398, "overall_prediction_f_score": 0.31250150000000004, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-1000_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.8719808914232976, "prediction_coverage": 0.7905997142240722, "prediction_overlap": 0.32021511447255124, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.4120472296298245, "prediction_f_score": 0.25613055555555553, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.5806451612903225, "prediction_coverage": 0.9032258064516129, "prediction_overlap": 0.36666666666666664, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.6861051076816144, "prediction_f_score": 0.289025, "gold_f_score": 0.92077}, "overall_cer": 1.3394530174350034, "overall_prediction_f_score": 0.25941999999999993, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-1200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.8221840251473695, "prediction_coverage": 0.8106514204866114, "prediction_overlap": 0.29350588829939867, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.8054383949968316, "prediction_f_score": 0.22860944444444442, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.2352941176470589, "prediction_coverage": 0.7647058823529411, "prediction_overlap": 0.28125, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.849533542578494, "prediction_f_score": 0.138545, "gold_f_score": 0.92077}, "overall_cer": 0.8098479097549978, "overall_prediction_f_score": 0.21960299999999994, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-1400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.5143679285226461, "prediction_coverage": 0.7738137173764872, "prediction_overlap": 0.2503290798735599, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.1999531950362898, "prediction_f_score": 0.17004944444444448, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 0.8571428571428571, "prediction_coverage": 0.6428571428571429, "prediction_overlap": 0.1111111111111111, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.9773721993548877, "prediction_f_score": 0.020835, "gold_f_score": 0.92077}, "overall_cer": 1.1776950954681495, "overall_prediction_f_score": 0.15512800000000002, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-1600_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.1639860870124028, "prediction_coverage": 0.7281414897642967, "prediction_overlap": 0.23378615743793393, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.6309410437275702, "prediction_f_score": 0.15538888888888885, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.0909090909090908, "prediction_coverage": 0.7272727272727273, "prediction_overlap": 0.2, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.879329257034873, "prediction_f_score": 0.11111, "gold_f_score": 0.92077}, "overall_cer": 1.5557798650583006, "overall_prediction_f_score": 0.15096099999999996, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-1800_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.5184892753313806, "prediction_coverage": 0.7930978209925578, "prediction_overlap": 0.31201783410682676, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.666537952194139, "prediction_f_score": 0.26667555555555555, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.0357142857142858, "prediction_coverage": 0.6071428571428571, "prediction_overlap": 0.25925925925925924, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.9094942276572868, "prediction_f_score": 0.083335, "gold_f_score": 0.92077}, "overall_cer": 1.5908335797404538, "overall_prediction_f_score": 0.2483415, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-2000_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.3219727355365278, "prediction_coverage": 0.76823454027059, "prediction_overlap": 0.25568686559398635, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.8865556182108217, "prediction_f_score": 0.17080833333333334, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 0.8275862068965517, "prediction_coverage": 0.6206896551724138, "prediction_overlap": 0.1111111111111111, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.9195510279440033, "prediction_f_score": 0.074075, "gold_f_score": 0.92077}, "overall_cer": 0.8898551591841402, "overall_prediction_f_score": 0.16113500000000003, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.201219997780788, "prediction_coverage": 0.7874165180776839, "prediction_overlap": 0.3533560916801807, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.9713126827410523, "prediction_f_score": 0.27363333333333334, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.6761904761904762, "prediction_coverage": 0.8380952380952381, "prediction_overlap": 0.2647058823529412, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8320373165937205, "prediction_f_score": 0.154655, "gold_f_score": 0.92077}, "overall_cer": 0.9573851461263192, "overall_prediction_f_score": 0.2617355, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-2200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.4066406022350653, "prediction_coverage": 0.7686993726351756, "prediction_overlap": 0.26331969425602547, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.573498757601273, "prediction_f_score": 0.172105, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.3636363636363638, "prediction_coverage": 0.9090909090909091, "prediction_overlap": 0.6, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.5054628191622229, "prediction_f_score": 0.455355, "gold_f_score": 0.92077}, "overall_cer": 1.4666951637573677, "overall_prediction_f_score": 0.20042999999999997, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-2400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 3.620061168246286, "prediction_coverage": 0.8593381602153531, "prediction_overlap": 0.47191603368073953, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 2.5248363421349875, "prediction_f_score": 0.3731500000000001, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.754385964912281, "prediction_coverage": 0.7894736842105263, "prediction_overlap": 0.38181818181818183, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.6421364727347764, "prediction_f_score": 0.32950999999999997, "gold_f_score": 0.92077}, "overall_cer": 2.3365663551949662, "overall_prediction_f_score": 0.36878600000000006, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.33315838880355, "prediction_coverage": 0.7415132854216955, "prediction_overlap": 0.3536180511755224, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.4312894096250022, "prediction_f_score": 0.2580672222222222, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 0.0, "prediction_coverage": 0.0, "prediction_overlap": 0.0, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 1.0, "prediction_f_score": 0.0, "gold_f_score": 0.92077}, "overall_cer": 1.388160468662502, "overall_prediction_f_score": 0.23226050000000004, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-600_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.3454095203098453, "prediction_coverage": 0.7891058849777202, "prediction_overlap": 0.23855688768809338, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.8972096393455021, "prediction_f_score": 0.15779833333333332, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.1607142857142858, "prediction_coverage": 0.7678571428571429, "prediction_overlap": 0.18867924528301888, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8557022926463721, "prediction_f_score": 0.132865, "gold_f_score": 0.92077}, "overall_cer": 0.8930589046755891, "overall_prediction_f_score": 0.15530499999999997, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_checkpoint-800_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.674911981599555, "prediction_coverage": 0.853503513617454, "prediction_overlap": 0.35879570458939997, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 1.771801071817887, "prediction_f_score": 0.25895944444444446, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.1818181818181817, "prediction_coverage": 0.7272727272727273, "prediction_overlap": 0.3333333333333333, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.6725892459571879, "prediction_f_score": 0.30147, "gold_f_score": 0.92077}, "overall_cer": 1.6618798892318167, "overall_prediction_f_score": 0.2632105, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_0.0006_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 3.2991458796856716, "prediction_coverage": 0.8258302500938007, "prediction_overlap": 0.38393002166587076, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 2.2677005867157303, "prediction_f_score": 0.28435666666666665, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.6521739130434783, "prediction_coverage": 0.782608695652174, "prediction_overlap": 0.3181818181818182, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7681831510583533, "prediction_f_score": 0.21345, "gold_f_score": 0.92077}, "overall_cer": 2.1177488431499922, "overall_prediction_f_score": 0.277266, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-1000_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.184942756524357, "prediction_coverage": 0.7856301824490953, "prediction_overlap": 0.31952470158793, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.74435517557791, "prediction_f_score": 0.2367038888888889, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.7673267326732673, "prediction_coverage": 0.8366336633663366, "prediction_overlap": 0.2608695652173913, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.82820356875224, "prediction_f_score": 0.15818500000000002, "gold_f_score": 0.92077}, "overall_cer": 0.752740014895343, "overall_prediction_f_score": 0.228852, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-1200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.86658630217669, "prediction_coverage": 0.7884446359819482, "prediction_overlap": 0.31149550768478135, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.5493208093888395, "prediction_f_score": 0.22169000000000003, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.7673267326732673, "prediction_coverage": 0.8366336633663366, "prediction_overlap": 0.2608695652173913, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.82820356875224, "prediction_f_score": 0.15818500000000002, "gold_f_score": 0.92077}, "overall_cer": 0.5772090853251796, "overall_prediction_f_score": 0.21533950000000002, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-1400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.9415983938829657, "prediction_coverage": 0.7734251035814648, "prediction_overlap": 0.2917792571248405, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.6383507431617146, "prediction_f_score": 0.21199166666666666, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.3066666666666666, "prediction_coverage": 0.7466666666666667, "prediction_overlap": 0.176056338028169, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.876950812906589, "prediction_f_score": 0.1133, "gold_f_score": 0.92077}, "overall_cer": 0.662210750136202, "overall_prediction_f_score": 0.20212249999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-1600_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.1385269054523683, "prediction_coverage": 0.7806563902439904, "prediction_overlap": 0.28734523657469996, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.7551032719336835, "prediction_f_score": 0.22221444444444444, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.3869346733668342, "prediction_coverage": 0.7839195979899497, "prediction_overlap": 0.19889502762430938, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.8791935010914778, "prediction_f_score": 0.111235, "gold_f_score": 0.92077}, "overall_cer": 0.7675122948494628, "overall_prediction_f_score": 0.21111649999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-1800_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.1157046293632806, "prediction_coverage": 0.7783393104400124, "prediction_overlap": 0.2838006149842241, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.6829725888648913, "prediction_f_score": 0.22061277777777777, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.6490066225165563, "prediction_coverage": 0.7880794701986755, "prediction_overlap": 0.28169014084507044, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.824353530197552, "prediction_f_score": 0.16172999999999998, "gold_f_score": 0.92077}, "overall_cer": 0.6971106829981574, "overall_prediction_f_score": 0.21472449999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-2000_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.4894772261574736, "prediction_coverage": 0.8065214622583081, "prediction_overlap": 0.32390987563664414, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.722767113452329, "prediction_f_score": 0.26274666666666663, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.051282051282051, "prediction_coverage": 0.8717948717948718, "prediction_overlap": 0.36936936936936937, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7780553232620524, "prediction_f_score": 0.20436, "gold_f_score": 0.92077}, "overall_cer": 0.7282959344333013, "overall_prediction_f_score": 0.256908, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.4324839802314695, "prediction_coverage": 0.7531831746759434, "prediction_overlap": 0.24894729749462918, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.2778581185188729, "prediction_f_score": 0.18897833333333336, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.113095238095238, "prediction_coverage": 0.8869047619047619, "prediction_overlap": 0.33557046979865773, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7726359460017159, "prediction_f_score": 0.20934999999999998, "gold_f_score": 0.92077}, "overall_cer": 0.32733590126715717, "overall_prediction_f_score": 0.1910155, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-2200_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.000180723658075, "prediction_coverage": 0.7792776662269829, "prediction_overlap": 0.2895365163232429, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.6862955346795606, "prediction_f_score": 0.215645, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.051282051282051, "prediction_coverage": 0.8717948717948718, "prediction_overlap": 0.36936936936936937, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7780553232620524, "prediction_f_score": 0.20436, "gold_f_score": 0.92077}, "overall_cer": 0.6954715135378098, "overall_prediction_f_score": 0.2145165, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-2400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.8334036985368114, "prediction_coverage": 0.790697943796479, "prediction_overlap": 0.27035153606212864, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.532430312334329, "prediction_f_score": 0.20732555555555557, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.051282051282051, "prediction_coverage": 0.8717948717948718, "prediction_overlap": 0.36936936936936937, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7780553232620524, "prediction_f_score": 0.20436, "gold_f_score": 0.92077}, "overall_cer": 0.5569928134271013, "overall_prediction_f_score": 0.207029, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-400_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.7229098884919332, "prediction_coverage": 0.7562623303067225, "prediction_overlap": 0.248147004541267, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.5321853239916475, "prediction_f_score": 0.1651372222222222, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.984732824427481, "prediction_coverage": 0.8244274809160306, "prediction_overlap": 0.319672131147541, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.761770040292364, "prediction_f_score": 0.21935500000000002, "gold_f_score": 0.92077}, "overall_cer": 0.5551437956217191, "overall_prediction_f_score": 0.17055900000000002, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-600_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 3.0781882190300296, "prediction_coverage": 0.7386410315421992, "prediction_overlap": 0.24939770623604401, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.7185477636669836, "prediction_f_score": 0.1690311111111111, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.1176470588235294, "prediction_coverage": 0.7647058823529411, "prediction_overlap": 0.21212121212121213, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.849533542578494, "prediction_f_score": 0.138545, "gold_f_score": 0.92077}, "overall_cer": 0.7316463415581347, "overall_prediction_f_score": 0.16598249999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_checkpoint-800_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 1.7318852614689553, "prediction_coverage": 0.7649410891480122, "prediction_overlap": 0.2594639610084674, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.4952273834568001, "prediction_f_score": 0.1701261111111111, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 1.1176470588235294, "prediction_coverage": 0.7647058823529411, "prediction_overlap": 0.21212121212121213, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.849533542578494, "prediction_f_score": 0.138545, "gold_f_score": 0.92077}, "overall_cer": 0.5306579993689695, "overall_prediction_f_score": 0.16696799999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/extractiveness_extractiveness_1e-05_extractiveness.json": {"result": {"normal": {"num_examples": 9, "prediction_density": 2.153622203800463, "prediction_coverage": 0.7991726437733457, "prediction_overlap": 0.3168520690149775, "reference_density": 1.8825514404072257, "reference_coverage": 0.8303323431856967, "reference_overlap": 0.2942774667706603, "cer": 0.7578810759106869, "prediction_f_score": 0.24918444444444443, "gold_f_score": 0.21289055555555556}, "fully": {"num_examples": 1, "prediction_density": 2.051282051282051, "prediction_coverage": 0.8717948717948718, "prediction_overlap": 0.36936936936936937, "reference_density": 7.266666666666667, "reference_coverage": 0.9333333333333333, "reference_overlap": 0.8275862068965517, "cer": 0.7780553232620524, "prediction_f_score": 0.20436, "gold_f_score": 0.92077}, "overall_cer": 0.7598985006458234, "overall_prediction_f_score": 0.24470199999999998, "overall_gold_f_score": 0.2836785}, "attribute": "extractiveness"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-1000_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-1200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-1400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-1600_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-1800_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-2000_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-2200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-2400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-600_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_checkpoint-800_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0001_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-1000_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-1200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-1400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-1600_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-1800_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-2000_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-2200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-2400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-600_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_checkpoint-800_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_0.0006_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-1000_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-1200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-1400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-1600_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-1800_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-2000_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-2200_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-2400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-400_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-600_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_checkpoint-800_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/length_length_1e-05_length.json": {"result": null, "attribute": "length"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-1000_specificity.json": {"result": {"normal": {"cer": 0.2878085966458606, "prediction_specificity": 3.9599206349206355, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.0, "prediction_specificity": 6.1, "gold_specificity": 6.1}, "overall_cer": 0.25902773698127457, "overall_prediction_specificity": 4.173928571428571, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-1200_specificity.json": {"result": {"normal": {"cer": 0.43968720589226074, "prediction_specificity": 3.7749999999999995, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.0928961748633878, "prediction_specificity": 5.533333333333334, "gold_specificity": 6.1}, "overall_cer": 0.4050081027893735, "overall_prediction_specificity": 3.950833333333333, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-1400_specificity.json": {"result": {"normal": {"cer": 0.3338568697757408, "prediction_specificity": 3.571913580246914, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.4043715846994535, "prediction_specificity": 3.6333333333333333, "gold_specificity": 6.1}, "overall_cer": 0.3409083412681121, "overall_prediction_specificity": 3.5780555555555553, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-1600_specificity.json": {"result": {"normal": {"cer": 0.6336286371783912, "prediction_specificity": 5.580555555555556, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.43442622950819665, "prediction_specificity": 3.45, "gold_specificity": 6.1}, "overall_cer": 0.6137083964113718, "overall_prediction_specificity": 5.367500000000001, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-1800_specificity.json": {"result": {"normal": {"cer": 0.49480819742946924, "prediction_specificity": 5.6023148148148145, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.7377049180327869, "prediction_specificity": 1.6, "gold_specificity": 6.1}, "overall_cer": 0.5190978694898011, "overall_prediction_specificity": 5.202083333333333, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-2000_specificity.json": {"result": {"normal": {"cer": 0.49339700248073637, "prediction_specificity": 3.9962962962962965, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.36065573770491793, "prediction_specificity": 3.9000000000000004, "gold_specificity": 6.1}, "overall_cer": 0.4801228760031545, "overall_prediction_specificity": 3.986666666666667, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-200_specificity.json": {"result": {"normal": {"cer": 0.7821121393601733, "prediction_specificity": 8.258439153439154, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.2766393442622951, "prediction_specificity": 4.4125, "gold_specificity": 6.1}, "overall_cer": 0.7315648598503854, "overall_prediction_specificity": 7.873845238095238, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-2200_specificity.json": {"result": {"normal": {"cer": 0.4817753148636027, "prediction_specificity": 4.757407407407408, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.3497267759562841, "prediction_specificity": 3.966666666666667, "gold_specificity": 6.1}, "overall_cer": 0.46857046097287086, "overall_prediction_specificity": 4.678333333333334, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-2400_specificity.json": {"result": {"normal": {"cer": 0.6357112074821543, "prediction_specificity": 3.9101851851851848, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.6229508196721312, "prediction_specificity": 2.3, "gold_specificity": 6.1}, "overall_cer": 0.6344351687011519, "overall_prediction_specificity": 3.749166666666666, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-400_specificity.json": {"result": {"normal": {"cer": 0.2970203410475444, "prediction_specificity": 5.197222222222222, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.049180327868852285, "prediction_specificity": 5.800000000000001, "gold_specificity": 6.1}, "overall_cer": 0.27223633972967515, "overall_prediction_specificity": 5.2575, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-600_specificity.json": {"result": {"normal": {"cer": 0.3271336404176244, "prediction_specificity": 4.552604166666668, "gold_specificity": 5.687083333333334}, "high": {"cer": 0.09836065573770515, "prediction_specificity": 6.700000000000001, "gold_specificity": 6.1}, "overall_cer": 0.30171441989763337, "overall_prediction_specificity": 4.7912037037037045, "overall_gold_specificity": 5.732962962962963}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_checkpoint-800_specificity.json": {"result": {"normal": {"cer": 0.4125273487168517, "prediction_specificity": 4.562808641975308, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.17486338797814205, "prediction_specificity": 5.033333333333333, "gold_specificity": 6.1}, "overall_cer": 0.3887609526429808, "overall_prediction_specificity": 4.609861111111111, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/specificity_0.0006_specificity.json": {"result": {"normal": {"cer": 0.5279728905321243, "prediction_specificity": 4.4531481481481485, "gold_specificity": 5.57462962962963}, "high": {"cer": 0.368107302533532, "prediction_specificity": 3.8545454545454545, "gold_specificity": 6.1}, "overall_cer": 0.511986331732265, "overall_prediction_specificity": 4.393287878787879, "overall_gold_specificity": 5.627166666666667}, "attribute": "specificity"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_checkpoint-1000_topic.json": {"result": {"relative_score": 0.45, "abs_score": 0.55, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_checkpoint-1200_topic.json": {"result": {"relative_score": 0.6666666666666667, "abs_score": 0.3333333333333333, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_checkpoint-200_topic.json": {"result": {"relative_score": 0.33333333333333337, "abs_score": 0.6666666666666666, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_checkpoint-400_topic.json": {"result": {"relative_score": 0.3, "abs_score": 0.7, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_checkpoint-600_topic.json": {"result": {"relative_score": 0.5, "abs_score": 0.5, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_checkpoint-800_topic.json": {"result": {"relative_score": 0.425, "abs_score": 0.575, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0001_topic.json": {"result": {"relative_score": 0.5916666666666667, "abs_score": 0.4083333333333333, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_checkpoint-1000_topic.json": {"result": {"relative_score": 0.675, "abs_score": 0.325, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_checkpoint-1200_topic.json": {"result": {"relative_score": 0.425, "abs_score": 0.575, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_checkpoint-200_topic.json": {"result": {"relative_score": 0.425, "abs_score": 0.575, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_checkpoint-400_topic.json": {"result": {"relative_score": 0.4833333333333334, "abs_score": 0.5166666666666666, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_checkpoint-600_topic.json": {"result": {"relative_score": 0.7666666666666667, "abs_score": 0.2333333333333333, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_checkpoint-800_topic.json": {"result": {"relative_score": 0.65, "abs_score": 0.35, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_0.0006_topic.json": {"result": {"relative_score": 0.5, "abs_score": 0.5, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_checkpoint-1000_topic.json": {"result": {"relative_score": 0.4333333333333334, "abs_score": 0.5666666666666667, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_checkpoint-1200_topic.json": {"result": {"relative_score": 0.4333333333333334, "abs_score": 0.5666666666666667, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_checkpoint-200_topic.json": {"result": {"relative_score": 0.2, "abs_score": 0.8, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_checkpoint-400_topic.json": {"result": {"relative_score": 0.33333333333333337, "abs_score": 0.6666666666666666, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_checkpoint-600_topic.json": {"result": {"relative_score": 0.25833333333333336, "abs_score": 0.7416666666666666, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_checkpoint-800_topic.json": {"result": {"relative_score": 0.33333333333333337, "abs_score": 0.6666666666666666, "abs_gold_score": 1.0}, "attribute": "topic"}, "/scratch/tathagato/experiment_outputs/topic_topic_1e-05_topic.json": {"result": {"relative_score": 0.4333333333333334, "abs_score": 0.5666666666666667, "abs_gold_score": 1.0}, "attribute": "topic"}}