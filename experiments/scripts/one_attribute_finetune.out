Activating Conda Environment Virtual Environment
running script
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-05-25 03:03:38 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:03:38 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0005,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/tathagato/adapter_experiments/length_then_topic/runs/May25_03-03-38_gnode081,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=20,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/tathagato/adapter_experiments/length_then_topic,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/tathagato/adapter_experiments/length_then_topic,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=400,
save_strategy=steps,
save_total_limit=400,
seed=0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
2024-05-25 03:03:38 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'q_proj', 'o_proj', 'k_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
2024-05-25 03:03:38 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:03:38 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:03:38 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1 distributed training: True, 16-bits training: True
[WARNING|modeling_utils.py:3058] 2024-05-25 03:03:39,362 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|configuration_utils.py:726] 2024-05-25 03:03:39,433 >> loading configuration file config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:03:39,437 >> Model config LlamaConfig {
  "_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": false,
  "vocab_size": 32000
}

[INFO|quantizer_bnb_4bit.py:247] 2024-05-25 03:03:39,537 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[WARNING|modeling_utils.py:3058] 2024-05-25 03:03:39,537 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:3283] 2024-05-25 03:03:39,537 >> loading weights file model.safetensors from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors
[INFO|modeling_utils.py:1417] 2024-05-25 03:03:39,555 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:928] 2024-05-25 03:03:39,557 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[WARNING|modeling_utils.py:3058] 2024-05-25 03:03:39,659 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 03:03:39,683 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:4024] 2024-05-25 03:03:42,390 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-05-25 03:03:42,391 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-05-25 03:03:42,634 >> loading configuration file generation_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json
[INFO|configuration_utils.py:928] 2024-05-25 03:03:42,635 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:03:43,060 >> loading file tokenizer.model from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:03:43,060 >> loading file tokenizer.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:03:43,060 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:03:43,060 >> loading file special_tokens_map.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:03:43,060 >> loading file tokenizer_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json
loading model from : /scratch/tathagato/adapter_experiments/length/length
loading model from : /scratch/tathagato/adapter_experiments/length/length
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
loading model from : /scratch/tathagato/adapter_experiments/length/length
loading model from : /scratch/tathagato/adapter_experiments/length/length
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
train dataset size 2013
test dataset size 272
2013
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
Spawning 10 processes
2024-05-25 03:03:45 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<22:30,  1.49 examples/s]trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:00<00:06, 274.56 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 451.15 examples/s]train dataset size 2013
test dataset size 272
2013
Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 580.41 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 642.36 examples/s]trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:01<00:01, 704.47 examples/s]train dataset size 2013
test dataset size 272
2013
Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 777.56 examples/s]train dataset size 2013
test dataset size 272
2013
Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 767.35 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 894.77 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<24:40,  1.36 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:02<00:00, 886.98 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:00<00:06, 261.40 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 478.70 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 657.02 examples/s]
Concatenating 10 shards
2024-05-25 03:03:48 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 542.16 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 651.83 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<26:37,  1.26 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<27:24,  1.22 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:01<00:01, 701.19 examples/s]Spawning 10 processes
2024-05-25 03:03:49 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:01<00:07, 237.67 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:01<00:07, 239.22 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 706.17 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 424.89 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 432.52 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:47,  2.52 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 562.69 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 735.91 examples/s]Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 57/272 [00:00<00:01, 120.20 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 780.94 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 494.26 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 111/272 [00:00<00:00, 191.80 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 610.05 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 630.48 examples/s]Applying chat template to test_sft (num_proc=10):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 165/272 [00:00<00:00, 229.08 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:02<00:00, 770.35 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:02<00:01, 687.75 examples/s]Applying chat template to test_sft (num_proc=10):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 219/272 [00:01<00:00, 263.92 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:02<00:01, 649.56 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 623.01 examples/s]
Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 694.98 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 204.00 examples/s]
Concatenating 10 shards
2024-05-25 03:03:50 - INFO - datasets.arrow_dataset - Concatenating 10 shards
tokenizer padding side left
Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 645.93 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 704.02 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 749.93 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 664.78 examples/s]Using custom data configuration default-6ab037a909b14552
2024-05-25 03:03:51 - INFO - datasets.builder - Using custom data configuration default-6ab037a909b14552
Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
2024-05-25 03:03:51 - INFO - datasets.info - Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
Overwrite dataset info from restored data version if exists.
2024-05-25 03:03:51 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
2024-05-25 03:03:51 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0)
2024-05-25 03:03:51 - INFO - datasets.builder - Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0)
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
2024-05-25 03:03:51 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 765.80 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:03<00:00, 803.02 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:03<00:00, 796.92 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 600.43 examples/s]
Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 594.97 examples/s]
Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:52,  2.40 examples/s]Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 57/272 [00:00<00:01, 123.13 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 111/272 [00:00<00:00, 193.27 examples/s]Applying chat template to test_sft (num_proc=10):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 165/272 [00:00<00:00, 268.99 examples/s]Applying chat template to test_sft (num_proc=10):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 219/272 [00:00<00:00, 321.33 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 356.11 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 214.44 examples/s]
tokenizer padding side left
Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<02:18,  1.95 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:54,  2.36 examples/s]Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 57/272 [00:00<00:02, 100.21 examples/s]Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 56/272 [00:00<00:01, 129.70 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 111/272 [00:00<00:00, 164.76 examples/s]Applying chat template to test_sft (num_proc=10):  31%|‚ñà‚ñà‚ñà       | 84/272 [00:00<00:01, 143.92 examples/s]Applying chat template to test_sft (num_proc=10):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 165/272 [00:01<00:00, 212.48 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 138/272 [00:00<00:00, 206.64 examples/s]Applying chat template to test_sft (num_proc=10):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 219/272 [00:01<00:00, 240.46 examples/s]Applying chat template to test_sft (num_proc=10):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 219/272 [00:01<00:00, 309.52 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 181.39 examples/s]
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 209.01 examples/s]
tokenizer padding side left
tokenizer padding side left
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
2024-05-25 03:03:54 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
[INFO|trainer.py:607] 2024-05-25 03:03:55,463 >> Using auto half precision backend
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:1969] 2024-05-25 03:03:56,056 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-05-25 03:03:56,056 >>   Num examples = 1,279
[INFO|trainer.py:1971] 2024-05-25 03:03:56,056 >>   Num Epochs = 5
[INFO|trainer.py:1972] 2024-05-25 03:03:56,056 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-05-25 03:03:56,056 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-05-25 03:03:56,056 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-05-25 03:03:56,057 >>   Total optimization steps = 800
[INFO|trainer.py:1978] 2024-05-25 03:03:56,059 >>   Number of trainable parameters = 4,505,600
[INFO|integration_utils.py:723] 2024-05-25 03:03:56,122 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: roy3 (ihub-drug-discovery). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home2/tathagato/summarization/MACSum/experiments/wandb/run-20240525_030358-ju0x0lyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-salad-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ihub-drug-discovery/huggingface
wandb: üöÄ View run at https://wandb.ai/ihub-drug-discovery/huggingface/runs/ju0x0lyr
  0%|          | 0/800 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/800 [00:02<32:35,  2.45s/it]  0%|          | 2/800 [00:04<32:08,  2.42s/it]  0%|          | 3/800 [00:07<31:58,  2.41s/it]  0%|          | 4/800 [00:09<31:53,  2.40s/it]  1%|          | 5/800 [00:12<31:50,  2.40s/it]  1%|          | 6/800 [00:14<31:46,  2.40s/it]  1%|          | 7/800 [00:16<31:42,  2.40s/it]  1%|          | 8/800 [00:19<31:40,  2.40s/it]  1%|          | 9/800 [00:21<31:37,  2.40s/it]  1%|‚ñè         | 10/800 [00:24<31:36,  2.40s/it]  1%|‚ñè         | 11/800 [00:26<31:35,  2.40s/it]  2%|‚ñè         | 12/800 [00:28<31:56,  2.43s/it]  2%|‚ñè         | 13/800 [00:31<31:57,  2.44s/it]  2%|‚ñè         | 14/800 [00:33<31:47,  2.43s/it]  2%|‚ñè         | 15/800 [00:36<31:40,  2.42s/it]  2%|‚ñè         | 16/800 [00:38<31:34,  2.42s/it]  2%|‚ñè         | 17/800 [00:41<31:29,  2.41s/it]  2%|‚ñè         | 18/800 [00:43<31:25,  2.41s/it]  2%|‚ñè         | 19/800 [00:45<31:22,  2.41s/it]  2%|‚ñé         | 20/800 [00:48<31:19,  2.41s/it]                                                {'loss': 0.7218, 'grad_norm': 0.5586788654327393, 'learning_rate': 6.25e-05, 'epoch': 0.12}
  2%|‚ñé         | 20/800 [00:48<31:19,  2.41s/it]  3%|‚ñé         | 21/800 [00:50<31:17,  2.41s/it]  3%|‚ñé         | 22/800 [00:53<31:14,  2.41s/it]  3%|‚ñé         | 23/800 [00:55<31:11,  2.41s/it]  3%|‚ñé         | 24/800 [00:57<31:09,  2.41s/it]  3%|‚ñé         | 25/800 [01:00<31:06,  2.41s/it]  3%|‚ñé         | 26/800 [01:02<31:10,  2.42s/it]  3%|‚ñé         | 27/800 [01:05<31:06,  2.41s/it]  4%|‚ñé         | 28/800 [01:07<31:03,  2.41s/it]  4%|‚ñé         | 29/800 [01:09<31:08,  2.42s/it]  4%|‚ñç         | 30/800 [01:12<31:03,  2.42s/it]  4%|‚ñç         | 31/800 [01:14<30:58,  2.42s/it]  4%|‚ñç         | 32/800 [01:17<30:55,  2.42s/it]  4%|‚ñç         | 33/800 [01:19<30:51,  2.41s/it]  4%|‚ñç         | 34/800 [01:22<30:48,  2.41s/it]  4%|‚ñç         | 35/800 [01:24<30:46,  2.41s/it]  4%|‚ñç         | 36/800 [01:26<30:45,  2.42s/it]  5%|‚ñç         | 37/800 [01:29<30:43,  2.42s/it]  5%|‚ñç         | 38/800 [01:31<30:40,  2.41s/it]  5%|‚ñç         | 39/800 [01:34<30:39,  2.42s/it]  5%|‚ñå         | 40/800 [01:36<30:36,  2.42s/it]                                                {'loss': 0.6481, 'grad_norm': 0.4677649438381195, 'learning_rate': 0.000121875, 'epoch': 0.25}
  5%|‚ñå         | 40/800 [01:36<30:36,  2.42s/it]  5%|‚ñå         | 41/800 [01:38<30:34,  2.42s/it]  5%|‚ñå         | 42/800 [01:41<30:37,  2.42s/it]  5%|‚ñå         | 43/800 [01:43<30:32,  2.42s/it]  6%|‚ñå         | 44/800 [01:46<30:28,  2.42s/it]  6%|‚ñå         | 45/800 [01:48<30:24,  2.42s/it]  6%|‚ñå         | 46/800 [01:51<30:21,  2.42s/it]  6%|‚ñå         | 47/800 [01:53<30:19,  2.42s/it]  6%|‚ñå         | 48/800 [01:55<30:17,  2.42s/it]  6%|‚ñå         | 49/800 [01:58<30:14,  2.42s/it]  6%|‚ñã         | 50/800 [02:00<30:11,  2.42s/it]  6%|‚ñã         | 51/800 [02:03<30:08,  2.41s/it]  6%|‚ñã         | 52/800 [02:05<30:05,  2.41s/it]  7%|‚ñã         | 53/800 [02:07<30:04,  2.42s/it]  7%|‚ñã         | 54/800 [02:10<30:10,  2.43s/it]  7%|‚ñã         | 55/800 [02:12<30:05,  2.42s/it]  7%|‚ñã         | 56/800 [02:15<30:16,  2.44s/it]  7%|‚ñã         | 57/800 [02:17<30:08,  2.43s/it]  7%|‚ñã         | 58/800 [02:20<30:01,  2.43s/it]  7%|‚ñã         | 59/800 [02:22<29:56,  2.43s/it]  8%|‚ñä         | 60/800 [02:24<29:52,  2.42s/it]                                                {'loss': 0.6645, 'grad_norm': 0.4793098568916321, 'learning_rate': 0.00018437500000000002, 'epoch': 0.38}
  8%|‚ñä         | 60/800 [02:24<29:52,  2.42s/it]  8%|‚ñä         | 61/800 [02:27<29:49,  2.42s/it]  8%|‚ñä         | 62/800 [02:29<29:47,  2.42s/it]  8%|‚ñä         | 63/800 [02:32<29:43,  2.42s/it]  8%|‚ñä         | 64/800 [02:34<29:40,  2.42s/it]  8%|‚ñä         | 65/800 [02:37<29:37,  2.42s/it]  8%|‚ñä         | 66/800 [02:39<29:34,  2.42s/it]  8%|‚ñä         | 67/800 [02:41<29:32,  2.42s/it]  8%|‚ñä         | 68/800 [02:44<29:30,  2.42s/it]  9%|‚ñä         | 69/800 [02:46<29:27,  2.42s/it]  9%|‚ñâ         | 70/800 [02:49<29:30,  2.43s/it]  9%|‚ñâ         | 71/800 [02:51<29:26,  2.42s/it]  9%|‚ñâ         | 72/800 [02:54<29:23,  2.42s/it]  9%|‚ñâ         | 73/800 [02:56<29:19,  2.42s/it]  9%|‚ñâ         | 74/800 [02:58<29:16,  2.42s/it]  9%|‚ñâ         | 75/800 [03:01<29:14,  2.42s/it] 10%|‚ñâ         | 76/800 [03:03<29:11,  2.42s/it] 10%|‚ñâ         | 77/800 [03:06<29:08,  2.42s/it] 10%|‚ñâ         | 78/800 [03:08<29:05,  2.42s/it] 10%|‚ñâ         | 79/800 [03:10<29:03,  2.42s/it] 10%|‚ñà         | 80/800 [03:13<29:00,  2.42s/it]                                                {'loss': 0.6276, 'grad_norm': 0.44130441546440125, 'learning_rate': 0.00024375, 'epoch': 0.5}
 10%|‚ñà         | 80/800 [03:13<29:00,  2.42s/it] 10%|‚ñà         | 81/800 [03:15<28:59,  2.42s/it] 10%|‚ñà         | 82/800 [03:18<28:57,  2.42s/it] 10%|‚ñà         | 83/800 [03:20<29:03,  2.43s/it] 10%|‚ñà         | 84/800 [03:23<28:58,  2.43s/it] 11%|‚ñà         | 85/800 [03:25<28:53,  2.42s/it] 11%|‚ñà         | 86/800 [03:27<28:50,  2.42s/it] 11%|‚ñà         | 87/800 [03:30<28:46,  2.42s/it] 11%|‚ñà         | 88/800 [03:32<28:43,  2.42s/it] 11%|‚ñà         | 89/800 [03:35<28:41,  2.42s/it] 11%|‚ñà‚ñè        | 90/800 [03:37<28:38,  2.42s/it] 11%|‚ñà‚ñè        | 91/800 [03:40<28:35,  2.42s/it] 12%|‚ñà‚ñè        | 92/800 [03:42<28:32,  2.42s/it] 12%|‚ñà‚ñè        | 93/800 [03:44<28:30,  2.42s/it] 12%|‚ñà‚ñè        | 94/800 [03:47<28:27,  2.42s/it] 12%|‚ñà‚ñè        | 95/800 [03:49<28:24,  2.42s/it] 12%|‚ñà‚ñè        | 96/800 [03:52<28:22,  2.42s/it] 12%|‚ñà‚ñè        | 97/800 [03:54<28:19,  2.42s/it] 12%|‚ñà‚ñè        | 98/800 [03:56<28:26,  2.43s/it] 12%|‚ñà‚ñè        | 99/800 [03:59<28:21,  2.43s/it] 12%|‚ñà‚ñé        | 100/800 [04:01<28:17,  2.42s/it]                                                 {'loss': 0.6204, 'grad_norm': 0.4423437714576721, 'learning_rate': 0.00030625000000000004, 'epoch': 0.62}
 12%|‚ñà‚ñé        | 100/800 [04:01<28:17,  2.42s/it] 13%|‚ñà‚ñé        | 101/800 [04:04<28:13,  2.42s/it] 13%|‚ñà‚ñé        | 102/800 [04:06<28:10,  2.42s/it] 13%|‚ñà‚ñé        | 103/800 [04:09<28:06,  2.42s/it] 13%|‚ñà‚ñé        | 104/800 [04:11<28:03,  2.42s/it] 13%|‚ñà‚ñé        | 105/800 [04:13<28:00,  2.42s/it] 13%|‚ñà‚ñé        | 106/800 [04:16<27:58,  2.42s/it] 13%|‚ñà‚ñé        | 107/800 [04:18<27:55,  2.42s/it] 14%|‚ñà‚ñé        | 108/800 [04:21<27:53,  2.42s/it] 14%|‚ñà‚ñé        | 109/800 [04:23<27:50,  2.42s/it] 14%|‚ñà‚ñç        | 110/800 [04:26<27:48,  2.42s/it] 14%|‚ñà‚ñç        | 111/800 [04:28<27:55,  2.43s/it] 14%|‚ñà‚ñç        | 112/800 [04:30<27:54,  2.43s/it] 14%|‚ñà‚ñç        | 113/800 [04:33<27:48,  2.43s/it] 14%|‚ñà‚ñç        | 114/800 [04:35<27:44,  2.43s/it] 14%|‚ñà‚ñç        | 115/800 [04:38<27:40,  2.42s/it] 14%|‚ñà‚ñç        | 116/800 [04:40<27:36,  2.42s/it] 15%|‚ñà‚ñç        | 117/800 [04:42<27:33,  2.42s/it] 15%|‚ñà‚ñç        | 118/800 [04:45<27:30,  2.42s/it] 15%|‚ñà‚ñç        | 119/800 [04:47<27:27,  2.42s/it] 15%|‚ñà‚ñå        | 120/800 [04:50<27:25,  2.42s/it]                                                 {'loss': 0.6466, 'grad_norm': 0.3271624445915222, 'learning_rate': 0.00036875000000000005, 'epoch': 0.75}
 15%|‚ñà‚ñå        | 120/800 [04:50<27:25,  2.42s/it] 15%|‚ñà‚ñå        | 121/800 [04:52<27:22,  2.42s/it] 15%|‚ñà‚ñå        | 122/800 [04:55<27:20,  2.42s/it] 15%|‚ñà‚ñå        | 123/800 [04:57<27:17,  2.42s/it] 16%|‚ñà‚ñå        | 124/800 [04:59<27:15,  2.42s/it] 16%|‚ñà‚ñå        | 125/800 [05:02<27:13,  2.42s/it] 16%|‚ñà‚ñå        | 126/800 [05:04<27:27,  2.44s/it] 16%|‚ñà‚ñå        | 127/800 [05:07<27:19,  2.44s/it] 16%|‚ñà‚ñå        | 128/800 [05:09<27:13,  2.43s/it] 16%|‚ñà‚ñå        | 129/800 [05:12<27:08,  2.43s/it] 16%|‚ñà‚ñã        | 130/800 [05:14<27:04,  2.43s/it] 16%|‚ñà‚ñã        | 131/800 [05:16<27:01,  2.42s/it] 16%|‚ñà‚ñã        | 132/800 [05:19<26:57,  2.42s/it] 17%|‚ñà‚ñã        | 133/800 [05:21<26:54,  2.42s/it] 17%|‚ñà‚ñã        | 134/800 [05:24<26:51,  2.42s/it] 17%|‚ñà‚ñã        | 135/800 [05:26<26:48,  2.42s/it] 17%|‚ñà‚ñã        | 136/800 [05:29<26:46,  2.42s/it] 17%|‚ñà‚ñã        | 137/800 [05:31<26:43,  2.42s/it] 17%|‚ñà‚ñã        | 138/800 [05:33<26:41,  2.42s/it] 17%|‚ñà‚ñã        | 139/800 [05:36<26:45,  2.43s/it] 18%|‚ñà‚ñä        | 140/800 [05:38<26:40,  2.43s/it]                                                 {'loss': 0.6177, 'grad_norm': 0.31491976976394653, 'learning_rate': 0.00043125000000000005, 'epoch': 0.88}
 18%|‚ñà‚ñä        | 140/800 [05:38<26:40,  2.43s/it] 18%|‚ñà‚ñä        | 141/800 [05:41<26:37,  2.42s/it] 18%|‚ñà‚ñä        | 142/800 [05:43<26:33,  2.42s/it] 18%|‚ñà‚ñä        | 143/800 [05:45<26:30,  2.42s/it] 18%|‚ñà‚ñä        | 144/800 [05:48<26:27,  2.42s/it] 18%|‚ñà‚ñä        | 145/800 [05:50<26:24,  2.42s/it] 18%|‚ñà‚ñä        | 146/800 [05:53<26:22,  2.42s/it] 18%|‚ñà‚ñä        | 147/800 [05:55<26:19,  2.42s/it] 18%|‚ñà‚ñä        | 148/800 [05:58<26:17,  2.42s/it] 19%|‚ñà‚ñä        | 149/800 [06:00<26:14,  2.42s/it] 19%|‚ñà‚ñâ        | 150/800 [06:02<26:12,  2.42s/it] 19%|‚ñà‚ñâ        | 151/800 [06:05<26:10,  2.42s/it] 19%|‚ñà‚ñâ        | 152/800 [06:07<26:10,  2.42s/it] 19%|‚ñà‚ñâ        | 153/800 [06:10<26:06,  2.42s/it] 19%|‚ñà‚ñâ        | 154/800 [06:12<26:03,  2.42s/it] 19%|‚ñà‚ñâ        | 155/800 [06:15<26:05,  2.43s/it] 20%|‚ñà‚ñâ        | 156/800 [06:17<26:01,  2.43s/it] 20%|‚ñà‚ñâ        | 157/800 [06:19<25:58,  2.42s/it] 20%|‚ñà‚ñâ        | 158/800 [06:22<25:54,  2.42s/it] 20%|‚ñà‚ñâ        | 159/800 [06:24<25:51,  2.42s/it] 20%|‚ñà‚ñà        | 160/800 [06:27<25:48,  2.42s/it]                                                 {'loss': 0.5436, 'grad_norm': 0.4272554814815521, 'learning_rate': 0.00049375, 'epoch': 1.0}
 20%|‚ñà‚ñà        | 160/800 [06:27<25:48,  2.42s/it] 20%|‚ñà‚ñà        | 161/800 [06:29<25:46,  2.42s/it] 20%|‚ñà‚ñà        | 162/800 [06:31<25:44,  2.42s/it] 20%|‚ñà‚ñà        | 163/800 [06:34<25:41,  2.42s/it] 20%|‚ñà‚ñà        | 164/800 [06:36<25:38,  2.42s/it] 21%|‚ñà‚ñà        | 165/800 [06:39<25:36,  2.42s/it] 21%|‚ñà‚ñà        | 166/800 [06:41<25:33,  2.42s/it] 21%|‚ñà‚ñà        | 167/800 [06:44<25:30,  2.42s/it] 21%|‚ñà‚ñà        | 168/800 [06:46<25:34,  2.43s/it] 21%|‚ñà‚ñà        | 169/800 [06:48<25:30,  2.43s/it] 21%|‚ñà‚ñà‚ñè       | 170/800 [06:51<25:26,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 171/800 [06:53<25:22,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 172/800 [06:56<25:20,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 173/800 [06:58<25:17,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 174/800 [07:01<25:14,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 175/800 [07:03<25:12,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 176/800 [07:05<25:09,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 177/800 [07:08<25:06,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 178/800 [07:10<25:04,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 179/800 [07:13<25:02,  2.42s/it] 22%|‚ñà‚ñà‚ñé       | 180/800 [07:15<24:59,  2.42s/it]                                                 {'loss': 0.5279, 'grad_norm': 0.29193350672721863, 'learning_rate': 0.0004990247583129218, 'epoch': 1.12}
 22%|‚ñà‚ñà‚ñé       | 180/800 [07:15<24:59,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 181/800 [07:18<25:05,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 182/800 [07:20<25:00,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 183/800 [07:22<24:57,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 184/800 [07:25<24:53,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 185/800 [07:27<24:49,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 186/800 [07:30<24:47,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 187/800 [07:32<24:44,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 188/800 [07:34<24:41,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 189/800 [07:37<24:38,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 190/800 [07:39<24:36,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 191/800 [07:42<24:33,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 192/800 [07:44<24:30,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 193/800 [07:47<24:28,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 194/800 [07:49<24:26,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 195/800 [07:51<24:36,  2.44s/it] 24%|‚ñà‚ñà‚ñç       | 196/800 [07:54<24:30,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 197/800 [07:56<24:25,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 198/800 [07:59<24:20,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 199/800 [08:01<24:21,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 200/800 [08:04<24:16,  2.43s/it]                                                 {'loss': 0.564, 'grad_norm': 0.32290545105934143, 'learning_rate': 0.000495663319832678, 'epoch': 1.25}
 25%|‚ñà‚ñà‚ñå       | 200/800 [08:04<24:16,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 201/800 [08:06<24:13,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 202/800 [08:08<24:09,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 203/800 [08:11<24:06,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 204/800 [08:13<24:03,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 205/800 [08:16<24:00,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 206/800 [08:18<23:57,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 207/800 [08:21<23:54,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 208/800 [08:23<23:52,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 209/800 [08:25<23:51,  2.42s/it] 26%|‚ñà‚ñà‚ñã       | 210/800 [08:28<23:48,  2.42s/it] 26%|‚ñà‚ñà‚ñã       | 211/800 [08:30<23:46,  2.42s/it] 26%|‚ñà‚ñà‚ñã       | 212/800 [08:33<23:43,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 213/800 [08:35<23:40,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 214/800 [08:37<23:37,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 215/800 [08:40<23:35,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 216/800 [08:42<23:32,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 217/800 [08:45<23:29,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 218/800 [08:47<23:27,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 219/800 [08:50<23:25,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 220/800 [08:52<23:22,  2.42s/it]                                                 {'loss': 0.5746, 'grad_norm': 0.38193926215171814, 'learning_rate': 0.000490277804028108, 'epoch': 1.38}
 28%|‚ñà‚ñà‚ñä       | 220/800 [08:52<23:22,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 221/800 [08:54<23:20,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 222/800 [08:57<23:25,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 223/800 [08:59<23:20,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 224/800 [09:02<23:16,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 225/800 [09:04<23:13,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 226/800 [09:07<23:10,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 227/800 [09:09<23:07,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 228/800 [09:11<23:04,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 229/800 [09:14<23:01,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 230/800 [09:16<22:58,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 231/800 [09:19<22:56,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 232/800 [09:21<22:53,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 233/800 [09:23<22:51,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 234/800 [09:26<22:48,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 235/800 [09:28<22:46,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 236/800 [09:31<22:44,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 237/800 [09:33<22:43,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 238/800 [09:36<22:40,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 239/800 [09:38<22:37,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 240/800 [09:40<22:35,  2.42s/it]                                                 {'loss': 0.5613, 'grad_norm': 0.38698992133140564, 'learning_rate': 0.0004823536581098261, 'epoch': 1.5}
 30%|‚ñà‚ñà‚ñà       | 240/800 [09:40<22:35,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 241/800 [09:43<22:33,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 242/800 [09:45<22:31,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 243/800 [09:48<22:27,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 244/800 [09:50<22:25,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 245/800 [09:53<22:22,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 246/800 [09:55<22:20,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 247/800 [09:57<22:17,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 248/800 [10:00<22:14,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 249/800 [10:02<22:12,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 250/800 [10:05<22:15,  2.43s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 251/800 [10:07<22:11,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 252/800 [10:09<22:07,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 253/800 [10:12<22:05,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 254/800 [10:14<22:02,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 255/800 [10:17<21:59,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 256/800 [10:19<21:56,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 257/800 [10:22<21:53,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 258/800 [10:24<21:50,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 259/800 [10:26<21:48,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 260/800 [10:29<21:46,  2.42s/it]                                                 {'loss': 0.5697, 'grad_norm': 0.39490318298339844, 'learning_rate': 0.0004721918194465169, 'epoch': 1.62}
 32%|‚ñà‚ñà‚ñà‚ñé      | 260/800 [10:29<21:46,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 261/800 [10:31<21:44,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 262/800 [10:34<21:42,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 263/800 [10:36<21:39,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 264/800 [10:39<21:36,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 265/800 [10:41<21:43,  2.44s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 266/800 [10:43<21:37,  2.43s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 267/800 [10:46<21:33,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 268/800 [10:48<21:29,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 269/800 [10:51<21:26,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 270/800 [10:53<21:23,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 271/800 [10:55<21:20,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 272/800 [10:58<21:18,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 273/800 [11:00<21:15,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 274/800 [11:03<21:12,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 275/800 [11:05<21:10,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 276/800 [11:08<21:07,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 277/800 [11:10<21:04,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 278/800 [11:12<21:08,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 279/800 [11:15<21:04,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 280/800 [11:17<21:00,  2.42s/it]                                                 {'loss': 0.5255, 'grad_norm': 0.3833886384963989, 'learning_rate': 0.00045989015209953394, 'epoch': 1.75}
 35%|‚ñà‚ñà‚ñà‚ñå      | 280/800 [11:17<21:00,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 281/800 [11:20<20:57,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 282/800 [11:22<20:54,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 283/800 [11:25<20:51,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 284/800 [11:27<20:49,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 285/800 [11:29<20:46,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 286/800 [11:32<20:47,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 287/800 [11:34<20:43,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 288/800 [11:37<20:40,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 289/800 [11:39<20:37,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 290/800 [11:42<20:35,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 291/800 [11:44<20:34,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 292/800 [11:46<20:31,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 293/800 [11:49<20:27,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 294/800 [11:51<20:25,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 295/800 [11:54<20:22,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 296/800 [11:56<20:19,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 297/800 [11:58<20:17,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 298/800 [12:01<20:14,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 299/800 [12:03<20:12,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 300/800 [12:06<20:09,  2.42s/it]                                                 {'loss': 0.5085, 'grad_norm': 0.35175561904907227, 'learning_rate': 0.0004455671278502041, 'epoch': 1.88}
 38%|‚ñà‚ñà‚ñà‚ñä      | 300/800 [12:06<20:09,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 301/800 [12:08<20:08,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 302/800 [12:11<20:05,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 303/800 [12:13<20:02,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 304/800 [12:15<20:00,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 305/800 [12:18<19:57,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 306/800 [12:20<19:54,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 307/800 [12:23<19:57,  2.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 308/800 [12:25<19:53,  2.43s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 309/800 [12:28<19:49,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 310/800 [12:30<19:47,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 311/800 [12:32<19:43,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 312/800 [12:35<19:41,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 313/800 [12:37<19:38,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 314/800 [12:40<19:35,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 315/800 [12:42<19:35,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 316/800 [12:44<19:32,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 317/800 [12:47<19:29,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 318/800 [12:49<19:26,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 319/800 [12:52<19:23,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 320/800 [12:54<19:23,  2.42s/it]                                                 {'loss': 0.5476, 'grad_norm': 0.35150063037872314, 'learning_rate': 0.00042936068525181004, 'epoch': 2.0}
 40%|‚ñà‚ñà‚ñà‚ñà      | 320/800 [12:54<19:23,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 321/800 [12:57<19:20,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 322/800 [12:59<19:17,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 323/800 [13:01<19:14,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 324/800 [13:04<19:11,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 325/800 [13:06<19:08,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 326/800 [13:09<19:06,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 327/800 [13:11<19:04,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 328/800 [13:14<19:01,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 329/800 [13:16<18:58,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 330/800 [13:18<18:56,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 331/800 [13:21<18:54,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 332/800 [13:23<18:51,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 333/800 [13:26<18:49,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 334/800 [13:28<18:56,  2.44s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 335/800 [13:30<18:51,  2.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 336/800 [13:33<18:46,  2.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 337/800 [13:35<18:42,  2.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 338/800 [13:38<18:39,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 339/800 [13:40<18:36,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 340/800 [13:43<18:33,  2.42s/it]                                                 {'loss': 0.426, 'grad_norm': 0.31090718507766724, 'learning_rate': 0.00041142690120591686, 'epoch': 2.12}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 340/800 [13:43<18:33,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 341/800 [13:45<18:31,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 342/800 [13:47<18:28,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 343/800 [13:50<18:25,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 344/800 [13:52<18:23,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 345/800 [13:55<18:20,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 346/800 [13:57<18:17,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 347/800 [14:00<18:15,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 348/800 [14:02<18:16,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 349/800 [14:04<18:12,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 350/800 [14:07<18:09,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 351/800 [14:09<18:07,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 352/800 [14:12<18:04,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 353/800 [14:14<18:01,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 354/800 [14:16<17:58,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 355/800 [14:19<17:56,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 356/800 [14:21<17:54,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 357/800 [14:24<17:51,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 358/800 [14:26<17:51,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 359/800 [14:29<17:48,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 360/800 [14:31<17:45,  2.42s/it]                                                 {'loss': 0.4652, 'grad_norm': 0.37678587436676025, 'learning_rate': 0.00039193848785649016, 'epoch': 2.25}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 360/800 [14:31<17:45,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 361/800 [14:33<17:43,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 362/800 [14:36<17:40,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 363/800 [14:38<17:38,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 364/800 [14:41<17:35,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 365/800 [14:43<17:32,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 366/800 [14:46<17:30,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 367/800 [14:48<17:27,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 368/800 [14:50<17:25,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 369/800 [14:53<17:22,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 370/800 [14:55<17:20,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 371/800 [14:58<17:17,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 372/800 [15:00<17:15,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 373/800 [15:02<17:12,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 374/800 [15:05<17:10,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 375/800 [15:07<17:07,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 376/800 [15:10<17:08,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 377/800 [15:12<17:04,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 378/800 [15:15<17:01,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 379/800 [15:17<16:59,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 380/800 [15:19<16:56,  2.42s/it]                                                 {'loss': 0.4693, 'grad_norm': 0.338687926530838, 'learning_rate': 0.0003710831292775353, 'epoch': 2.38}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 380/800 [15:19<16:56,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 381/800 [15:22<16:54,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 382/800 [15:24<16:51,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 383/800 [15:27<16:49,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 384/800 [15:29<16:46,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 385/800 [15:32<16:43,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 386/800 [15:34<16:41,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 387/800 [15:36<16:39,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 388/800 [15:39<16:36,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 389/800 [15:41<16:36,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 390/800 [15:44<16:33,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 391/800 [15:46<16:30,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 392/800 [15:48<16:27,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 393/800 [15:51<16:24,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 394/800 [15:53<16:22,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 395/800 [15:56<16:19,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 396/800 [15:58<16:17,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 397/800 [16:01<16:14,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 398/800 [16:03<16:11,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 399/800 [16:05<16:09,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 400/800 [16:08<16:07,  2.42s/it]                                                 {'loss': 0.4531, 'grad_norm': 0.34929966926574707, 'learning_rate': 0.0003490616739728664, 'epoch': 2.5}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 400/800 [16:08<16:07,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 03:20:13,767 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_topic/checkpoint-400
[INFO|configuration_utils.py:726] 2024-05-25 03:20:14,973 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:20:14,976 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 03:20:15,066 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_topic/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 03:20:15,067 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_topic/checkpoint-400/special_tokens_map.json
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 401/800 [16:12<18:57,  2.85s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 402/800 [16:14<18:02,  2.72s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 403/800 [16:16<17:24,  2.63s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 404/800 [16:19<16:59,  2.58s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 405/800 [16:21<16:38,  2.53s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 406/800 [16:24<16:23,  2.50s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 407/800 [16:26<16:12,  2.47s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 408/800 [16:29<16:03,  2.46s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 409/800 [16:31<15:56,  2.45s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 410/800 [16:33<15:51,  2.44s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 411/800 [16:36<15:46,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 412/800 [16:38<15:42,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 413/800 [16:41<15:39,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 414/800 [16:43<15:35,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 415/800 [16:46<15:43,  2.45s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 416/800 [16:48<15:37,  2.44s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 417/800 [16:51<15:33,  2.44s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 418/800 [16:53<15:28,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 419/800 [16:55<15:25,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 420/800 [16:58<15:21,  2.43s/it]                                                 {'loss': 0.4638, 'grad_norm': 0.41924846172332764, 'learning_rate': 0.0003260862005952193, 'epoch': 2.62}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 420/800 [16:58<15:21,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 421/800 [17:00<15:18,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 422/800 [17:03<15:15,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 423/800 [17:05<15:13,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 424/800 [17:07<15:10,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 425/800 [17:10<15:08,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 426/800 [17:12<15:05,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 427/800 [17:15<15:02,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 428/800 [17:17<15:00,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 429/800 [17:20<14:57,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 430/800 [17:22<14:57,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 431/800 [17:24<14:54,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 432/800 [17:27<14:51,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 433/800 [17:29<14:48,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 434/800 [17:32<14:46,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 435/800 [17:34<14:43,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 436/800 [17:37<14:41,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 437/800 [17:39<14:38,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 438/800 [17:41<14:36,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 439/800 [17:44<14:33,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 440/800 [17:46<14:31,  2.42s/it]                                                 {'loss': 0.4678, 'grad_norm': 0.38859426975250244, 'learning_rate': 0.00030237797551289225, 'epoch': 2.75}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 440/800 [17:46<14:31,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 441/800 [17:49<14:28,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 442/800 [17:51<14:26,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 443/800 [17:53<14:26,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 444/800 [17:56<14:22,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 445/800 [17:58<14:20,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 446/800 [18:01<14:19,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 447/800 [18:03<14:16,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 448/800 [18:06<14:13,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 449/800 [18:08<14:10,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 450/800 [18:10<14:07,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 451/800 [18:13<14:04,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 452/800 [18:15<14:02,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 453/800 [18:18<14:00,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 454/800 [18:20<13:57,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 455/800 [18:23<13:54,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 456/800 [18:25<13:52,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 457/800 [18:27<13:49,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 458/800 [18:30<13:47,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 459/800 [18:32<13:47,  2.43s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 460/800 [18:35<13:44,  2.43s/it]                                                 {'loss': 0.4156, 'grad_norm': 0.37603145837783813, 'learning_rate': 0.00027816532189366193, 'epoch': 2.88}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 460/800 [18:35<13:44,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 461/800 [18:37<13:41,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 462/800 [18:39<13:38,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 463/800 [18:42<13:36,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 464/800 [18:44<13:33,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 465/800 [18:47<13:31,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 466/800 [18:49<13:28,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 467/800 [18:52<13:26,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 468/800 [18:54<13:23,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 469/800 [18:56<13:21,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 470/800 [18:59<13:18,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 471/800 [19:01<13:16,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 472/800 [19:04<13:14,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 473/800 [19:06<13:16,  2.43s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 474/800 [19:09<13:12,  2.43s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 475/800 [19:11<13:08,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 476/800 [19:13<13:05,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 477/800 [19:16<13:02,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 478/800 [19:18<12:59,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 479/800 [19:21<12:57,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 480/800 [19:23<12:54,  2.42s/it]                                                 {'loss': 0.4252, 'grad_norm': 0.3401625156402588, 'learning_rate': 0.00025368142082786465, 'epoch': 3.0}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 480/800 [19:23<12:54,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 481/800 [19:26<12:52,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 482/800 [19:28<12:49,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 483/800 [19:30<12:47,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 484/800 [19:33<12:44,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 485/800 [19:35<12:42,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 486/800 [19:38<12:39,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 487/800 [19:40<12:37,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 488/800 [19:42<12:34,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 489/800 [19:45<12:32,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 490/800 [19:47<12:30,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 491/800 [19:50<12:27,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 492/800 [19:52<12:25,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 493/800 [19:55<12:22,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 494/800 [19:57<12:20,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 495/800 [19:59<12:17,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 496/800 [20:02<12:15,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 497/800 [20:04<12:12,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 498/800 [20:07<12:10,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 499/800 [20:09<12:08,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 500/800 [20:12<12:07,  2.42s/it]                                                 {'loss': 0.3615, 'grad_norm': 0.2742671072483063, 'learning_rate': 0.0002291620656670256, 'epoch': 3.12}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 500/800 [20:12<12:07,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 501/800 [20:14<12:04,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 502/800 [20:16<12:02,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 503/800 [20:19<11:59,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 504/800 [20:21<11:56,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 505/800 [20:24<11:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 506/800 [20:26<11:51,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 507/800 [20:28<11:49,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 508/800 [20:31<11:46,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 509/800 [20:33<11:44,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 510/800 [20:36<11:41,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 511/800 [20:38<11:39,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 512/800 [20:41<11:36,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 513/800 [20:43<11:34,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 514/800 [20:45<11:31,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 515/800 [20:48<11:31,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 516/800 [20:50<11:28,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 517/800 [20:53<11:27,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 518/800 [20:55<11:24,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 519/800 [20:58<11:21,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 520/800 [21:00<11:18,  2.42s/it]                                                 {'loss': 0.3544, 'grad_norm': 0.3146759569644928, 'learning_rate': 0.0002048433912049868, 'epoch': 3.25}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 520/800 [21:00<11:18,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 521/800 [21:02<11:15,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 522/800 [21:05<11:13,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 523/800 [21:07<11:10,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 524/800 [21:10<11:07,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 525/800 [21:12<11:05,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 526/800 [21:14<11:02,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 527/800 [21:17<11:00,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 528/800 [21:19<10:58,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 529/800 [21:22<10:55,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 530/800 [21:24<10:53,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 531/800 [21:27<10:50,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 532/800 [21:29<10:48,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 533/800 [21:31<10:45,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 534/800 [21:34<10:43,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 535/800 [21:36<10:41,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 536/800 [21:39<10:38,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 537/800 [21:41<10:36,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 538/800 [21:43<10:33,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 539/800 [21:46<10:31,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 540/800 [21:48<10:29,  2.42s/it]                                                 {'loss': 0.3607, 'grad_norm': 0.2978363633155823, 'learning_rate': 0.0001809595995707573, 'epoch': 3.38}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 540/800 [21:48<10:29,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 541/800 [21:51<10:26,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 542/800 [21:53<10:24,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 543/800 [21:56<10:27,  2.44s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 544/800 [21:58<10:23,  2.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 545/800 [22:00<10:19,  2.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 546/800 [22:03<10:16,  2.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 547/800 [22:05<10:13,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 548/800 [22:08<10:10,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 549/800 [22:10<10:07,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 550/800 [22:13<10:05,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 551/800 [22:15<10:02,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 552/800 [22:17<10:00,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 553/800 [22:20<09:57,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 554/800 [22:22<09:55,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 555/800 [22:25<09:52,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 556/800 [22:27<09:52,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 557/800 [22:30<09:49,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 558/800 [22:32<09:46,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 559/800 [22:34<09:45,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 560/800 [22:37<09:42,  2.43s/it]                                                 {'loss': 0.3644, 'grad_norm': 0.29287776350975037, 'learning_rate': 0.0001577407047339834, 'epoch': 3.5}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 560/800 [22:37<09:42,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 561/800 [22:39<09:39,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 562/800 [22:42<09:36,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 563/800 [22:44<09:33,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 564/800 [22:46<09:31,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 565/800 [22:49<09:28,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 566/800 [22:51<09:26,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 567/800 [22:54<09:23,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 568/800 [22:56<09:21,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 569/800 [22:59<09:18,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 570/800 [23:01<09:16,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 571/800 [23:03<09:13,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 572/800 [23:06<09:11,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 573/800 [23:08<09:09,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 574/800 [23:11<09:06,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 575/800 [23:13<09:04,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 576/800 [23:16<09:01,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 577/800 [23:18<08:59,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 578/800 [23:20<08:57,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 579/800 [23:23<08:54,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 580/800 [23:25<08:52,  2.42s/it]                                                 {'loss': 0.3875, 'grad_norm': 0.3090277314186096, 'learning_rate': 0.00013541031734468211, 'epoch': 3.62}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 580/800 [23:25<08:52,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 581/800 [23:28<08:49,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 582/800 [23:30<08:47,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 583/800 [23:32<08:45,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 584/800 [23:35<08:42,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 585/800 [23:37<08:41,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 586/800 [23:40<08:38,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 587/800 [23:42<08:36,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 588/800 [23:45<08:33,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 589/800 [23:47<08:31,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 590/800 [23:49<08:28,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 591/800 [23:52<08:25,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 592/800 [23:54<08:23,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 593/800 [23:57<08:20,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 594/800 [23:59<08:18,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 595/800 [24:02<08:15,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 596/800 [24:04<08:13,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 597/800 [24:06<08:10,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 598/800 [24:09<08:10,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 599/800 [24:11<08:07,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 600/800 [24:14<08:04,  2.42s/it]                                                 {'loss': 0.3793, 'grad_norm': 0.3624802231788635, 'learning_rate': 0.00011418349124044405, 'epoch': 3.75}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 600/800 [24:14<08:04,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 601/800 [24:16<08:02,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 602/800 [24:18<07:59,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 603/800 [24:21<07:56,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 604/800 [24:23<07:54,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 605/800 [24:26<07:52,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 606/800 [24:28<07:49,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 607/800 [24:31<07:47,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 608/800 [24:33<07:44,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 609/800 [24:35<07:42,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 610/800 [24:38<07:39,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 611/800 [24:40<07:37,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 612/800 [24:43<07:36,  2.43s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 613/800 [24:45<07:33,  2.43s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 614/800 [24:48<07:30,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 615/800 [24:50<07:28,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 616/800 [24:52<07:25,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 617/800 [24:55<07:22,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 618/800 [24:57<07:20,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 619/800 [25:00<07:17,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 620/800 [25:02<07:15,  2.42s/it]                                                 {'loss': 0.3992, 'grad_norm': 0.3601585626602173, 'learning_rate': 9.42646523604165e-05, 'epoch': 3.88}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 620/800 [25:02<07:15,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 621/800 [25:04<07:13,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 622/800 [25:07<07:10,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 623/800 [25:09<07:08,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 624/800 [25:12<07:05,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 625/800 [25:14<07:03,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 626/800 [25:17<07:00,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 627/800 [25:19<06:58,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 628/800 [25:21<06:56,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 629/800 [25:24<06:53,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 630/800 [25:26<06:51,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 631/800 [25:29<06:48,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 632/800 [25:31<06:46,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 633/800 [25:34<06:44,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 634/800 [25:36<06:42,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 635/800 [25:38<06:39,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 636/800 [25:41<06:37,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 637/800 [25:43<06:34,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 638/800 [25:46<06:32,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 639/800 [25:48<06:30,  2.43s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 640/800 [25:50<06:27,  2.42s/it]                                                 {'loss': 0.3864, 'grad_norm': 0.366159588098526, 'learning_rate': 7.584563001175895e-05, 'epoch': 4.0}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 640/800 [25:50<06:27,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 641/800 [25:53<06:25,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 642/800 [25:55<06:22,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 643/800 [25:58<06:20,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 644/800 [26:00<06:17,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 645/800 [26:03<06:15,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 646/800 [26:05<06:12,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 647/800 [26:07<06:10,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 648/800 [26:10<06:07,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 649/800 [26:12<06:05,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 650/800 [26:15<06:02,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 651/800 [26:17<06:00,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 652/800 [26:20<05:58,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 653/800 [26:22<05:55,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 654/800 [26:24<05:53,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 655/800 [26:27<05:50,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 656/800 [26:29<05:48,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 657/800 [26:32<05:45,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 658/800 [26:34<05:43,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 659/800 [26:36<05:41,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 660/800 [26:39<05:38,  2.42s/it]                                                 {'loss': 0.3296, 'grad_norm': 0.2865164279937744, 'learning_rate': 5.910380944855087e-05, 'epoch': 4.12}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 660/800 [26:39<05:38,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 661/800 [26:41<05:36,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 662/800 [26:44<05:33,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 663/800 [26:46<05:31,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 664/800 [26:49<05:29,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 665/800 [26:51<05:26,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 666/800 [26:53<05:24,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 667/800 [26:56<05:21,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 668/800 [26:58<05:19,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 669/800 [27:01<05:16,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 670/800 [27:03<05:14,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 671/800 [27:05<05:12,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 672/800 [27:08<05:09,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 673/800 [27:10<05:07,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 674/800 [27:13<05:04,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 675/800 [27:15<05:03,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 676/800 [27:18<05:00,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 677/800 [27:20<04:57,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 678/800 [27:22<04:55,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 679/800 [27:25<04:52,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 680/800 [27:27<04:50,  2.42s/it]                                                 {'loss': 0.3204, 'grad_norm': 0.3288865387439728, 'learning_rate': 4.420042355482601e-05, 'epoch': 4.25}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 680/800 [27:27<04:50,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 681/800 [27:30<04:48,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 682/800 [27:32<04:46,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 683/800 [27:35<04:44,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 684/800 [27:37<04:41,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 685/800 [27:39<04:38,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 686/800 [27:42<04:36,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 687/800 [27:44<04:33,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 688/800 [27:47<04:31,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 689/800 [27:49<04:28,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 690/800 [27:52<04:26,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 691/800 [27:54<04:23,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 692/800 [27:56<04:21,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 693/800 [27:59<04:18,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 694/800 [28:01<04:16,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 695/800 [28:04<04:14,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 696/800 [28:06<04:11,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 697/800 [28:08<04:09,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 698/800 [28:11<04:06,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 699/800 [28:13<04:04,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 700/800 [28:16<04:02,  2.42s/it]                                                 {'loss': 0.3415, 'grad_norm': 0.27765020728111267, 'learning_rate': 3.127900008376044e-05, 'epoch': 4.38}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 700/800 [28:16<04:02,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 701/800 [28:18<03:59,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 702/800 [28:21<03:57,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 703/800 [28:23<03:54,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 704/800 [28:25<03:52,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 705/800 [28:28<03:49,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 706/800 [28:30<03:47,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 707/800 [28:33<03:45,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 708/800 [28:35<03:43,  2.43s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 709/800 [28:38<03:40,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 710/800 [28:40<03:38,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 711/800 [28:42<03:35,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 712/800 [28:45<03:33,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 713/800 [28:47<03:30,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 714/800 [28:50<03:28,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 715/800 [28:52<03:25,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 716/800 [28:54<03:23,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 717/800 [28:57<03:20,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 718/800 [28:59<03:18,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 719/800 [29:02<03:15,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 720/800 [29:04<03:14,  2.43s/it]                                                 {'loss': 0.3472, 'grad_norm': 0.3174089789390564, 'learning_rate': 2.0463979406949023e-05, 'epoch': 4.5}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 720/800 [29:04<03:14,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 721/800 [29:07<03:11,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 722/800 [29:09<03:09,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 723/800 [29:11<03:06,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 724/800 [29:14<03:03,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 725/800 [29:16<03:01,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 726/800 [29:19<02:59,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 727/800 [29:21<02:56,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 728/800 [29:24<02:54,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 729/800 [29:26<02:51,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 730/800 [29:28<02:49,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 731/800 [29:31<02:46,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 732/800 [29:33<02:44,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 733/800 [29:36<02:42,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 734/800 [29:38<02:39,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 735/800 [29:40<02:37,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 736/800 [29:43<02:34,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 737/800 [29:45<02:32,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 738/800 [29:48<02:30,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 739/800 [29:50<02:27,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 740/800 [29:53<02:25,  2.42s/it]                                                 {'loss': 0.3281, 'grad_norm': 0.25584128499031067, 'learning_rate': 1.185951608560118e-05, 'epoch': 4.62}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 740/800 [29:53<02:25,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 741/800 [29:55<02:22,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 742/800 [29:57<02:20,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 743/800 [30:00<02:17,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 744/800 [30:02<02:15,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 745/800 [30:05<02:13,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 746/800 [30:07<02:10,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 747/800 [30:10<02:08,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 748/800 [30:12<02:05,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 749/800 [30:14<02:03,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 750/800 [30:17<02:01,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 751/800 [30:19<01:59,  2.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 752/800 [30:22<01:56,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 753/800 [30:24<01:54,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 754/800 [30:27<01:51,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 755/800 [30:29<01:49,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 756/800 [30:31<01:46,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 757/800 [30:34<01:44,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 758/800 [30:36<01:41,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 759/800 [30:39<01:39,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 760/800 [30:41<01:36,  2.42s/it]                                                 {'loss': 0.3467, 'grad_norm': 0.2788195312023163, 'learning_rate': 5.548475805179587e-06, 'epoch': 4.75}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 760/800 [30:41<01:36,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 761/800 [30:43<01:34,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 762/800 [30:46<01:31,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 763/800 [30:48<01:29,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 764/800 [30:51<01:27,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 765/800 [30:53<01:25,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 766/800 [30:56<01:22,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 767/800 [30:58<01:20,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 768/800 [31:00<01:17,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 769/800 [31:03<01:15,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 770/800 [31:05<01:12,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 771/800 [31:08<01:10,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 772/800 [31:10<01:07,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 773/800 [31:13<01:05,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 774/800 [31:15<01:02,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 775/800 [31:17<01:00,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 776/800 [31:20<00:58,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 777/800 [31:22<00:55,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 778/800 [31:25<00:53,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 779/800 [31:27<00:50,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 780/800 [31:29<00:48,  2.42s/it]                                                 {'loss': 0.3464, 'grad_norm': 0.3104519844055176, 'learning_rate': 1.5916373335503054e-06, 'epoch': 4.88}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 780/800 [31:29<00:48,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 781/800 [31:32<00:45,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 782/800 [31:34<00:43,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 783/800 [31:37<00:41,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 784/800 [31:39<00:38,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 785/800 [31:42<00:36,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 786/800 [31:44<00:33,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 787/800 [31:46<00:31,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 788/800 [31:49<00:29,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 789/800 [31:51<00:26,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 790/800 [31:54<00:24,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 791/800 [31:56<00:21,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 792/800 [31:59<00:19,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 793/800 [32:01<00:16,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 794/800 [32:03<00:14,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 795/800 [32:06<00:12,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 796/800 [32:08<00:09,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 797/800 [32:11<00:07,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 798/800 [32:13<00:04,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 799/800 [32:15<00:02,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:18<00:00,  2.42s/it]                                                 {'loss': 0.3364, 'grad_norm': 0.23565912246704102, 'learning_rate': 2.7107188222991187e-08, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:18<00:00,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 03:36:23,815 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_topic/checkpoint-800
[INFO|configuration_utils.py:726] 2024-05-25 03:36:25,180 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:36:25,182 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 03:36:26,427 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:36:26,429 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 03:36:26,481 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_topic/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 03:36:26,482 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_topic/checkpoint-800/special_tokens_map.json
[INFO|trainer.py:2231] 2024-05-25 03:36:26,609 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 1950.551, 'train_samples_per_second': 3.279, 'train_steps_per_second': 0.41, 'train_loss': 0.46862020671367643, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:21<00:00,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:21<00:00,  2.43s/it]
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4686
  train_runtime            = 0:32:30.55
  train_samples_per_second =      3.279
  train_steps_per_second   =       0.41
[INFO|trainer.py:3203] 2024-05-25 03:36:26,615 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_topic
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-05-25 03:36:27,545 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:36:27,547 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 03:36:28,035 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:36:28,037 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 03:36:28,078 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_topic/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 03:36:28,079 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_topic/special_tokens_map.json
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:471] 2024-05-25 03:36:28,461 >> Configuration saved in /scratch/tathagato/adapter_experiments/length_then_topic/final_merged_model/config.json
[INFO|configuration_utils.py:697] 2024-05-25 03:36:28,463 >> Configuration saved in /scratch/tathagato/adapter_experiments/length_then_topic/final_merged_model/generation_config.json
[INFO|modeling_utils.py:2474] 2024-05-25 03:36:34,839 >> Model weights saved in /scratch/tathagato/adapter_experiments/length_then_topic/final_merged_model/model.safetensors
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.029 MB uploadedwandb: / 0.008 MB of 0.032 MB uploadedwandb: - 0.032 MB of 0.032 MB uploadedwandb: \ 0.032 MB of 0.032 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ
wandb: train/learning_rate ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 8.17116991193088e+16
wandb:              train/epoch 5.0
wandb:        train/global_step 800
wandb:          train/grad_norm 0.23566
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.3364
wandb:               train_loss 0.46862
wandb:            train_runtime 1950.551
wandb: train_samples_per_second 3.279
wandb:   train_steps_per_second 0.41
wandb: 
wandb: üöÄ View run trim-salad-98 at: https://wandb.ai/ihub-drug-discovery/huggingface/runs/ju0x0lyr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ihub-drug-discovery/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240525_030358-ju0x0lyr/logs
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-05-25 03:37:05 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:37:05 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:37:05 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:37:05 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 03:37:05 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0005,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/tathagato/adapter_experiments/length_then_extractiveness/runs/May25_03-37-05_gnode081,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=20,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/tathagato/adapter_experiments/length_then_extractiveness,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/tathagato/adapter_experiments/length_then_extractiveness,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=400,
save_strategy=steps,
save_total_limit=400,
seed=0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
2024-05-25 03:37:05 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'o_proj', 'q_proj', 'v_proj', 'k_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
[INFO|configuration_utils.py:726] 2024-05-25 03:37:06,444 >> loading configuration file config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:37:06,448 >> Model config LlamaConfig {
  "_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": false,
  "vocab_size": 32000
}

[WARNING|modeling_utils.py:3058] 2024-05-25 03:37:06,509 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 03:37:06,509 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 03:37:06,522 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|quantizer_bnb_4bit.py:247] 2024-05-25 03:37:06,542 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[WARNING|modeling_utils.py:3058] 2024-05-25 03:37:06,542 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:3283] 2024-05-25 03:37:06,543 >> loading weights file model.safetensors from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors
[INFO|modeling_utils.py:1417] 2024-05-25 03:37:06,559 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:928] 2024-05-25 03:37:06,561 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[INFO|modeling_utils.py:4024] 2024-05-25 03:37:09,555 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-05-25 03:37:09,555 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-05-25 03:37:09,789 >> loading configuration file generation_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json
[INFO|configuration_utils.py:928] 2024-05-25 03:37:09,789 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

loading model from : /scratch/tathagato/adapter_experiments/length/length
loading model from : /scratch/tathagato/adapter_experiments/length/length
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:37:10,555 >> loading file tokenizer.model from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:37:10,556 >> loading file tokenizer.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:37:10,556 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:37:10,556 >> loading file special_tokens_map.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 03:37:10,556 >> loading file tokenizer_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json
loading model from : /scratch/tathagato/adapter_experiments/length/length
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
loading model from : /scratch/tathagato/adapter_experiments/length/length
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
train dataset size 4278
test dataset size 554
4278
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Spawning 10 processes
2024-05-25 03:37:13 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]train dataset size 4278
test dataset size 554
4278
train dataset size 4278
test dataset size 554
4278
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:13:29,  1.03s/ examples]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:07, 514.55 examples/s]train dataset size 4278
test dataset size 554
4278
Applying chat template to train_sft (num_proc=10):  15%|‚ñà‚ñå        | 662/4278 [00:01<00:06, 573.61 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:05, 599.00 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:01<00:02, 1076.23 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:18:48,  1.11s/ examples]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:14:00,  1.04s/ examples]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:07, 483.30 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1712/4278 [00:02<00:02, 1054.54 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:08, 467.14 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 856/4278 [00:01<00:04, 686.13 examples/s]Applying chat template to train_sft (num_proc=10):  15%|‚ñà‚ñå        | 649/4278 [00:01<00:06, 552.53 examples/s]Applying chat template to train_sft (num_proc=10):  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1958/4278 [00:02<00:02, 934.34 examples/s] Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 856/4278 [00:01<00:04, 749.47 examples/s]Applying chat template to train_sft (num_proc=10):  25%|‚ñà‚ñà‚ñå       | 1087/4278 [00:02<00:04, 679.54 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2141/4278 [00:03<00:02, 770.13 examples/s]Applying chat template to train_sft (num_proc=10):  25%|‚ñà‚ñà‚ñç       | 1065/4278 [00:01<00:04, 721.78 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2568/4278 [00:03<00:01, 1157.99 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:23:41,  1.17s/ examples]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:02<00:04, 617.11 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:09, 425.82 examples/s]Applying chat template to train_sft (num_proc=10):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2813/4278 [00:03<00:01, 1005.93 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:02<00:04, 624.54 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1712/4278 [00:02<00:02, 1053.22 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 759.38 examples/s]Applying chat template to train_sft (num_proc=10):  15%|‚ñà‚ñå        | 650/4278 [00:01<00:07, 485.92 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:02<00:01, 1118.51 examples/s]Applying chat template to train_sft (num_proc=10):  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1921/4278 [00:02<00:02, 926.33 examples/s] Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:03<00:01, 780.90 examples/s] Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:02<00:01, 1089.31 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/4278 [00:04<00:00, 1139.25 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:02<00:06, 534.45 examples/s]Applying chat template to train_sft (num_proc=10):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2360/4278 [00:03<00:01, 979.51 examples/s] Applying chat template to train_sft (num_proc=10):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3639/4278 [00:04<00:00, 1075.06 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:02<00:03, 893.58 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2568/4278 [00:03<00:01, 1080.27 examples/s]Applying chat template to train_sft (num_proc=10):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2405/4278 [00:03<00:01, 975.35 examples/s] Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1198.94 examples/s]Applying chat template to train_sft (num_proc=10):  35%|‚ñà‚ñà‚ñà‚ñå      | 1505/4278 [00:02<00:03, 813.03 examples/s]Applying chat template to train_sft (num_proc=10):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2794/4278 [00:03<00:01, 832.13 examples/s] Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:03<00:02, 738.08 examples/s]Applying chat template to train_sft (num_proc=10):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4079/4278 [00:04<00:00, 940.19 examples/s] Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:03<00:01, 1140.95 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 693.29 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:04<00:01, 764.32 examples/s]Applying chat template to train_sft (num_proc=10):  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3179/4278 [00:04<00:01, 1029.48 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 823.25 examples/s]
Applying chat template to train_sft (num_proc=10):  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3391/4278 [00:04<00:00, 1186.48 examples/s]Concatenating 10 shards
2024-05-25 03:37:18 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2141/4278 [00:03<00:02, 791.73 examples/s]Applying chat template to train_sft (num_proc=10):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3669/4278 [00:04<00:00, 913.66 examples/s] Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:01, 706.05 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1026.40 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:03<00:01, 888.65 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3852/4278 [00:04<00:00, 815.89 examples/s]Spawning 10 processes
2024-05-25 03:37:19 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:03<00:01, 1198.52 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:04<00:00, 1237.20 examples/s]Applying chat template to train_sft (num_proc=10):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4080/4278 [00:05<00:00, 935.78 examples/s] Applying chat template to train_sft (num_proc=10):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3190/4278 [00:04<00:01, 991.75 examples/s] Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 813.78 examples/s] 
Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 762.49 examples/s]
Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:08,  1.79 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:00, 916.02 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 112/554 [00:00<00:02, 214.56 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1292.61 examples/s]Applying chat template to test_sft (num_proc=10):  31%|‚ñà‚ñà‚ñà       | 169/554 [00:00<00:01, 260.37 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:00<00:00, 406.24 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 389/554 [00:01<00:00, 552.46 examples/s]Applying chat template to train_sft (num_proc=10):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4108/4278 [00:05<00:00, 1058.55 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 617.41 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 791.35 examples/s] 
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 348.39 examples/s]
Concatenating 10 shards
2024-05-25 03:37:21 - INFO - datasets.arrow_dataset - Concatenating 10 shards
tokenizer padding side left
Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:10,  1.78 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 189.71 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:49,  1.58 examples/s]Applying chat template to test_sft (num_proc=10):  31%|‚ñà‚ñà‚ñà       | 169/554 [00:00<00:01, 253.12 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:01, 312.48 examples/s]Using custom data configuration default-37faee928f8259ce
2024-05-25 03:37:21 - INFO - datasets.builder - Using custom data configuration default-37faee928f8259ce
Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
2024-05-25 03:37:21 - INFO - datasets.info - Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
Overwrite dataset info from restored data version if exists.
2024-05-25 03:37:21 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
2024-05-25 03:37:21 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0)
2024-05-25 03:37:21 - INFO - datasets.builder - Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0)
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
2024-05-25 03:37:21 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 174.36 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 338.30 examples/s]Applying chat template to test_sft (num_proc=10):  31%|‚ñà‚ñà‚ñà       | 169/554 [00:00<00:01, 229.84 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 390/554 [00:01<00:00, 494.17 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 396.62 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 538.87 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 389/554 [00:01<00:00, 466.83 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 495.56 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<04:09,  2.22 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 320.80 examples/s]
Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 216.15 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 320.53 examples/s]
Applying chat template to test_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 224/554 [00:00<00:00, 402.34 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 334/554 [00:00<00:00, 458.57 examples/s]Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 444/554 [00:01<00:00, 517.36 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 570.39 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 374.05 examples/s]
tokenizer padding side left
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
2024-05-25 03:37:23 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
[INFO|trainer.py:607] 2024-05-25 03:37:25,015 >> Using auto half precision backend
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:1969] 2024-05-25 03:37:25,723 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-05-25 03:37:25,723 >>   Num examples = 2,462
[INFO|trainer.py:1971] 2024-05-25 03:37:25,723 >>   Num Epochs = 5
[INFO|trainer.py:1972] 2024-05-25 03:37:25,723 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-05-25 03:37:25,723 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-05-25 03:37:25,723 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-05-25 03:37:25,723 >>   Total optimization steps = 1,540
[INFO|trainer.py:1978] 2024-05-25 03:37:25,725 >>   Number of trainable parameters = 4,505,600
[INFO|integration_utils.py:723] 2024-05-25 03:37:25,789 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: roy3 (ihub-drug-discovery). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home2/tathagato/summarization/MACSum/experiments/wandb/run-20240525_033728-9u7o4mjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-snowflake-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ihub-drug-discovery/huggingface
wandb: üöÄ View run at https://wandb.ai/ihub-drug-discovery/huggingface/runs/9u7o4mjh
  0%|          | 0/1540 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1540 [00:02<1:03:22,  2.47s/it]  0%|          | 2/1540 [00:04<1:02:20,  2.43s/it]  0%|          | 3/1540 [00:07<1:01:59,  2.42s/it]  0%|          | 4/1540 [00:09<1:01:48,  2.41s/it]  0%|          | 5/1540 [00:12<1:01:40,  2.41s/it]  0%|          | 6/1540 [00:14<1:01:35,  2.41s/it]  0%|          | 7/1540 [00:16<1:01:32,  2.41s/it]  1%|          | 8/1540 [00:19<1:01:30,  2.41s/it]  1%|          | 9/1540 [00:21<1:01:27,  2.41s/it]  1%|          | 10/1540 [00:24<1:01:25,  2.41s/it]  1%|          | 11/1540 [00:26<1:01:24,  2.41s/it]  1%|          | 12/1540 [00:29<1:02:05,  2.44s/it]  1%|          | 13/1540 [00:31<1:02:09,  2.44s/it]  1%|          | 14/1540 [00:33<1:01:56,  2.44s/it]  1%|          | 15/1540 [00:36<1:01:43,  2.43s/it]  1%|          | 16/1540 [00:38<1:01:33,  2.42s/it]  1%|          | 17/1540 [00:41<1:01:26,  2.42s/it]  1%|          | 18/1540 [00:43<1:01:21,  2.42s/it]  1%|          | 19/1540 [00:45<1:01:15,  2.42s/it]  1%|‚ñè         | 20/1540 [00:48<1:01:12,  2.42s/it]                                                   {'loss': 0.7015, 'grad_norm': 0.49373891949653625, 'learning_rate': 3.246753246753247e-05, 'epoch': 0.06}
  1%|‚ñè         | 20/1540 [00:48<1:01:12,  2.42s/it]  1%|‚ñè         | 21/1540 [00:50<1:01:12,  2.42s/it]  1%|‚ñè         | 22/1540 [00:53<1:01:10,  2.42s/it]  1%|‚ñè         | 23/1540 [00:55<1:01:08,  2.42s/it]  2%|‚ñè         | 24/1540 [00:58<1:01:05,  2.42s/it]  2%|‚ñè         | 25/1540 [01:00<1:01:04,  2.42s/it]  2%|‚ñè         | 26/1540 [01:02<1:01:11,  2.43s/it]  2%|‚ñè         | 27/1540 [01:05<1:01:04,  2.42s/it]  2%|‚ñè         | 28/1540 [01:07<1:00:59,  2.42s/it]  2%|‚ñè         | 29/1540 [01:10<1:01:10,  2.43s/it]  2%|‚ñè         | 30/1540 [01:12<1:01:03,  2.43s/it]  2%|‚ñè         | 31/1540 [01:15<1:00:57,  2.42s/it]  2%|‚ñè         | 32/1540 [01:17<1:00:52,  2.42s/it]  2%|‚ñè         | 33/1540 [01:19<1:00:49,  2.42s/it]  2%|‚ñè         | 34/1540 [01:22<1:00:46,  2.42s/it]  2%|‚ñè         | 35/1540 [01:24<1:00:42,  2.42s/it]  2%|‚ñè         | 36/1540 [01:27<1:00:39,  2.42s/it]  2%|‚ñè         | 37/1540 [01:29<1:00:36,  2.42s/it]  2%|‚ñè         | 38/1540 [01:31<1:00:34,  2.42s/it]  3%|‚ñé         | 39/1540 [01:34<1:00:32,  2.42s/it]  3%|‚ñé         | 40/1540 [01:36<1:00:29,  2.42s/it]                                                   {'loss': 0.6736, 'grad_norm': 0.5405275225639343, 'learning_rate': 6.33116883116883e-05, 'epoch': 0.13}
  3%|‚ñé         | 40/1540 [01:36<1:00:29,  2.42s/it]  3%|‚ñé         | 41/1540 [01:39<1:00:28,  2.42s/it]  3%|‚ñé         | 42/1540 [01:41<1:00:40,  2.43s/it]  3%|‚ñé         | 43/1540 [01:44<1:00:34,  2.43s/it]  3%|‚ñé         | 44/1540 [01:46<1:00:28,  2.43s/it]  3%|‚ñé         | 45/1540 [01:48<1:00:23,  2.42s/it]  3%|‚ñé         | 46/1540 [01:51<1:00:20,  2.42s/it]  3%|‚ñé         | 47/1540 [01:53<1:00:17,  2.42s/it]  3%|‚ñé         | 48/1540 [01:56<1:00:13,  2.42s/it]  3%|‚ñé         | 49/1540 [01:58<1:00:11,  2.42s/it]  3%|‚ñé         | 50/1540 [02:01<1:00:08,  2.42s/it]  3%|‚ñé         | 51/1540 [02:03<1:00:06,  2.42s/it]  3%|‚ñé         | 52/1540 [02:05<1:00:03,  2.42s/it]  3%|‚ñé         | 53/1540 [02:08<1:00:00,  2.42s/it]  4%|‚ñé         | 54/1540 [02:10<1:00:07,  2.43s/it]  4%|‚ñé         | 55/1540 [02:13<1:00:02,  2.43s/it]  4%|‚ñé         | 56/1540 [02:15<1:00:33,  2.45s/it]  4%|‚ñé         | 57/1540 [02:18<1:00:18,  2.44s/it]  4%|‚ñç         | 58/1540 [02:20<1:00:08,  2.43s/it]  4%|‚ñç         | 59/1540 [02:22<59:59,  2.43s/it]    4%|‚ñç         | 60/1540 [02:25<59:52,  2.43s/it]                                                 {'loss': 0.6446, 'grad_norm': 0.49160313606262207, 'learning_rate': 9.577922077922078e-05, 'epoch': 0.19}
  4%|‚ñç         | 60/1540 [02:25<59:52,  2.43s/it]  4%|‚ñç         | 61/1540 [02:27<59:48,  2.43s/it]  4%|‚ñç         | 62/1540 [02:30<59:43,  2.42s/it]  4%|‚ñç         | 63/1540 [02:32<59:39,  2.42s/it]  4%|‚ñç         | 64/1540 [02:35<59:35,  2.42s/it]  4%|‚ñç         | 65/1540 [02:37<59:32,  2.42s/it]  4%|‚ñç         | 66/1540 [02:39<59:30,  2.42s/it]  4%|‚ñç         | 67/1540 [02:42<59:27,  2.42s/it]  4%|‚ñç         | 68/1540 [02:44<59:34,  2.43s/it]  4%|‚ñç         | 69/1540 [02:47<59:28,  2.43s/it]  5%|‚ñç         | 70/1540 [02:49<59:36,  2.43s/it]  5%|‚ñç         | 71/1540 [02:52<59:28,  2.43s/it]  5%|‚ñç         | 72/1540 [02:54<59:22,  2.43s/it]  5%|‚ñç         | 73/1540 [02:56<59:17,  2.43s/it]  5%|‚ñç         | 74/1540 [02:59<59:14,  2.42s/it]  5%|‚ñç         | 75/1540 [03:01<59:10,  2.42s/it]  5%|‚ñç         | 76/1540 [03:04<59:08,  2.42s/it]  5%|‚ñå         | 77/1540 [03:06<59:04,  2.42s/it]  5%|‚ñå         | 78/1540 [03:09<59:00,  2.42s/it]  5%|‚ñå         | 79/1540 [03:11<58:58,  2.42s/it]  5%|‚ñå         | 80/1540 [03:13<58:55,  2.42s/it]                                                 {'loss': 0.6608, 'grad_norm': 0.4785288870334625, 'learning_rate': 0.00012824675324675324, 'epoch': 0.26}
  5%|‚ñå         | 80/1540 [03:13<58:55,  2.42s/it]  5%|‚ñå         | 81/1540 [03:16<58:53,  2.42s/it]  5%|‚ñå         | 82/1540 [03:18<58:50,  2.42s/it]  5%|‚ñå         | 83/1540 [03:21<59:02,  2.43s/it]  5%|‚ñå         | 84/1540 [03:23<58:55,  2.43s/it]  6%|‚ñå         | 85/1540 [03:26<58:50,  2.43s/it]  6%|‚ñå         | 86/1540 [03:28<58:46,  2.43s/it]  6%|‚ñå         | 87/1540 [03:30<58:42,  2.42s/it]  6%|‚ñå         | 88/1540 [03:33<58:38,  2.42s/it]  6%|‚ñå         | 89/1540 [03:35<58:35,  2.42s/it]  6%|‚ñå         | 90/1540 [03:38<58:32,  2.42s/it]  6%|‚ñå         | 91/1540 [03:40<58:30,  2.42s/it]  6%|‚ñå         | 92/1540 [03:42<58:27,  2.42s/it]  6%|‚ñå         | 93/1540 [03:45<58:24,  2.42s/it]  6%|‚ñå         | 94/1540 [03:47<58:22,  2.42s/it]  6%|‚ñå         | 95/1540 [03:50<58:19,  2.42s/it]  6%|‚ñå         | 96/1540 [03:52<58:17,  2.42s/it]  6%|‚ñã         | 97/1540 [03:55<58:14,  2.42s/it]  6%|‚ñã         | 98/1540 [03:57<58:22,  2.43s/it]  6%|‚ñã         | 99/1540 [03:59<58:17,  2.43s/it]  6%|‚ñã         | 100/1540 [04:02<58:12,  2.43s/it]                                                  {'loss': 0.6762, 'grad_norm': 0.3613786995410919, 'learning_rate': 0.00016071428571428573, 'epoch': 0.32}
  6%|‚ñã         | 100/1540 [04:02<58:12,  2.43s/it]  7%|‚ñã         | 101/1540 [04:04<58:08,  2.42s/it]  7%|‚ñã         | 102/1540 [04:07<58:04,  2.42s/it]  7%|‚ñã         | 103/1540 [04:09<58:00,  2.42s/it]  7%|‚ñã         | 104/1540 [04:12<57:57,  2.42s/it]  7%|‚ñã         | 105/1540 [04:14<57:54,  2.42s/it]  7%|‚ñã         | 106/1540 [04:16<57:51,  2.42s/it]  7%|‚ñã         | 107/1540 [04:19<57:48,  2.42s/it]  7%|‚ñã         | 108/1540 [04:21<57:46,  2.42s/it]  7%|‚ñã         | 109/1540 [04:24<57:43,  2.42s/it]  7%|‚ñã         | 110/1540 [04:26<57:40,  2.42s/it]  7%|‚ñã         | 111/1540 [04:29<57:50,  2.43s/it]  7%|‚ñã         | 112/1540 [04:31<57:54,  2.43s/it]  7%|‚ñã         | 113/1540 [04:33<57:45,  2.43s/it]  7%|‚ñã         | 114/1540 [04:36<57:39,  2.43s/it]  7%|‚ñã         | 115/1540 [04:38<57:34,  2.42s/it]  8%|‚ñä         | 116/1540 [04:41<57:30,  2.42s/it]  8%|‚ñä         | 117/1540 [04:43<57:26,  2.42s/it]  8%|‚ñä         | 118/1540 [04:45<57:22,  2.42s/it]  8%|‚ñä         | 119/1540 [04:48<57:20,  2.42s/it]  8%|‚ñä         | 120/1540 [04:50<57:17,  2.42s/it]                                                  {'loss': 0.6468, 'grad_norm': 0.366914838552475, 'learning_rate': 0.00019318181818181817, 'epoch': 0.39}
  8%|‚ñä         | 120/1540 [04:50<57:17,  2.42s/it]  8%|‚ñä         | 121/1540 [04:53<57:15,  2.42s/it]  8%|‚ñä         | 122/1540 [04:55<57:11,  2.42s/it]  8%|‚ñä         | 123/1540 [04:58<57:08,  2.42s/it]  8%|‚ñä         | 124/1540 [05:00<57:06,  2.42s/it]  8%|‚ñä         | 125/1540 [05:02<57:03,  2.42s/it]  8%|‚ñä         | 126/1540 [05:05<57:31,  2.44s/it]  8%|‚ñä         | 127/1540 [05:07<57:20,  2.43s/it]  8%|‚ñä         | 128/1540 [05:10<57:11,  2.43s/it]  8%|‚ñä         | 129/1540 [05:12<57:04,  2.43s/it]  8%|‚ñä         | 130/1540 [05:15<56:58,  2.42s/it]  9%|‚ñä         | 131/1540 [05:17<56:54,  2.42s/it]  9%|‚ñä         | 132/1540 [05:19<56:49,  2.42s/it]  9%|‚ñä         | 133/1540 [05:22<56:46,  2.42s/it]  9%|‚ñä         | 134/1540 [05:24<56:43,  2.42s/it]  9%|‚ñâ         | 135/1540 [05:27<56:40,  2.42s/it]  9%|‚ñâ         | 136/1540 [05:29<56:37,  2.42s/it]  9%|‚ñâ         | 137/1540 [05:32<56:35,  2.42s/it]  9%|‚ñâ         | 138/1540 [05:34<56:34,  2.42s/it]  9%|‚ñâ         | 139/1540 [05:36<56:44,  2.43s/it]  9%|‚ñâ         | 140/1540 [05:39<56:37,  2.43s/it]                                                  {'loss': 0.6224, 'grad_norm': 0.40950146317481995, 'learning_rate': 0.00022564935064935067, 'epoch': 0.45}
  9%|‚ñâ         | 140/1540 [05:39<56:37,  2.43s/it]  9%|‚ñâ         | 141/1540 [05:41<56:32,  2.43s/it]  9%|‚ñâ         | 142/1540 [05:44<56:27,  2.42s/it]  9%|‚ñâ         | 143/1540 [05:46<56:23,  2.42s/it]  9%|‚ñâ         | 144/1540 [05:48<56:20,  2.42s/it]  9%|‚ñâ         | 145/1540 [05:51<56:18,  2.42s/it]  9%|‚ñâ         | 146/1540 [05:53<56:14,  2.42s/it] 10%|‚ñâ         | 147/1540 [05:56<56:11,  2.42s/it] 10%|‚ñâ         | 148/1540 [05:58<56:08,  2.42s/it] 10%|‚ñâ         | 149/1540 [06:01<56:07,  2.42s/it] 10%|‚ñâ         | 150/1540 [06:03<56:05,  2.42s/it] 10%|‚ñâ         | 151/1540 [06:05<56:02,  2.42s/it] 10%|‚ñâ         | 152/1540 [06:08<56:13,  2.43s/it] 10%|‚ñâ         | 153/1540 [06:10<56:06,  2.43s/it] 10%|‚ñà         | 154/1540 [06:13<56:00,  2.42s/it] 10%|‚ñà         | 155/1540 [06:15<56:11,  2.43s/it] 10%|‚ñà         | 156/1540 [06:18<56:03,  2.43s/it] 10%|‚ñà         | 157/1540 [06:20<55:56,  2.43s/it] 10%|‚ñà         | 158/1540 [06:22<55:50,  2.42s/it] 10%|‚ñà         | 159/1540 [06:25<55:45,  2.42s/it] 10%|‚ñà         | 160/1540 [06:27<55:42,  2.42s/it]                                                  {'loss': 0.6269, 'grad_norm': 0.36692097783088684, 'learning_rate': 0.00025811688311688314, 'epoch': 0.52}
 10%|‚ñà         | 160/1540 [06:27<55:42,  2.42s/it] 10%|‚ñà         | 161/1540 [06:30<55:39,  2.42s/it] 11%|‚ñà         | 162/1540 [06:32<55:36,  2.42s/it] 11%|‚ñà         | 163/1540 [06:35<55:33,  2.42s/it] 11%|‚ñà         | 164/1540 [06:37<55:30,  2.42s/it] 11%|‚ñà         | 165/1540 [06:39<55:27,  2.42s/it] 11%|‚ñà         | 166/1540 [06:42<55:25,  2.42s/it] 11%|‚ñà         | 167/1540 [06:44<55:22,  2.42s/it] 11%|‚ñà         | 168/1540 [06:47<55:37,  2.43s/it] 11%|‚ñà         | 169/1540 [06:49<55:29,  2.43s/it] 11%|‚ñà         | 170/1540 [06:52<55:24,  2.43s/it] 11%|‚ñà         | 171/1540 [06:54<55:18,  2.42s/it] 11%|‚ñà         | 172/1540 [06:56<55:14,  2.42s/it] 11%|‚ñà         | 173/1540 [06:59<55:10,  2.42s/it] 11%|‚ñà‚ñè        | 174/1540 [07:01<55:07,  2.42s/it] 11%|‚ñà‚ñè        | 175/1540 [07:04<55:04,  2.42s/it] 11%|‚ñà‚ñè        | 176/1540 [07:06<55:01,  2.42s/it] 11%|‚ñà‚ñè        | 177/1540 [07:08<54:59,  2.42s/it] 12%|‚ñà‚ñè        | 178/1540 [07:11<54:57,  2.42s/it] 12%|‚ñà‚ñè        | 179/1540 [07:13<54:54,  2.42s/it] 12%|‚ñà‚ñè        | 180/1540 [07:16<54:52,  2.42s/it]                                                  {'loss': 0.5816, 'grad_norm': 0.31835511326789856, 'learning_rate': 0.0002905844155844156, 'epoch': 0.58}
 12%|‚ñà‚ñè        | 180/1540 [07:16<54:52,  2.42s/it] 12%|‚ñà‚ñè        | 181/1540 [07:18<54:59,  2.43s/it] 12%|‚ñà‚ñè        | 182/1540 [07:21<54:54,  2.43s/it] 12%|‚ñà‚ñè        | 183/1540 [07:23<54:49,  2.42s/it] 12%|‚ñà‚ñè        | 184/1540 [07:25<55:02,  2.44s/it] 12%|‚ñà‚ñè        | 185/1540 [07:28<54:53,  2.43s/it] 12%|‚ñà‚ñè        | 186/1540 [07:30<54:46,  2.43s/it] 12%|‚ñà‚ñè        | 187/1540 [07:33<54:41,  2.43s/it] 12%|‚ñà‚ñè        | 188/1540 [07:35<54:36,  2.42s/it] 12%|‚ñà‚ñè        | 189/1540 [07:38<54:33,  2.42s/it] 12%|‚ñà‚ñè        | 190/1540 [07:40<54:29,  2.42s/it] 12%|‚ñà‚ñè        | 191/1540 [07:42<54:26,  2.42s/it] 12%|‚ñà‚ñè        | 192/1540 [07:45<54:23,  2.42s/it] 13%|‚ñà‚ñé        | 193/1540 [07:47<54:20,  2.42s/it] 13%|‚ñà‚ñé        | 194/1540 [07:50<54:17,  2.42s/it] 13%|‚ñà‚ñé        | 195/1540 [07:52<54:46,  2.44s/it] 13%|‚ñà‚ñé        | 196/1540 [07:55<54:34,  2.44s/it] 13%|‚ñà‚ñé        | 197/1540 [07:57<54:25,  2.43s/it] 13%|‚ñà‚ñé        | 198/1540 [07:59<54:18,  2.43s/it] 13%|‚ñà‚ñé        | 199/1540 [08:02<54:26,  2.44s/it] 13%|‚ñà‚ñé        | 200/1540 [08:04<54:16,  2.43s/it]                                                  {'loss': 0.59, 'grad_norm': 0.3797699213027954, 'learning_rate': 0.000323051948051948, 'epoch': 0.65}
 13%|‚ñà‚ñé        | 200/1540 [08:04<54:16,  2.43s/it] 13%|‚ñà‚ñé        | 201/1540 [08:07<54:12,  2.43s/it] 13%|‚ñà‚ñé        | 202/1540 [08:09<54:07,  2.43s/it] 13%|‚ñà‚ñé        | 203/1540 [08:12<54:02,  2.43s/it] 13%|‚ñà‚ñé        | 204/1540 [08:14<53:58,  2.42s/it] 13%|‚ñà‚ñé        | 205/1540 [08:16<53:54,  2.42s/it] 13%|‚ñà‚ñé        | 206/1540 [08:19<53:50,  2.42s/it] 13%|‚ñà‚ñé        | 207/1540 [08:21<53:47,  2.42s/it] 14%|‚ñà‚ñé        | 208/1540 [08:24<53:44,  2.42s/it] 14%|‚ñà‚ñé        | 209/1540 [08:26<53:56,  2.43s/it] 14%|‚ñà‚ñé        | 210/1540 [08:29<53:49,  2.43s/it] 14%|‚ñà‚ñé        | 211/1540 [08:31<53:43,  2.43s/it] 14%|‚ñà‚ñç        | 212/1540 [08:33<53:38,  2.42s/it] 14%|‚ñà‚ñç        | 213/1540 [08:36<53:42,  2.43s/it] 14%|‚ñà‚ñç        | 214/1540 [08:38<53:37,  2.43s/it] 14%|‚ñà‚ñç        | 215/1540 [08:41<53:32,  2.42s/it] 14%|‚ñà‚ñç        | 216/1540 [08:43<53:28,  2.42s/it] 14%|‚ñà‚ñç        | 217/1540 [08:46<53:24,  2.42s/it] 14%|‚ñà‚ñç        | 218/1540 [08:48<53:21,  2.42s/it] 14%|‚ñà‚ñç        | 219/1540 [08:50<53:18,  2.42s/it] 14%|‚ñà‚ñç        | 220/1540 [08:53<53:18,  2.42s/it]                                                  {'loss': 0.6099, 'grad_norm': 0.3769649863243103, 'learning_rate': 0.00035551948051948054, 'epoch': 0.71}
 14%|‚ñà‚ñç        | 220/1540 [08:53<53:18,  2.42s/it] 14%|‚ñà‚ñç        | 221/1540 [08:55<53:15,  2.42s/it] 14%|‚ñà‚ñç        | 222/1540 [08:58<53:29,  2.44s/it] 14%|‚ñà‚ñç        | 223/1540 [09:00<53:21,  2.43s/it] 15%|‚ñà‚ñç        | 224/1540 [09:03<53:14,  2.43s/it] 15%|‚ñà‚ñç        | 225/1540 [09:05<53:09,  2.43s/it] 15%|‚ñà‚ñç        | 226/1540 [09:07<53:04,  2.42s/it] 15%|‚ñà‚ñç        | 227/1540 [09:10<53:00,  2.42s/it] 15%|‚ñà‚ñç        | 228/1540 [09:12<53:06,  2.43s/it] 15%|‚ñà‚ñç        | 229/1540 [09:15<53:00,  2.43s/it] 15%|‚ñà‚ñç        | 230/1540 [09:17<52:55,  2.42s/it] 15%|‚ñà‚ñå        | 231/1540 [09:19<52:50,  2.42s/it] 15%|‚ñà‚ñå        | 232/1540 [09:22<52:47,  2.42s/it] 15%|‚ñà‚ñå        | 233/1540 [09:24<52:44,  2.42s/it] 15%|‚ñà‚ñå        | 234/1540 [09:27<52:41,  2.42s/it] 15%|‚ñà‚ñå        | 235/1540 [09:29<52:38,  2.42s/it] 15%|‚ñà‚ñå        | 236/1540 [09:32<52:35,  2.42s/it] 15%|‚ñà‚ñå        | 237/1540 [09:34<52:47,  2.43s/it] 15%|‚ñà‚ñå        | 238/1540 [09:36<52:41,  2.43s/it] 16%|‚ñà‚ñå        | 239/1540 [09:39<52:35,  2.43s/it] 16%|‚ñà‚ñå        | 240/1540 [09:41<52:30,  2.42s/it]                                                  {'loss': 0.5795, 'grad_norm': 0.35368606448173523, 'learning_rate': 0.000387987012987013, 'epoch': 0.78}
 16%|‚ñà‚ñå        | 240/1540 [09:41<52:30,  2.42s/it] 16%|‚ñà‚ñå        | 241/1540 [09:44<52:27,  2.42s/it] 16%|‚ñà‚ñå        | 242/1540 [09:46<52:23,  2.42s/it] 16%|‚ñà‚ñå        | 243/1540 [09:49<52:19,  2.42s/it] 16%|‚ñà‚ñå        | 244/1540 [09:51<52:17,  2.42s/it] 16%|‚ñà‚ñå        | 245/1540 [09:53<52:14,  2.42s/it] 16%|‚ñà‚ñå        | 246/1540 [09:56<52:11,  2.42s/it] 16%|‚ñà‚ñå        | 247/1540 [09:58<52:09,  2.42s/it] 16%|‚ñà‚ñå        | 248/1540 [10:01<52:07,  2.42s/it] 16%|‚ñà‚ñå        | 249/1540 [10:03<52:04,  2.42s/it] 16%|‚ñà‚ñå        | 250/1540 [10:06<52:15,  2.43s/it] 16%|‚ñà‚ñã        | 251/1540 [10:08<52:08,  2.43s/it] 16%|‚ñà‚ñã        | 252/1540 [10:10<52:02,  2.42s/it] 16%|‚ñà‚ñã        | 253/1540 [10:13<51:58,  2.42s/it] 16%|‚ñà‚ñã        | 254/1540 [10:15<51:54,  2.42s/it] 17%|‚ñà‚ñã        | 255/1540 [10:18<51:51,  2.42s/it] 17%|‚ñà‚ñã        | 256/1540 [10:20<51:48,  2.42s/it] 17%|‚ñà‚ñã        | 257/1540 [10:22<51:49,  2.42s/it] 17%|‚ñà‚ñã        | 258/1540 [10:25<51:45,  2.42s/it] 17%|‚ñà‚ñã        | 259/1540 [10:27<51:42,  2.42s/it] 17%|‚ñà‚ñã        | 260/1540 [10:30<51:39,  2.42s/it]                                                  {'loss': 0.6057, 'grad_norm': 0.3642495274543762, 'learning_rate': 0.0004204545454545455, 'epoch': 0.84}
 17%|‚ñà‚ñã        | 260/1540 [10:30<51:39,  2.42s/it] 17%|‚ñà‚ñã        | 261/1540 [10:32<51:37,  2.42s/it] 17%|‚ñà‚ñã        | 262/1540 [10:35<51:34,  2.42s/it] 17%|‚ñà‚ñã        | 263/1540 [10:37<51:31,  2.42s/it] 17%|‚ñà‚ñã        | 264/1540 [10:39<51:29,  2.42s/it] 17%|‚ñà‚ñã        | 265/1540 [10:42<51:54,  2.44s/it] 17%|‚ñà‚ñã        | 266/1540 [10:44<51:44,  2.44s/it] 17%|‚ñà‚ñã        | 267/1540 [10:47<51:34,  2.43s/it] 17%|‚ñà‚ñã        | 268/1540 [10:49<51:29,  2.43s/it] 17%|‚ñà‚ñã        | 269/1540 [10:52<51:23,  2.43s/it] 18%|‚ñà‚ñä        | 270/1540 [10:54<51:18,  2.42s/it] 18%|‚ñà‚ñä        | 271/1540 [10:56<51:17,  2.42s/it] 18%|‚ñà‚ñä        | 272/1540 [10:59<51:12,  2.42s/it] 18%|‚ñà‚ñä        | 273/1540 [11:01<51:08,  2.42s/it] 18%|‚ñà‚ñä        | 274/1540 [11:04<51:05,  2.42s/it] 18%|‚ñà‚ñä        | 275/1540 [11:06<51:01,  2.42s/it] 18%|‚ñà‚ñä        | 276/1540 [11:09<50:59,  2.42s/it] 18%|‚ñà‚ñä        | 277/1540 [11:11<50:56,  2.42s/it] 18%|‚ñà‚ñä        | 278/1540 [11:13<51:04,  2.43s/it] 18%|‚ñà‚ñä        | 279/1540 [11:16<50:58,  2.43s/it] 18%|‚ñà‚ñä        | 280/1540 [11:18<50:54,  2.42s/it]                                                  {'loss': 0.5801, 'grad_norm': 0.2892102599143982, 'learning_rate': 0.00045292207792207794, 'epoch': 0.91}
 18%|‚ñà‚ñä        | 280/1540 [11:18<50:54,  2.42s/it] 18%|‚ñà‚ñä        | 281/1540 [11:21<50:50,  2.42s/it] 18%|‚ñà‚ñä        | 282/1540 [11:23<50:46,  2.42s/it] 18%|‚ñà‚ñä        | 283/1540 [11:25<50:43,  2.42s/it] 18%|‚ñà‚ñä        | 284/1540 [11:28<50:40,  2.42s/it] 19%|‚ñà‚ñä        | 285/1540 [11:30<50:37,  2.42s/it] 19%|‚ñà‚ñä        | 286/1540 [11:33<50:35,  2.42s/it] 19%|‚ñà‚ñä        | 287/1540 [11:35<50:32,  2.42s/it] 19%|‚ñà‚ñä        | 288/1540 [11:38<50:29,  2.42s/it] 19%|‚ñà‚ñâ        | 289/1540 [11:40<50:27,  2.42s/it] 19%|‚ñà‚ñâ        | 290/1540 [11:42<50:24,  2.42s/it] 19%|‚ñà‚ñâ        | 291/1540 [11:45<50:29,  2.43s/it] 19%|‚ñà‚ñâ        | 292/1540 [11:47<50:24,  2.42s/it] 19%|‚ñà‚ñâ        | 293/1540 [11:50<50:20,  2.42s/it] 19%|‚ñà‚ñâ        | 294/1540 [11:52<50:17,  2.42s/it] 19%|‚ñà‚ñâ        | 295/1540 [11:55<50:14,  2.42s/it] 19%|‚ñà‚ñâ        | 296/1540 [11:57<50:11,  2.42s/it] 19%|‚ñà‚ñâ        | 297/1540 [11:59<50:08,  2.42s/it] 19%|‚ñà‚ñâ        | 298/1540 [12:02<50:06,  2.42s/it] 19%|‚ñà‚ñâ        | 299/1540 [12:04<50:03,  2.42s/it] 19%|‚ñà‚ñâ        | 300/1540 [12:07<50:01,  2.42s/it]                                                  {'loss': 0.612, 'grad_norm': 0.3086460530757904, 'learning_rate': 0.00048538961038961035, 'epoch': 0.97}
 19%|‚ñà‚ñâ        | 300/1540 [12:07<50:01,  2.42s/it] 20%|‚ñà‚ñâ        | 301/1540 [12:09<49:59,  2.42s/it] 20%|‚ñà‚ñâ        | 302/1540 [12:11<49:57,  2.42s/it] 20%|‚ñà‚ñâ        | 303/1540 [12:14<49:54,  2.42s/it] 20%|‚ñà‚ñâ        | 304/1540 [12:16<49:51,  2.42s/it] 20%|‚ñà‚ñâ        | 305/1540 [12:19<49:48,  2.42s/it] 20%|‚ñà‚ñâ        | 306/1540 [12:21<49:46,  2.42s/it] 20%|‚ñà‚ñâ        | 307/1540 [12:24<49:56,  2.43s/it] 20%|‚ñà‚ñà        | 308/1540 [12:26<49:48,  2.43s/it] 20%|‚ñà‚ñà        | 309/1540 [12:28<49:45,  2.42s/it] 20%|‚ñà‚ñà        | 310/1540 [12:31<49:41,  2.42s/it] 20%|‚ñà‚ñà        | 311/1540 [12:33<49:37,  2.42s/it] 20%|‚ñà‚ñà        | 312/1540 [12:36<49:33,  2.42s/it] 20%|‚ñà‚ñà        | 313/1540 [12:38<49:30,  2.42s/it] 20%|‚ñà‚ñà        | 314/1540 [12:41<49:28,  2.42s/it] 20%|‚ñà‚ñà        | 315/1540 [12:43<49:38,  2.43s/it] 21%|‚ñà‚ñà        | 316/1540 [12:45<49:32,  2.43s/it] 21%|‚ñà‚ñà        | 317/1540 [12:48<49:26,  2.43s/it] 21%|‚ñà‚ñà        | 318/1540 [12:50<49:21,  2.42s/it] 21%|‚ñà‚ñà        | 319/1540 [12:53<49:17,  2.42s/it] 21%|‚ñà‚ñà        | 320/1540 [12:55<49:21,  2.43s/it]                                                  {'loss': 0.5679, 'grad_norm': 0.4061155319213867, 'learning_rate': 0.0004999016565957633, 'epoch': 1.04}
 21%|‚ñà‚ñà        | 320/1540 [12:55<49:21,  2.43s/it] 21%|‚ñà‚ñà        | 321/1540 [12:58<49:17,  2.43s/it] 21%|‚ñà‚ñà        | 322/1540 [13:00<49:12,  2.42s/it] 21%|‚ñà‚ñà        | 323/1540 [13:02<49:08,  2.42s/it] 21%|‚ñà‚ñà        | 324/1540 [13:05<49:05,  2.42s/it] 21%|‚ñà‚ñà        | 325/1540 [13:07<49:01,  2.42s/it] 21%|‚ñà‚ñà        | 326/1540 [13:10<48:58,  2.42s/it] 21%|‚ñà‚ñà        | 327/1540 [13:12<48:56,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 328/1540 [13:14<48:53,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 329/1540 [13:17<48:54,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 330/1540 [13:19<48:50,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 331/1540 [13:22<48:47,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 332/1540 [13:24<48:44,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 333/1540 [13:27<48:42,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 334/1540 [13:29<48:55,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 335/1540 [13:31<48:48,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 336/1540 [13:34<48:42,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 337/1540 [13:36<48:37,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 338/1540 [13:39<48:33,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 339/1540 [13:41<48:29,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 340/1540 [13:44<48:25,  2.42s/it]                                                  {'loss': 0.5416, 'grad_norm': 0.342615008354187, 'learning_rate': 0.0004992192975102804, 'epoch': 1.1}
 22%|‚ñà‚ñà‚ñè       | 340/1540 [13:44<48:25,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 341/1540 [13:46<48:25,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 342/1540 [13:48<48:21,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 343/1540 [13:51<48:17,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 344/1540 [13:53<48:15,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 345/1540 [13:56<48:12,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 346/1540 [13:58<48:09,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 347/1540 [14:01<48:06,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 348/1540 [14:03<48:15,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 349/1540 [14:05<48:10,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 350/1540 [14:08<48:06,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 351/1540 [14:10<48:01,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 352/1540 [14:13<47:58,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 353/1540 [14:15<47:54,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 354/1540 [14:18<47:52,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 355/1540 [14:20<47:48,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 356/1540 [14:22<47:45,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 357/1540 [14:25<47:43,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 358/1540 [14:27<47:50,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 359/1540 [14:30<47:45,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 360/1540 [14:32<47:41,  2.42s/it]                                                  {'loss': 0.4921, 'grad_norm': 0.2507372200489044, 'learning_rate': 0.0004978888625516589, 'epoch': 1.17}
 23%|‚ñà‚ñà‚ñé       | 360/1540 [14:32<47:41,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 361/1540 [14:35<47:46,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 362/1540 [14:37<47:40,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 363/1540 [14:39<47:34,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 364/1540 [14:42<47:30,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 365/1540 [14:44<47:26,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 366/1540 [14:47<47:23,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 367/1540 [14:49<47:20,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 368/1540 [14:51<47:17,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 369/1540 [14:54<47:15,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 370/1540 [14:56<47:12,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 371/1540 [14:59<47:09,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 372/1540 [15:01<47:07,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 373/1540 [15:04<47:18,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 374/1540 [15:06<47:11,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 375/1540 [15:08<47:06,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 376/1540 [15:11<47:16,  2.44s/it] 24%|‚ñà‚ñà‚ñç       | 377/1540 [15:13<47:08,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 378/1540 [15:16<47:02,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 379/1540 [15:18<46:57,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 380/1540 [15:21<46:53,  2.43s/it]                                                  {'loss': 0.5402, 'grad_norm': 0.357341468334198, 'learning_rate': 0.0004959138114150592, 'epoch': 1.23}
 25%|‚ñà‚ñà‚ñç       | 380/1540 [15:21<46:53,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 381/1540 [15:23<46:49,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 382/1540 [15:25<46:45,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 383/1540 [15:28<46:42,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 384/1540 [15:30<46:38,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 385/1540 [15:33<46:35,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 386/1540 [15:35<46:33,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 387/1540 [15:38<46:43,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 388/1540 [15:40<46:38,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 389/1540 [15:42<46:33,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 390/1540 [15:45<46:28,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 391/1540 [15:47<46:24,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 392/1540 [15:50<46:20,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 393/1540 [15:52<46:17,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 394/1540 [15:54<46:14,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 395/1540 [15:57<46:11,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 396/1540 [15:59<46:09,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 397/1540 [16:02<46:06,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 398/1540 [16:04<46:03,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 399/1540 [16:07<46:01,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 400/1540 [16:09<45:58,  2.42s/it]                                                  {'loss': 0.5102, 'grad_norm': 0.415126770734787, 'learning_rate': 0.0004932992800711009, 'epoch': 1.3}
 26%|‚ñà‚ñà‚ñå       | 400/1540 [16:09<45:58,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 03:53:45,198 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-400
[INFO|configuration_utils.py:726] 2024-05-25 03:53:46,217 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 03:53:46,219 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 03:53:46,303 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 03:53:46,303 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-400/special_tokens_map.json
 26%|‚ñà‚ñà‚ñå       | 401/1540 [16:13<53:05,  2.80s/it] 26%|‚ñà‚ñà‚ñå       | 402/1540 [16:15<50:53,  2.68s/it] 26%|‚ñà‚ñà‚ñå       | 403/1540 [16:18<49:20,  2.60s/it] 26%|‚ñà‚ñà‚ñå       | 404/1540 [16:20<48:32,  2.56s/it] 26%|‚ñà‚ñà‚ñã       | 405/1540 [16:22<47:42,  2.52s/it] 26%|‚ñà‚ñà‚ñã       | 406/1540 [16:25<47:04,  2.49s/it] 26%|‚ñà‚ñà‚ñã       | 407/1540 [16:27<46:37,  2.47s/it] 26%|‚ñà‚ñà‚ñã       | 408/1540 [16:30<46:18,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 409/1540 [16:32<46:04,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 410/1540 [16:35<45:53,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 411/1540 [16:37<45:44,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 412/1540 [16:39<45:38,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 413/1540 [16:42<45:33,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 414/1540 [16:44<45:28,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 415/1540 [16:47<46:09,  2.46s/it] 27%|‚ñà‚ñà‚ñã       | 416/1540 [16:49<45:51,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 417/1540 [16:52<45:48,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 418/1540 [16:54<45:36,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 419/1540 [16:56<45:27,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 420/1540 [16:59<45:20,  2.43s/it]                                                  {'loss': 0.5473, 'grad_norm': 0.31555017828941345, 'learning_rate': 0.0004900520674101607, 'epoch': 1.36}
 27%|‚ñà‚ñà‚ñã       | 420/1540 [16:59<45:20,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 421/1540 [17:01<45:15,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 422/1540 [17:04<45:10,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 423/1540 [17:06<45:06,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 424/1540 [17:09<45:02,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 425/1540 [17:11<44:59,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 426/1540 [17:13<44:57,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 427/1540 [17:16<44:54,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 428/1540 [17:18<44:51,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 429/1540 [17:21<44:48,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 430/1540 [17:23<44:57,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 431/1540 [17:26<44:51,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 432/1540 [17:28<44:46,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 433/1540 [17:30<44:42,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 434/1540 [17:33<44:38,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 435/1540 [17:35<44:35,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 436/1540 [17:38<44:32,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 437/1540 [17:40<44:29,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 438/1540 [17:42<44:26,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 439/1540 [17:45<44:24,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 440/1540 [17:47<44:21,  2.42s/it]                                                  {'loss': 0.5006, 'grad_norm': 0.36640074849128723, 'learning_rate': 0.0004861806175623745, 'epoch': 1.43}
 29%|‚ñà‚ñà‚ñä       | 440/1540 [17:47<44:21,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 441/1540 [17:50<44:19,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 442/1540 [17:52<44:16,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 443/1540 [17:55<44:14,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 444/1540 [17:57<44:11,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 445/1540 [17:59<44:09,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 446/1540 [18:02<44:12,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 447/1540 [18:04<44:08,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 448/1540 [18:07<44:04,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 449/1540 [18:09<44:01,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 450/1540 [18:12<43:58,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 451/1540 [18:14<43:55,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 452/1540 [18:16<43:53,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 453/1540 [18:19<43:50,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 454/1540 [18:21<43:47,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 455/1540 [18:24<43:44,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 456/1540 [18:26<43:42,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 457/1540 [18:28<43:40,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 458/1540 [18:31<43:39,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 459/1540 [18:33<43:41,  2.43s/it] 30%|‚ñà‚ñà‚ñâ       | 460/1540 [18:36<43:37,  2.42s/it]                                                  {'loss': 0.539, 'grad_norm': 0.3739998936653137, 'learning_rate': 0.0004816949979393171, 'epoch': 1.49}
 30%|‚ñà‚ñà‚ñâ       | 460/1540 [18:36<43:37,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 461/1540 [18:38<43:34,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 462/1540 [18:41<43:31,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 463/1540 [18:43<43:27,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 464/1540 [18:45<43:25,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 465/1540 [18:48<43:21,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 466/1540 [18:50<43:19,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 467/1540 [18:53<43:16,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 468/1540 [18:55<43:13,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 469/1540 [18:58<43:11,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 470/1540 [19:00<43:08,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 471/1540 [19:02<43:06,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 472/1540 [19:05<43:12,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 473/1540 [19:07<43:19,  2.44s/it] 31%|‚ñà‚ñà‚ñà       | 474/1540 [19:10<43:11,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 475/1540 [19:12<43:05,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 476/1540 [19:14<43:00,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 477/1540 [19:17<42:56,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 478/1540 [19:19<42:52,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 479/1540 [19:22<42:48,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 480/1540 [19:24<42:45,  2.42s/it]                                                  {'loss': 0.5485, 'grad_norm': 0.37106403708457947, 'learning_rate': 0.00047660687305446235, 'epoch': 1.56}
 31%|‚ñà‚ñà‚ñà       | 480/1540 [19:24<42:45,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 481/1540 [19:27<42:43,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 482/1540 [19:29<42:40,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 483/1540 [19:31<42:37,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 484/1540 [19:34<42:34,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 485/1540 [19:36<42:32,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 486/1540 [19:39<42:29,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 487/1540 [19:41<42:36,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 488/1540 [19:44<42:31,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 489/1540 [19:46<42:27,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 490/1540 [19:48<42:23,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 491/1540 [19:51<42:19,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 492/1540 [19:53<42:17,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 493/1540 [19:56<42:13,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 494/1540 [19:58<42:11,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 495/1540 [20:00<42:08,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 496/1540 [20:03<42:06,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 497/1540 [20:05<42:04,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 498/1540 [20:08<42:01,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 499/1540 [20:10<41:59,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 500/1540 [20:13<41:56,  2.42s/it]                                                  {'loss': 0.5425, 'grad_norm': nan, 'learning_rate': 0.0004712271175980134, 'epoch': 1.62}
 32%|‚ñà‚ñà‚ñà‚ñè      | 500/1540 [20:13<41:56,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 501/1540 [20:15<42:02,  2.43s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 502/1540 [20:17<41:56,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 503/1540 [20:20<41:52,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 504/1540 [20:22<41:49,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 505/1540 [20:25<41:45,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 506/1540 [20:27<41:42,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 507/1540 [20:30<41:39,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 508/1540 [20:32<41:37,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 509/1540 [20:34<41:34,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 510/1540 [20:37<41:31,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 511/1540 [20:39<41:29,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 512/1540 [20:42<41:26,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 513/1540 [20:44<41:24,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 514/1540 [20:46<41:22,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 515/1540 [20:49<41:25,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 516/1540 [20:51<41:21,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 517/1540 [20:54<41:17,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 518/1540 [20:56<41:14,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 519/1540 [20:59<41:11,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1540 [21:01<41:09,  2.42s/it]                                                  {'loss': 0.4715, 'grad_norm': 0.349041223526001, 'learning_rate': 0.0004650035600519251, 'epoch': 1.69}
 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1540 [21:01<41:09,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 521/1540 [21:03<41:06,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 522/1540 [21:06<41:03,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 523/1540 [21:08<41:00,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 524/1540 [21:11<40:57,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 525/1540 [21:13<40:55,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 526/1540 [21:16<40:53,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 527/1540 [21:18<40:51,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 528/1540 [21:20<40:51,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 529/1540 [21:23<40:48,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 530/1540 [21:25<40:44,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 531/1540 [21:28<40:41,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 532/1540 [21:30<40:39,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 533/1540 [21:32<40:36,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 534/1540 [21:35<40:33,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 535/1540 [21:37<40:31,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 536/1540 [21:40<40:28,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 537/1540 [21:42<40:26,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 538/1540 [21:45<40:23,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 539/1540 [21:47<40:23,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1540 [21:49<40:21,  2.42s/it]                                                  {'loss': 0.5137, 'grad_norm': 0.378047913312912, 'learning_rate': 0.0004582209020617679, 'epoch': 1.75}
 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1540 [21:49<40:21,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 541/1540 [21:52<40:19,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 542/1540 [21:54<40:16,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 543/1540 [21:57<40:22,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 544/1540 [21:59<40:17,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 545/1540 [22:02<40:12,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 546/1540 [22:04<40:08,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 547/1540 [22:06<40:04,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 548/1540 [22:09<40:01,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 549/1540 [22:11<39:58,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 550/1540 [22:14<39:55,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 551/1540 [22:16<39:53,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 552/1540 [22:18<39:51,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 553/1540 [22:21<39:48,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 554/1540 [22:23<39:45,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 555/1540 [22:26<39:43,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 556/1540 [22:28<39:48,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 557/1540 [22:31<39:43,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 558/1540 [22:33<39:39,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 559/1540 [22:35<39:46,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1540 [22:38<39:39,  2.43s/it]                                                  {'loss': 0.465, 'grad_norm': 0.3873286843299866, 'learning_rate': 0.0004508967814149967, 'epoch': 1.82}
 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1540 [22:38<39:39,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 561/1540 [22:40<39:36,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 562/1540 [22:43<39:31,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 563/1540 [22:45<39:27,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 564/1540 [22:48<39:24,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 565/1540 [22:50<39:21,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 566/1540 [22:52<39:18,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 567/1540 [22:55<39:14,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 568/1540 [22:57<39:12,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 569/1540 [23:00<39:13,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 570/1540 [23:02<39:09,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 571/1540 [23:05<39:06,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 572/1540 [23:07<39:03,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 573/1540 [23:09<38:59,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 574/1540 [23:12<38:57,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 575/1540 [23:14<38:54,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 576/1540 [23:17<38:51,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 577/1540 [23:19<38:49,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 578/1540 [23:21<38:46,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 579/1540 [23:24<38:44,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1540 [23:26<38:41,  2.42s/it]                                                  {'loss': 0.4989, 'grad_norm': 0.36340969800949097, 'learning_rate': 0.0004430502439316204, 'epoch': 1.88}
 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1540 [23:26<38:41,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 581/1540 [23:29<38:40,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 582/1540 [23:31<38:37,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 583/1540 [23:34<38:35,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 584/1540 [23:36<38:33,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 585/1540 [23:38<38:32,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 586/1540 [23:41<38:29,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 587/1540 [23:43<38:26,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 588/1540 [23:46<38:24,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 589/1540 [23:48<38:21,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 590/1540 [23:51<38:18,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 591/1540 [23:53<38:16,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 592/1540 [23:55<38:13,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 593/1540 [23:58<38:10,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 594/1540 [24:00<38:08,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 595/1540 [24:03<38:06,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 596/1540 [24:05<38:03,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 597/1540 [24:07<38:01,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 598/1540 [24:10<38:03,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 599/1540 [24:12<37:59,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1540 [24:15<37:56,  2.42s/it]                                                  {'loss': 0.5333, 'grad_norm': 0.35570234060287476, 'learning_rate': 0.000434701693936992, 'epoch': 1.95}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1540 [24:15<37:56,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 601/1540 [24:17<37:53,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 602/1540 [24:20<37:50,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 603/1540 [24:22<37:47,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 604/1540 [24:24<37:44,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 605/1540 [24:27<37:42,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 606/1540 [24:29<37:39,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 607/1540 [24:32<37:36,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 608/1540 [24:34<37:34,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 609/1540 [24:36<37:32,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 610/1540 [24:39<37:29,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 611/1540 [24:41<37:27,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 612/1540 [24:44<37:35,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 613/1540 [24:46<37:29,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 614/1540 [24:49<37:25,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 615/1540 [24:51<37:21,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 616/1540 [24:53<37:18,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 617/1540 [24:56<37:16,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 618/1540 [24:58<37:12,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 619/1540 [25:01<37:09,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1540 [25:03<37:07,  2.42s/it]                                                  {'loss': 0.4546, 'grad_norm': 0.3362458050251007, 'learning_rate': 0.00042587284120190896, 'epoch': 2.01}
 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1540 [25:03<37:07,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 621/1540 [25:06<37:04,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 622/1540 [25:08<37:01,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 623/1540 [25:10<36:58,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 624/1540 [25:13<36:56,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 625/1540 [25:15<36:53,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 626/1540 [25:18<36:56,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 627/1540 [25:20<36:52,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 628/1540 [25:23<36:48,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 629/1540 [25:25<36:45,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 630/1540 [25:27<36:42,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 631/1540 [25:30<36:39,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 632/1540 [25:32<36:37,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 633/1540 [25:35<36:35,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 634/1540 [25:37<36:32,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 635/1540 [25:39<36:29,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 636/1540 [25:42<36:27,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 637/1540 [25:44<36:24,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 638/1540 [25:47<36:22,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 639/1540 [25:49<36:20,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1540 [25:52<36:17,  2.42s/it]                                                  {'loss': 0.4309, 'grad_norm': 0.3581311106681824, 'learning_rate': 0.000416586644488001, 'epoch': 2.08}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1540 [25:52<36:17,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 641/1540 [25:54<36:15,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 642/1540 [25:56<36:12,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 643/1540 [25:59<36:10,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 644/1540 [26:01<36:07,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 645/1540 [26:04<36:05,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 646/1540 [26:06<36:06,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 647/1540 [26:08<36:02,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 648/1540 [26:11<35:59,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 649/1540 [26:13<35:57,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 650/1540 [26:16<35:54,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 651/1540 [26:18<35:51,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 652/1540 [26:21<35:48,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 653/1540 [26:23<35:45,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 654/1540 [26:25<35:45,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 655/1540 [26:28<35:42,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 656/1540 [26:30<35:39,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 657/1540 [26:33<35:37,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 658/1540 [26:35<35:34,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 659/1540 [26:38<35:31,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1540 [26:40<35:29,  2.42s/it]                                                  {'loss': 0.4508, 'grad_norm': 0.34593650698661804, 'learning_rate': 0.000406867251845213, 'epoch': 2.14}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1540 [26:40<35:29,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 661/1540 [26:42<35:27,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 662/1540 [26:45<35:24,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 663/1540 [26:47<35:22,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 664/1540 [26:50<35:19,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 665/1540 [26:52<35:16,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 666/1540 [26:54<35:14,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 667/1540 [26:57<35:18,  2.43s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 668/1540 [26:59<35:14,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 669/1540 [27:02<35:10,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 670/1540 [27:04<35:06,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 671/1540 [27:07<35:03,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 672/1540 [27:09<35:00,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 673/1540 [27:11<34:58,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 674/1540 [27:14<34:55,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 675/1540 [27:16<34:53,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 676/1540 [27:19<34:50,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 677/1540 [27:21<34:47,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 678/1540 [27:24<34:45,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 679/1540 [27:26<34:42,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1540 [27:28<34:40,  2.42s/it]                                                  {'loss': 0.4242, 'grad_norm': 0.33592841029167175, 'learning_rate': 0.0003967399378166333, 'epoch': 2.21}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1540 [27:28<34:40,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 681/1540 [27:31<34:38,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 682/1540 [27:33<34:49,  2.44s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 683/1540 [27:36<34:43,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 684/1540 [27:38<34:37,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 685/1540 [27:41<34:32,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 686/1540 [27:43<34:28,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 687/1540 [27:45<34:25,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 688/1540 [27:48<34:23,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 689/1540 [27:50<34:20,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 690/1540 [27:53<34:17,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 691/1540 [27:55<34:14,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 692/1540 [27:57<34:12,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 693/1540 [28:00<34:10,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 694/1540 [28:02<34:07,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 695/1540 [28:05<34:06,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 696/1540 [28:07<34:03,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 697/1540 [28:10<34:00,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 698/1540 [28:12<33:57,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 699/1540 [28:14<33:54,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1540 [28:17<33:52,  2.42s/it]                                                  {'loss': 0.3885, 'grad_norm': 0.3707355260848999, 'learning_rate': 0.00038623103771396195, 'epoch': 2.27}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1540 [28:17<33:52,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 701/1540 [28:19<33:50,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 702/1540 [28:22<33:47,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 703/1540 [28:24<33:45,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 704/1540 [28:26<33:42,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 705/1540 [28:29<33:40,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 706/1540 [28:31<33:37,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 707/1540 [28:34<33:35,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 708/1540 [28:36<33:35,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 709/1540 [28:39<33:32,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 710/1540 [28:41<33:28,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 711/1540 [28:43<33:26,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 712/1540 [28:46<33:23,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 713/1540 [28:48<33:20,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 714/1540 [28:51<33:18,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 715/1540 [28:53<33:16,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 716/1540 [28:56<33:13,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 717/1540 [28:58<33:11,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 718/1540 [29:00<33:08,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 719/1540 [29:03<33:06,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1540 [29:05<33:08,  2.43s/it]                                                  {'loss': 0.3994, 'grad_norm': 0.35098645091056824, 'learning_rate': 0.00037536787913453106, 'epoch': 2.34}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1540 [29:05<33:08,  2.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 721/1540 [29:08<33:05,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 722/1540 [29:10<33:01,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 723/1540 [29:12<32:58,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 724/1540 [29:15<32:57,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 725/1540 [29:17<32:55,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 726/1540 [29:20<32:51,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 727/1540 [29:22<32:48,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 728/1540 [29:25<32:45,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 729/1540 [29:27<32:42,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 730/1540 [29:29<32:40,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 731/1540 [29:32<32:37,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 732/1540 [29:34<32:34,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 733/1540 [29:37<32:33,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 734/1540 [29:39<32:30,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 735/1540 [29:42<32:27,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 736/1540 [29:44<32:25,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 737/1540 [29:46<32:28,  2.43s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 738/1540 [29:49<32:24,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 739/1540 [29:51<32:20,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1540 [29:54<32:17,  2.42s/it]                                                  {'loss': 0.4125, 'grad_norm': 0.33518269658088684, 'learning_rate': 0.0003641787108979617, 'epoch': 2.4}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1540 [29:54<32:17,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 741/1540 [29:56<32:14,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 742/1540 [29:58<32:12,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 743/1540 [30:01<32:09,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 744/1540 [30:03<32:06,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 745/1540 [30:06<32:03,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 746/1540 [30:08<32:00,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 747/1540 [30:11<31:58,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 748/1540 [30:13<31:55,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 749/1540 [30:15<31:53,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 750/1540 [30:18<31:51,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 751/1540 [30:20<32:05,  2.44s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 752/1540 [30:23<31:58,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 753/1540 [30:25<31:52,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 754/1540 [30:28<31:47,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 755/1540 [30:30<31:43,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 756/1540 [30:32<31:39,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 757/1540 [30:35<31:36,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 758/1540 [30:37<31:33,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 759/1540 [30:40<31:30,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1540 [30:42<31:27,  2.42s/it]                                                  {'loss': 0.4232, 'grad_norm': 0.34932568669319153, 'learning_rate': 0.00035269262958725125, 'epoch': 2.47}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1540 [30:42<31:27,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 761/1540 [30:45<31:25,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 762/1540 [30:47<31:23,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 763/1540 [30:49<31:20,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 764/1540 [30:52<31:17,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 765/1540 [30:54<31:20,  2.43s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 766/1540 [30:57<31:16,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 767/1540 [30:59<31:12,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 768/1540 [31:01<31:09,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 769/1540 [31:04<31:07,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 770/1540 [31:06<31:03,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 771/1540 [31:09<31:00,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 772/1540 [31:11<30:58,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 773/1540 [31:14<30:55,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 774/1540 [31:16<30:53,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 775/1540 [31:18<30:51,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 776/1540 [31:21<30:48,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 777/1540 [31:23<30:46,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 778/1540 [31:26<30:47,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 779/1540 [31:28<30:43,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1540 [31:31<30:40,  2.42s/it]                                                  {'loss': 0.4198, 'grad_norm': 0.34612157940864563, 'learning_rate': 0.00034093950388531787, 'epoch': 2.53}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1540 [31:31<30:40,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 781/1540 [31:33<30:37,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 782/1540 [31:35<30:34,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 783/1540 [31:38<30:31,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 784/1540 [31:40<30:29,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 785/1540 [31:43<30:26,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 786/1540 [31:45<30:23,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 787/1540 [31:47<30:21,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 788/1540 [31:50<30:18,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 789/1540 [31:52<30:16,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 790/1540 [31:55<30:14,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 791/1540 [31:57<30:12,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 792/1540 [32:00<30:09,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 793/1540 [32:02<30:13,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 794/1540 [32:04<30:08,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 795/1540 [32:07<30:05,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 796/1540 [32:09<30:02,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 797/1540 [32:12<29:59,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 798/1540 [32:14<29:56,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 799/1540 [32:17<29:54,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1540 [32:19<29:51,  2.42s/it]                                                  {'loss': 0.412, 'grad_norm': 0.35475534200668335, 'learning_rate': 0.00032894989690375627, 'epoch': 2.6}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1540 [32:19<29:51,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 04:09:55,131 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-800
[INFO|configuration_utils.py:726] 2024-05-25 04:09:56,347 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:09:56,349 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 04:09:56,866 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:09:56,868 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 04:09:56,921 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 04:09:56,921 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-800/special_tokens_map.json
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 801/1540 [32:23<37:00,  3.01s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 802/1540 [32:26<34:47,  2.83s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 803/1540 [32:28<33:14,  2.71s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 804/1540 [32:31<32:08,  2.62s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 805/1540 [32:33<31:21,  2.56s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 806/1540 [32:35<30:53,  2.53s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 807/1540 [32:38<30:33,  2.50s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 808/1540 [32:40<30:12,  2.48s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 809/1540 [32:43<29:57,  2.46s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 810/1540 [32:45<29:45,  2.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 811/1540 [32:48<29:37,  2.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 812/1540 [32:50<29:30,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 813/1540 [32:52<29:25,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 814/1540 [32:55<29:20,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 815/1540 [32:57<29:17,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 816/1540 [33:00<29:13,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 817/1540 [33:02<29:10,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 818/1540 [33:04<29:07,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 819/1540 [33:07<29:04,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1540 [33:09<29:01,  2.42s/it]                                                  {'loss': 0.3962, 'grad_norm': 0.3359602391719818, 'learning_rate': 0.0003167549867057854, 'epoch': 2.66}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1540 [33:09<29:01,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 821/1540 [33:12<29:30,  2.46s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 822/1540 [33:14<29:18,  2.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 823/1540 [33:17<29:09,  2.44s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 824/1540 [33:19<29:01,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 825/1540 [33:22<28:56,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 826/1540 [33:24<28:51,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 827/1540 [33:26<28:47,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 828/1540 [33:29<28:44,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 829/1540 [33:31<28:41,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 830/1540 [33:34<28:38,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 831/1540 [33:36<28:35,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 832/1540 [33:38<28:32,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 833/1540 [33:41<28:30,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 834/1540 [33:43<28:30,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 835/1540 [33:46<28:27,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 836/1540 [33:48<28:24,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 837/1540 [33:51<28:21,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 838/1540 [33:53<28:18,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 839/1540 [33:55<28:16,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1540 [33:58<28:13,  2.42s/it]                                                  {'loss': 0.3928, 'grad_norm': 0.3621668517589569, 'learning_rate': 0.00030438648523006085, 'epoch': 2.73}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1540 [33:58<28:13,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 841/1540 [34:00<28:12,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 842/1540 [34:03<28:09,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 843/1540 [34:05<28:07,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 844/1540 [34:08<28:04,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 845/1540 [34:10<28:01,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 846/1540 [34:12<27:58,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 847/1540 [34:15<28:02,  2.43s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 848/1540 [34:17<27:58,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 849/1540 [34:20<27:56,  2.43s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 850/1540 [34:22<27:52,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 851/1540 [34:25<27:49,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 852/1540 [34:27<27:45,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 853/1540 [34:29<27:42,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 854/1540 [34:32<27:40,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 855/1540 [34:34<27:37,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 856/1540 [34:37<27:34,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 857/1540 [34:39<27:32,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 858/1540 [34:41<27:29,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 859/1540 [34:44<27:27,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1540 [34:46<27:24,  2.42s/it]                                                  {'loss': 0.3899, 'grad_norm': 0.36381298303604126, 'learning_rate': 0.0002918765558261841, 'epoch': 2.79}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1540 [34:46<27:24,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 861/1540 [34:49<27:22,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 862/1540 [34:51<27:20,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 863/1540 [34:54<27:23,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 864/1540 [34:56<27:18,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 865/1540 [34:58<27:15,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 866/1540 [35:01<27:11,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 867/1540 [35:03<27:09,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 868/1540 [35:06<27:06,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 869/1540 [35:08<27:03,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 870/1540 [35:10<27:00,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 871/1540 [35:13<26:58,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 872/1540 [35:15<26:55,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 873/1540 [35:18<26:53,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 874/1540 [35:20<26:50,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 875/1540 [35:23<26:48,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 876/1540 [35:25<26:50,  2.43s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 877/1540 [35:27<26:46,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 878/1540 [35:30<26:43,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 879/1540 [35:32<26:40,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1540 [35:35<26:37,  2.42s/it]                                                  {'loss': 0.4197, 'grad_norm': 0.3672630786895752, 'learning_rate': 0.00027925772961635294, 'epoch': 2.86}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1540 [35:35<26:37,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 881/1540 [35:37<26:35,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 882/1540 [35:40<26:32,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 883/1540 [35:42<26:29,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 884/1540 [35:44<26:27,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 885/1540 [35:47<26:23,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 886/1540 [35:49<26:21,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 887/1540 [35:52<26:19,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 888/1540 [35:54<26:16,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 889/1540 [35:56<26:14,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 890/1540 [35:59<26:24,  2.44s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 891/1540 [36:01<26:18,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 892/1540 [36:04<26:13,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 893/1540 [36:06<26:11,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 894/1540 [36:09<26:07,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 895/1540 [36:11<26:03,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 896/1540 [36:13<25:59,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 897/1540 [36:16<25:57,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 898/1540 [36:18<25:54,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 899/1540 [36:21<25:51,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1540 [36:23<25:48,  2.42s/it]                                                  {'loss': 0.3892, 'grad_norm': 0.28361567854881287, 'learning_rate': 0.0002671988642677426, 'epoch': 2.92}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1540 [36:23<25:48,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 901/1540 [36:26<25:46,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 902/1540 [36:28<25:43,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 903/1540 [36:30<25:41,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 904/1540 [36:33<25:40,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 905/1540 [36:35<25:37,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 906/1540 [36:38<25:34,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 907/1540 [36:40<25:32,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 908/1540 [36:43<25:29,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 909/1540 [36:45<25:26,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 910/1540 [36:47<25:24,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 911/1540 [36:50<25:21,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 912/1540 [36:52<25:19,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 913/1540 [36:55<25:16,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 914/1540 [36:57<25:14,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 915/1540 [36:59<25:11,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 916/1540 [37:02<25:09,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 917/1540 [37:04<25:16,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 918/1540 [37:07<25:11,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 919/1540 [37:09<25:07,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1540 [37:12<25:02,  2.42s/it]                                                  {'loss': 0.3835, 'grad_norm': 0.33310309052467346, 'learning_rate': 0.0002544622525947115, 'epoch': 2.99}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1540 [37:12<25:02,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 921/1540 [37:14<24:59,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 922/1540 [37:16<24:56,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 923/1540 [37:19<24:53,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 924/1540 [37:21<24:50,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 925/1540 [37:24<24:48,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 926/1540 [37:26<24:45,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 927/1540 [37:29<24:42,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 928/1540 [37:31<24:40,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 929/1540 [37:33<24:37,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 930/1540 [37:36<24:35,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 931/1540 [37:38<24:33,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 932/1540 [37:41<24:36,  2.43s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 933/1540 [37:43<24:32,  2.43s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 934/1540 [37:45<24:28,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 935/1540 [37:48<24:25,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 936/1540 [37:50<24:22,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 937/1540 [37:53<24:19,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 938/1540 [37:55<24:16,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 939/1540 [37:58<24:14,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1540 [38:00<24:11,  2.42s/it]                                                  {'loss': 0.3393, 'grad_norm': 0.298085480928421, 'learning_rate': 0.00024171403717239068, 'epoch': 3.05}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1540 [38:00<24:11,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 941/1540 [38:02<24:09,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 942/1540 [38:05<24:06,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 943/1540 [38:07<24:04,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 944/1540 [38:10<24:01,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 945/1540 [38:12<24:01,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 946/1540 [38:15<23:58,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 947/1540 [38:17<23:55,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 948/1540 [38:19<23:52,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 949/1540 [38:22<23:50,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 950/1540 [38:24<23:47,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 951/1540 [38:27<23:45,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 952/1540 [38:29<23:42,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 953/1540 [38:31<23:39,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 954/1540 [38:34<23:37,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 955/1540 [38:36<23:35,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 956/1540 [38:39<23:32,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 957/1540 [38:41<23:30,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 958/1540 [38:44<23:27,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 959/1540 [38:46<23:25,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 960/1540 [38:48<23:34,  2.44s/it]                                                  {'loss': 0.3463, 'grad_norm': 0.42598769068717957, 'learning_rate': 0.00022898736876768815, 'epoch': 3.12}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 960/1540 [38:48<23:34,  2.44s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 961/1540 [38:51<23:29,  2.43s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 962/1540 [38:53<23:24,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 963/1540 [38:56<23:20,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 964/1540 [38:58<23:16,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 965/1540 [39:01<23:16,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 966/1540 [39:03<23:12,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 967/1540 [39:05<23:08,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 968/1540 [39:08<23:05,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 969/1540 [39:10<23:02,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 970/1540 [39:13<22:59,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 971/1540 [39:15<22:57,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 972/1540 [39:18<22:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 973/1540 [39:20<22:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 974/1540 [39:22<22:50,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 975/1540 [39:25<22:47,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 976/1540 [39:27<22:45,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 977/1540 [39:30<22:42,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 978/1540 [39:32<22:40,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 979/1540 [39:34<22:37,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 980/1540 [39:37<22:35,  2.42s/it]                                                  {'loss': 0.3535, 'grad_norm': 0.3332461416721344, 'learning_rate': 0.00021631534211612774, 'epoch': 3.18}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 980/1540 [39:37<22:35,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 981/1540 [39:39<22:33,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 982/1540 [39:42<22:30,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 983/1540 [39:44<22:27,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 984/1540 [39:47<22:25,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 985/1540 [39:49<22:23,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 986/1540 [39:51<22:27,  2.43s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 987/1540 [39:54<22:23,  2.43s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 988/1540 [39:56<22:19,  2.43s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 989/1540 [39:59<22:15,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 990/1540 [40:01<22:12,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 991/1540 [40:04<22:09,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 992/1540 [40:06<22:06,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 993/1540 [40:08<22:04,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 994/1540 [40:11<22:07,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 995/1540 [40:13<22:03,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 996/1540 [40:16<21:59,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 997/1540 [40:18<21:55,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 998/1540 [40:21<21:52,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 999/1540 [40:23<21:49,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1000/1540 [40:25<21:46,  2.42s/it]                                                   {'loss': 0.3426, 'grad_norm': 0.3523094058036804, 'learning_rate': 0.0002037309098615004, 'epoch': 3.25}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1000/1540 [40:25<21:46,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1001/1540 [40:28<21:44,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1002/1540 [40:30<21:42,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1003/1540 [40:33<21:39,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1004/1540 [40:35<21:36,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1005/1540 [40:37<21:34,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1006/1540 [40:40<21:31,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1007/1540 [40:42<21:29,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1008/1540 [40:45<21:26,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1009/1540 [40:47<21:30,  2.43s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1010/1540 [40:50<21:26,  2.43s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1011/1540 [40:52<21:22,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1012/1540 [40:54<21:19,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1013/1540 [40:57<21:15,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1014/1540 [40:59<21:13,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1015/1540 [41:02<21:11,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1016/1540 [41:04<21:08,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1017/1540 [41:07<21:05,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1018/1540 [41:09<21:03,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1019/1540 [41:11<21:00,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1020/1540 [41:14<20:58,  2.42s/it]                                                   {'loss': 0.3505, 'grad_norm': 0.3131245970726013, 'learning_rate': 0.0001912667968650139, 'epoch': 3.31}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1020/1540 [41:14<20:58,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1021/1540 [41:16<20:55,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1022/1540 [41:19<20:53,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1023/1540 [41:21<20:51,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1024/1540 [41:23<20:48,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1025/1540 [41:26<20:45,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1026/1540 [41:28<20:43,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1027/1540 [41:31<20:40,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1028/1540 [41:33<20:38,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1029/1540 [41:36<20:44,  2.44s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1030/1540 [41:38<20:39,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1031/1540 [41:40<20:35,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1032/1540 [41:43<20:31,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1033/1540 [41:45<20:28,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1034/1540 [41:48<20:24,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1035/1540 [41:50<20:22,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1036/1540 [41:53<20:19,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1037/1540 [41:55<20:16,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1038/1540 [41:57<20:17,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1039/1540 [42:00<20:13,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1540 [42:02<20:11,  2.42s/it]                                                   {'loss': 0.3681, 'grad_norm': 0.3269442915916443, 'learning_rate': 0.00017895541510677497, 'epoch': 3.38}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1540 [42:02<20:11,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1041/1540 [42:05<20:08,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1042/1540 [42:07<20:05,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1043/1540 [42:09<20:05,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1044/1540 [42:12<20:01,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1045/1540 [42:14<19:58,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1046/1540 [42:17<19:55,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1047/1540 [42:19<19:52,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1048/1540 [42:22<19:50,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1049/1540 [42:24<19:47,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1050/1540 [42:26<19:45,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1051/1540 [42:29<19:42,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1052/1540 [42:31<19:40,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1053/1540 [42:34<19:37,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1054/1540 [42:36<19:35,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1055/1540 [42:39<19:32,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1056/1540 [42:41<19:35,  2.43s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1057/1540 [42:43<19:31,  2.43s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1058/1540 [42:46<19:28,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1059/1540 [42:48<19:25,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1540 [42:51<19:22,  2.42s/it]                                                   {'loss': 0.3377, 'grad_norm': 0.4083103835582733, 'learning_rate': 0.00016682877940089405, 'epoch': 3.44}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1540 [42:51<19:22,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1061/1540 [42:53<19:19,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1062/1540 [42:55<19:16,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1063/1540 [42:58<19:13,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1064/1540 [43:00<19:11,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1065/1540 [43:03<19:08,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1066/1540 [43:05<19:06,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1067/1540 [43:08<19:03,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1068/1540 [43:10<19:01,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1069/1540 [43:12<18:59,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1070/1540 [43:15<18:57,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1071/1540 [43:17<18:58,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1072/1540 [43:20<18:54,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1073/1540 [43:22<18:51,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1074/1540 [43:25<18:48,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1075/1540 [43:27<18:45,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1076/1540 [43:29<18:43,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1077/1540 [43:32<18:40,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1078/1540 [43:34<18:37,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1079/1540 [43:37<18:35,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1540 [43:39<18:32,  2.42s/it]                                                   {'loss': 0.3378, 'grad_norm': 0.3484027087688446, 'learning_rate': 0.00015491842414339023, 'epoch': 3.51}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1540 [43:39<18:32,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1081/1540 [43:41<18:34,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1082/1540 [43:44<18:30,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1083/1540 [43:46<18:27,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1084/1540 [43:49<18:24,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1085/1540 [43:51<18:21,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1086/1540 [43:54<18:19,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1087/1540 [43:56<18:16,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1088/1540 [43:58<18:13,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1089/1540 [44:01<18:11,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1090/1540 [44:03<18:08,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1091/1540 [44:06<18:06,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1092/1540 [44:08<18:03,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1093/1540 [44:11<18:01,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1094/1540 [44:13<17:58,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1095/1540 [44:15<17:56,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1096/1540 [44:18<17:53,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1097/1540 [44:20<17:51,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1098/1540 [44:23<17:48,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1099/1540 [44:25<17:55,  2.44s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1540 [44:28<17:50,  2.43s/it]                                                   {'loss': 0.3155, 'grad_norm': 0.3296494483947754, 'learning_rate': 0.0001432553213093876, 'epoch': 3.57}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1540 [44:28<17:50,  2.43s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1101/1540 [44:30<17:46,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1102/1540 [44:32<17:42,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1103/1540 [44:35<17:39,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1104/1540 [44:37<17:35,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1105/1540 [44:40<17:33,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1106/1540 [44:42<17:30,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1107/1540 [44:44<17:27,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1108/1540 [44:47<17:25,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1109/1540 [44:49<17:22,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1110/1540 [44:52<17:20,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1111/1540 [44:54<17:17,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1112/1540 [44:57<17:15,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1113/1540 [44:59<17:12,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1114/1540 [45:01<17:10,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1115/1540 [45:04<17:07,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1116/1540 [45:06<17:05,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1117/1540 [45:09<17:03,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1118/1540 [45:11<17:00,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1119/1540 [45:13<16:58,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1540 [45:16<16:55,  2.42s/it]                                                   {'loss': 0.3198, 'grad_norm': 0.31224653124809265, 'learning_rate': 0.0001318697999128436, 'epoch': 3.64}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1540 [45:16<16:55,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1121/1540 [45:18<16:53,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1122/1540 [45:21<16:51,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1123/1540 [45:23<16:48,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1124/1540 [45:26<16:46,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1125/1540 [45:28<16:45,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1126/1540 [45:30<16:42,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1127/1540 [45:33<16:39,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1128/1540 [45:35<16:36,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1129/1540 [45:38<16:34,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1130/1540 [45:40<16:31,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1131/1540 [45:43<16:29,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1132/1540 [45:45<16:27,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1133/1540 [45:47<16:24,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1134/1540 [45:50<16:21,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1135/1540 [45:52<16:19,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1136/1540 [45:55<16:17,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1137/1540 [45:57<16:14,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1138/1540 [45:59<16:12,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1139/1540 [46:02<16:09,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1540 [46:04<16:07,  2.42s/it]                                                   {'loss': 0.3256, 'grad_norm': 0.38824501633644104, 'learning_rate': 0.00012079146713824946, 'epoch': 3.7}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1540 [46:04<16:07,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1141/1540 [46:07<16:06,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1142/1540 [46:09<16:03,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1143/1540 [46:12<16:00,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1144/1540 [46:14<15:58,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1145/1540 [46:16<15:56,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1146/1540 [46:19<15:53,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1147/1540 [46:21<15:50,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1148/1540 [46:24<15:48,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1149/1540 [46:26<15:45,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1150/1540 [46:28<15:43,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1151/1540 [46:31<15:40,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1152/1540 [46:33<15:38,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1153/1540 [46:36<15:36,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1154/1540 [46:38<15:36,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1155/1540 [46:41<15:33,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1156/1540 [46:43<15:30,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1157/1540 [46:45<15:27,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1158/1540 [46:48<15:24,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1159/1540 [46:50<15:22,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1540 [46:53<15:19,  2.42s/it]                                                   {'loss': 0.3559, 'grad_norm': 0.32487767934799194, 'learning_rate': 0.00011004913134939388, 'epoch': 3.77}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1540 [46:53<15:19,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1161/1540 [46:55<15:17,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1162/1540 [46:58<15:14,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1163/1540 [47:00<15:12,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1164/1540 [47:02<15:09,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1165/1540 [47:05<15:07,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1166/1540 [47:07<15:04,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1167/1540 [47:10<15:02,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1168/1540 [47:12<15:07,  2.44s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1169/1540 [47:15<15:02,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1170/1540 [47:17<14:58,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1171/1540 [47:19<14:54,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1172/1540 [47:22<14:51,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1173/1540 [47:24<14:48,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1174/1540 [47:27<14:45,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1175/1540 [47:29<14:43,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1176/1540 [47:31<14:40,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1177/1540 [47:34<14:38,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1178/1540 [47:36<14:35,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1179/1540 [47:39<14:33,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1540 [47:41<14:30,  2.42s/it]                                                   {'loss': 0.3356, 'grad_norm': 0.3054658770561218, 'learning_rate': 0.00010018058337216326, 'epoch': 3.83}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1540 [47:41<14:30,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1181/1540 [47:44<14:28,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1182/1540 [47:46<14:26,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1183/1540 [47:48<14:23,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1184/1540 [47:51<14:21,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1185/1540 [47:53<14:18,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1186/1540 [47:56<14:16,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1187/1540 [47:58<14:13,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1188/1540 [48:00<14:11,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1189/1540 [48:03<14:09,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1190/1540 [48:05<14:06,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1191/1540 [48:08<14:03,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1192/1540 [48:10<14:01,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1193/1540 [48:13<13:59,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1194/1540 [48:15<13:56,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1195/1540 [48:17<13:55,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1196/1540 [48:20<13:52,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1197/1540 [48:22<13:50,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1198/1540 [48:25<13:47,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1199/1540 [48:27<13:44,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1540 [48:30<13:42,  2.42s/it]                                                   {'loss': 0.3139, 'grad_norm': 0.3283434510231018, 'learning_rate': 9.017292751611219e-05, 'epoch': 3.9}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1540 [48:30<13:42,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 04:26:05,697 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-1200
[INFO|configuration_utils.py:726] 2024-05-25 04:26:06,469 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:26:06,471 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 04:26:07,021 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:26:07,023 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 04:26:07,075 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 04:26:07,076 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/checkpoint-1200/special_tokens_map.json
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1201/1540 [48:33<16:17,  2.88s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1202/1540 [48:36<15:27,  2.74s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1203/1540 [48:38<14:52,  2.65s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1204/1540 [48:41<14:26,  2.58s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1205/1540 [48:43<14:08,  2.53s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1206/1540 [48:46<13:54,  2.50s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1207/1540 [48:48<13:43,  2.47s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1208/1540 [48:50<13:35,  2.46s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1209/1540 [48:53<13:29,  2.45s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1210/1540 [48:55<13:26,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1211/1540 [48:58<13:21,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1212/1540 [49:00<13:19,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1213/1540 [49:03<13:15,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1214/1540 [49:05<13:11,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1215/1540 [49:07<13:08,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1216/1540 [49:10<13:05,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1217/1540 [49:12<13:02,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1218/1540 [49:15<12:59,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1219/1540 [49:17<12:56,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1540 [49:19<12:54,  2.42s/it]                                                   {'loss': 0.3239, 'grad_norm': 0.3021090626716614, 'learning_rate': 8.058088983484104e-05, 'epoch': 3.96}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1540 [49:19<12:54,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1221/1540 [49:22<12:52,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1222/1540 [49:24<12:49,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1223/1540 [49:27<12:48,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1224/1540 [49:29<12:45,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1225/1540 [49:32<12:42,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1226/1540 [49:34<12:42,  2.43s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1227/1540 [49:36<12:38,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1228/1540 [49:39<12:35,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1229/1540 [49:41<12:33,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1230/1540 [49:44<12:30,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1231/1540 [49:46<12:27,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1232/1540 [49:49<12:25,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1233/1540 [49:51<12:22,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1234/1540 [49:53<12:20,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1235/1540 [49:56<12:17,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1236/1540 [49:58<12:15,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1237/1540 [50:01<12:12,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1238/1540 [50:03<12:16,  2.44s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1239/1540 [50:06<12:12,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1540 [50:08<12:08,  2.43s/it]                                                   {'loss': 0.308, 'grad_norm': 0.2687188386917114, 'learning_rate': 7.142941369452411e-05, 'epoch': 4.03}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1540 [50:08<12:08,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1241/1540 [50:10<12:06,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1242/1540 [50:13<12:02,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1243/1540 [50:15<11:59,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1244/1540 [50:18<11:56,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1245/1540 [50:20<11:54,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1246/1540 [50:22<11:51,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1247/1540 [50:25<11:48,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1248/1540 [50:27<11:46,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1249/1540 [50:30<11:43,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1250/1540 [50:32<11:41,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1251/1540 [50:35<11:39,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1252/1540 [50:37<11:36,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1253/1540 [50:39<11:34,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1254/1540 [50:42<11:31,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1255/1540 [50:44<11:29,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1256/1540 [50:47<11:27,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1257/1540 [50:49<11:24,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1258/1540 [50:52<11:22,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1259/1540 [50:54<11:19,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1540 [50:56<11:17,  2.42s/it]                                                   {'loss': 0.3139, 'grad_norm': 0.3097650110721588, 'learning_rate': 6.274229681447688e-05, 'epoch': 4.09}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1540 [50:56<11:17,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1261/1540 [50:59<11:15,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1262/1540 [51:01<11:12,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1263/1540 [51:04<11:10,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1264/1540 [51:06<11:08,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1265/1540 [51:08<11:05,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1266/1540 [51:11<11:03,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1267/1540 [51:13<11:00,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1268/1540 [51:16<10:57,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1269/1540 [51:18<10:55,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1270/1540 [51:21<10:53,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1271/1540 [51:23<10:51,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1272/1540 [51:25<10:49,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1273/1540 [51:28<10:46,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1274/1540 [51:30<10:44,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1275/1540 [51:33<10:41,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1276/1540 [51:35<10:38,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1277/1540 [51:38<10:36,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1278/1540 [51:40<10:33,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1279/1540 [51:42<10:31,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1540 [51:45<10:30,  2.43s/it]                                                   {'loss': 0.3223, 'grad_norm': 0.2660805284976959, 'learning_rate': 5.454212938299255e-05, 'epoch': 4.16}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1540 [51:45<10:30,  2.43s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1281/1540 [51:47<10:27,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1282/1540 [51:50<10:25,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1283/1540 [51:52<10:22,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1284/1540 [51:54<10:21,  2.43s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1285/1540 [51:57<10:18,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1286/1540 [51:59<10:15,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1287/1540 [52:02<10:12,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1288/1540 [52:04<10:09,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1289/1540 [52:07<10:07,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1290/1540 [52:09<10:05,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1291/1540 [52:11<10:02,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1292/1540 [52:14<10:00,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1293/1540 [52:16<09:57,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1294/1540 [52:19<09:55,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1295/1540 [52:21<09:52,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1296/1540 [52:24<09:50,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1297/1540 [52:26<09:48,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1298/1540 [52:28<09:45,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1299/1540 [52:31<09:44,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1540 [52:33<09:41,  2.42s/it]                                                   {'loss': 0.2963, 'grad_norm': 0.25700512528419495, 'learning_rate': 4.685023531327193e-05, 'epoch': 4.22}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1540 [52:33<09:41,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1301/1540 [52:36<09:39,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1302/1540 [52:38<09:36,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1303/1540 [52:40<09:33,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1304/1540 [52:43<09:31,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1305/1540 [52:45<09:28,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1306/1540 [52:48<09:25,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1307/1540 [52:50<09:28,  2.44s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1308/1540 [52:53<09:24,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1309/1540 [52:55<09:21,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1310/1540 [52:57<09:17,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1311/1540 [53:00<09:15,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1312/1540 [53:02<09:12,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1313/1540 [53:05<09:11,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1314/1540 [53:07<09:08,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1315/1540 [53:10<09:05,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1316/1540 [53:12<09:02,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1317/1540 [53:14<08:59,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1318/1540 [53:17<08:57,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1319/1540 [53:19<08:54,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1540 [53:22<08:52,  2.42s/it]                                                   {'loss': 0.3127, 'grad_norm': 0.2819778025150299, 'learning_rate': 3.968661679220467e-05, 'epoch': 4.29}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1540 [53:22<08:52,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1321/1540 [53:24<08:49,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1322/1540 [53:27<08:47,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1323/1540 [53:29<08:44,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1324/1540 [53:31<08:42,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1325/1540 [53:34<08:40,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1326/1540 [53:36<08:37,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1327/1540 [53:39<08:35,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1328/1540 [53:41<08:32,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1329/1540 [53:43<08:30,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1330/1540 [53:46<08:28,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1331/1540 [53:48<08:25,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1332/1540 [53:51<08:23,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1333/1540 [53:53<08:20,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1334/1540 [53:56<08:19,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1335/1540 [53:58<08:16,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1336/1540 [54:00<08:13,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1337/1540 [54:03<08:11,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1338/1540 [54:05<08:08,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1339/1540 [54:08<08:06,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1540 [54:10<08:03,  2.42s/it]                                                   {'loss': 0.2997, 'grad_norm': 0.2815568447113037, 'learning_rate': 3.306990226620032e-05, 'epoch': 4.35}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1540 [54:10<08:03,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1341/1540 [54:12<08:01,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1342/1540 [54:15<08:00,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1343/1540 [54:17<07:57,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1344/1540 [54:20<07:54,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1345/1540 [54:22<07:52,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1346/1540 [54:25<07:49,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1347/1540 [54:27<07:47,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1348/1540 [54:29<07:44,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1349/1540 [54:32<07:43,  2.43s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1350/1540 [54:34<07:40,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1351/1540 [54:37<07:37,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1352/1540 [54:39<07:35,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1353/1540 [54:42<07:32,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1354/1540 [54:44<07:30,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1355/1540 [54:46<07:27,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1356/1540 [54:49<07:25,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1357/1540 [54:51<07:22,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1358/1540 [54:54<07:20,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1359/1540 [54:56<07:17,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1540 [54:58<07:15,  2.42s/it]                                                   {'loss': 0.3024, 'grad_norm': 0.26327088475227356, 'learning_rate': 2.7017297999326535e-05, 'epoch': 4.42}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1540 [54:59<07:15,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1361/1540 [55:01<07:13,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1362/1540 [55:03<07:10,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1363/1540 [55:06<07:08,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1364/1540 [55:08<07:05,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1365/1540 [55:11<07:03,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1366/1540 [55:13<07:00,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1367/1540 [55:15<06:58,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1368/1540 [55:18<06:56,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1369/1540 [55:20<06:53,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1370/1540 [55:23<06:51,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1371/1540 [55:25<06:48,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1372/1540 [55:28<06:46,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1373/1540 [55:30<06:43,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1374/1540 [55:32<06:41,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1375/1540 [55:35<06:39,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1376/1540 [55:37<06:36,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1377/1540 [55:40<06:37,  2.44s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1378/1540 [55:42<06:33,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1379/1540 [55:45<06:30,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1540 [55:47<06:28,  2.43s/it]                                                   {'loss': 0.2747, 'grad_norm': 0.3146466016769409, 'learning_rate': 2.1544543329725387e-05, 'epoch': 4.48}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1540 [55:47<06:28,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1381/1540 [55:49<06:25,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1382/1540 [55:52<06:22,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1383/1540 [55:54<06:20,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1384/1540 [55:57<06:17,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1385/1540 [55:59<06:15,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1386/1540 [56:01<06:14,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1387/1540 [56:04<06:11,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1388/1540 [56:06<06:08,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1389/1540 [56:09<06:05,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1390/1540 [56:11<06:03,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1391/1540 [56:14<06:00,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1392/1540 [56:16<05:58,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1393/1540 [56:18<05:55,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1394/1540 [56:21<05:53,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1395/1540 [56:23<05:50,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1396/1540 [56:26<05:48,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1397/1540 [56:28<05:45,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1398/1540 [56:31<05:43,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1399/1540 [56:33<05:41,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1540 [56:35<05:38,  2.42s/it]                                                   {'loss': 0.2974, 'grad_norm': 0.2417582869529724, 'learning_rate': 1.6665869740658312e-05, 'epoch': 4.55}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1540 [56:35<05:38,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1401/1540 [56:38<05:36,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1402/1540 [56:40<05:33,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1403/1540 [56:43<05:31,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1404/1540 [56:45<05:29,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1405/1540 [56:47<05:26,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1406/1540 [56:50<05:24,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1407/1540 [56:52<05:21,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1408/1540 [56:55<05:19,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1409/1540 [56:57<05:16,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1410/1540 [57:00<05:14,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1411/1540 [57:02<05:12,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1412/1540 [57:04<05:09,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1413/1540 [57:07<05:07,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1414/1540 [57:09<05:04,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1415/1540 [57:12<05:02,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1416/1540 [57:14<05:00,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1417/1540 [57:16<04:57,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1418/1540 [57:19<04:55,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1419/1540 [57:21<04:53,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1420/1540 [57:24<04:50,  2.42s/it]                                                   {'loss': 0.315, 'grad_norm': 0.22305724024772644, 'learning_rate': 1.2393963852614209e-05, 'epoch': 4.61}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1420/1540 [57:24<04:50,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1421/1540 [57:26<04:48,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1422/1540 [57:29<04:45,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1423/1540 [57:31<04:43,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1424/1540 [57:33<04:40,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1425/1540 [57:36<04:38,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1426/1540 [57:38<04:35,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1427/1540 [57:41<04:33,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1428/1540 [57:43<04:30,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1429/1540 [57:46<04:28,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1430/1540 [57:48<04:26,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1431/1540 [57:50<04:23,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1432/1540 [57:53<04:21,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1433/1540 [57:55<04:19,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1434/1540 [57:58<04:16,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1435/1540 [58:00<04:14,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1436/1540 [58:02<04:11,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1437/1540 [58:05<04:09,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1438/1540 [58:07<04:06,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1439/1540 [58:10<04:04,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1440/1540 [58:12<04:01,  2.42s/it]                                                   {'loss': 0.3119, 'grad_norm': 0.21234291791915894, 'learning_rate': 8.739934432715035e-06, 'epoch': 4.68}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1440/1540 [58:12<04:01,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1441/1540 [58:15<03:59,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1442/1540 [58:17<03:57,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1443/1540 [58:19<03:54,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1444/1540 [58:22<03:52,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1445/1540 [58:24<03:49,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1446/1540 [58:27<03:48,  2.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1447/1540 [58:29<03:46,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1448/1540 [58:32<03:43,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1449/1540 [58:34<03:40,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1450/1540 [58:36<03:38,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1451/1540 [58:39<03:35,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1452/1540 [58:41<03:33,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1453/1540 [58:44<03:30,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1454/1540 [58:46<03:28,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1455/1540 [58:49<03:25,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1456/1540 [58:51<03:23,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1457/1540 [58:53<03:20,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1458/1540 [58:56<03:18,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1459/1540 [58:58<03:15,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1460/1540 [59:01<03:13,  2.42s/it]                                                   {'loss': 0.3092, 'grad_norm': 0.27669259905815125, 'learning_rate': 5.7132835072101484e-06, 'epoch': 4.74}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1460/1540 [59:01<03:13,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1461/1540 [59:03<03:11,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1462/1540 [59:05<03:08,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1463/1540 [59:08<03:06,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1464/1540 [59:10<03:03,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1465/1540 [59:13<03:01,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1466/1540 [59:15<02:59,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1467/1540 [59:18<02:56,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1468/1540 [59:20<02:54,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1469/1540 [59:22<02:51,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1470/1540 [59:25<02:49,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1471/1540 [59:27<02:46,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1472/1540 [59:30<02:44,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1473/1540 [59:32<02:42,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1474/1540 [59:35<02:40,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1475/1540 [59:37<02:37,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1476/1540 [59:39<02:34,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1477/1540 [59:42<02:32,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1478/1540 [59:44<02:30,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1479/1540 [59:47<02:27,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1480/1540 [59:49<02:25,  2.42s/it]                                                   {'loss': 0.309, 'grad_norm': 0.2838241755962372, 'learning_rate': 3.3218816521777827e-06, 'epoch': 4.81}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1480/1540 [59:49<02:25,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1481/1540 [59:51<02:22,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1482/1540 [59:54<02:20,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1483/1540 [59:56<02:17,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1484/1540 [59:59<02:15,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1485/1540 [1:00:01<02:13,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1486/1540 [1:00:04<02:10,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1487/1540 [1:00:06<02:08,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1488/1540 [1:00:08<02:06,  2.43s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1489/1540 [1:00:11<02:03,  2.43s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1490/1540 [1:00:13<02:01,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1491/1540 [1:00:16<01:58,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1492/1540 [1:00:18<01:56,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1493/1540 [1:00:21<01:53,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1494/1540 [1:00:23<01:51,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1495/1540 [1:00:25<01:48,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1496/1540 [1:00:28<01:46,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1497/1540 [1:00:30<01:44,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1498/1540 [1:00:33<01:41,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1499/1540 [1:00:35<01:39,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1500/1540 [1:00:37<01:36,  2.42s/it]                                                     {'loss': 0.2927, 'grad_norm': 0.28549936413764954, 'learning_rate': 1.571947526689349e-06, 'epoch': 4.87}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1500/1540 [1:00:37<01:36,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1501/1540 [1:00:40<01:34,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1502/1540 [1:00:42<01:32,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1503/1540 [1:00:45<01:29,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1504/1540 [1:00:47<01:27,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1505/1540 [1:00:50<01:24,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1506/1540 [1:00:52<01:22,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1507/1540 [1:00:54<01:19,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1508/1540 [1:00:57<01:17,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1509/1540 [1:00:59<01:14,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1510/1540 [1:01:02<01:12,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1511/1540 [1:01:04<01:10,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1512/1540 [1:01:06<01:07,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1513/1540 [1:01:09<01:05,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1514/1540 [1:01:11<01:02,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1515/1540 [1:01:14<01:00,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1516/1540 [1:01:16<00:58,  2.44s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1517/1540 [1:01:19<00:55,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1518/1540 [1:01:21<00:53,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1519/1540 [1:01:23<00:50,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1520/1540 [1:01:26<00:48,  2.42s/it]                                                     {'loss': 0.3064, 'grad_norm': 0.291903018951416, 'learning_rate': 4.680317016582669e-07, 'epoch': 4.94}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1520/1540 [1:01:26<00:48,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1521/1540 [1:01:28<00:46,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1522/1540 [1:01:31<00:43,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1523/1540 [1:01:33<00:41,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1524/1540 [1:01:36<00:38,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1525/1540 [1:01:38<00:36,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1526/1540 [1:01:40<00:33,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1527/1540 [1:01:43<00:31,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1528/1540 [1:01:45<00:29,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1529/1540 [1:01:48<00:26,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1530/1540 [1:01:50<00:24,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1531/1540 [1:01:52<00:21,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1532/1540 [1:01:55<00:19,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1533/1540 [1:01:57<00:16,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1534/1540 [1:02:00<00:14,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1535/1540 [1:02:02<00:12,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1536/1540 [1:02:05<00:09,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1537/1540 [1:02:07<00:07,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1538/1540 [1:02:09<00:04,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1539/1540 [1:02:12<00:02,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it]                                                     {'loss': 0.2957, 'grad_norm': 0.2915961742401123, 'learning_rate': 1.300482642560552e-08, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it][INFO|trainer.py:2231] 2024-05-25 04:39:50,441 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 3744.7167, 'train_samples_per_second': 3.287, 'train_steps_per_second': 0.411, 'train_loss': 0.4382349971052888, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.43s/it]
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4382
  train_runtime            = 1:02:24.71
  train_samples_per_second =      3.287
  train_steps_per_second   =      0.411
[INFO|trainer.py:3203] 2024-05-25 04:39:50,448 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/length_then_extractiveness
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-05-25 04:39:51,624 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:39:51,626 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 04:39:52,202 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:39:52,204 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 04:39:52,256 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 04:39:52,257 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/special_tokens_map.json
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:471] 2024-05-25 04:39:53,197 >> Configuration saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/final_merged_model/config.json
[INFO|configuration_utils.py:697] 2024-05-25 04:39:53,199 >> Configuration saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/final_merged_model/generation_config.json
[INFO|modeling_utils.py:2474] 2024-05-25 04:39:59,148 >> Model weights saved in /scratch/tathagato/adapter_experiments/length_then_extractiveness/final_merged_model/model.safetensors
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.034 MB uploadedwandb: - 0.034 MB of 0.038 MB uploadedwandb: \ 0.034 MB of 0.038 MB uploadedwandb: | 0.034 MB of 0.038 MB uploadedwandb: / 0.034 MB of 0.038 MB uploadedwandb: - 0.034 MB of 0.038 MB uploadedwandb: \ 0.034 MB of 0.038 MB uploadedwandb: | 0.034 MB of 0.038 MB uploadedwandb: / 0.034 MB of 0.038 MB uploadedwandb: - 0.034 MB of 0.038 MB uploadedwandb: \ 0.034 MB of 0.038 MB uploadedwandb: | 0.034 MB of 0.038 MB uploadedwandb: / 0.034 MB of 0.038 MB uploadedwandb: - 0.034 MB of 0.038 MB uploadedwandb: \ 0.034 MB of 0.038 MB uploadedwandb: | 0.034 MB of 0.038 MB uploadedwandb: / 0.034 MB of 0.038 MB uploadedwandb: - 0.034 MB of 0.038 MB uploadedwandb: \ 0.034 MB of 0.038 MB uploadedwandb: | 0.034 MB of 0.038 MB uploadedwandb: / 0.034 MB of 0.038 MB uploadedwandb: - 0.034 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb: train/learning_rate ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 1.5729502080466944e+17
wandb:              train/epoch 5.0
wandb:        train/global_step 1540
wandb:          train/grad_norm 0.2916
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.2957
wandb:               train_loss 0.43823
wandb:            train_runtime 3744.7167
wandb: train_samples_per_second 3.287
wandb:   train_steps_per_second 0.411
wandb: 
wandb: üöÄ View run sleek-snowflake-99 at: https://wandb.ai/ihub-drug-discovery/huggingface/runs/9u7o4mjh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ihub-drug-discovery/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240525_033728-9u7o4mjh/logs
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-05-25 04:40:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 04:40:52 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 04:40:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0005,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/tathagato/adapter_experiments/extractiveness_then_topic/runs/May25_04-40-52_gnode081,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=20,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/tathagato/adapter_experiments/extractiveness_then_topic,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/tathagato/adapter_experiments/extractiveness_then_topic,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=400,
save_strategy=steps,
save_total_limit=400,
seed=0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
2024-05-25 04:40:52 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'o_proj', 'k_proj', 'v_proj', 'q_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
2024-05-25 04:40:52 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 04:40:52 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1 distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:726] 2024-05-25 04:40:52,556 >> loading configuration file config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:40:52,560 >> Model config LlamaConfig {
  "_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": false,
  "vocab_size": 32000
}

[WARNING|modeling_utils.py:3058] 2024-05-25 04:40:52,714 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|quantizer_bnb_4bit.py:247] 2024-05-25 04:40:52,716 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[WARNING|modeling_utils.py:3058] 2024-05-25 04:40:52,716 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:3283] 2024-05-25 04:40:52,717 >> loading weights file model.safetensors from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors
[INFO|modeling_utils.py:1417] 2024-05-25 04:40:52,736 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:928] 2024-05-25 04:40:52,739 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[WARNING|modeling_utils.py:3058] 2024-05-25 04:40:52,977 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 04:40:53,024 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:4024] 2024-05-25 04:40:55,840 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-05-25 04:40:55,841 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-05-25 04:40:56,085 >> loading configuration file generation_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json
[INFO|configuration_utils.py:928] 2024-05-25 04:40:56,085 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

[INFO|tokenization_utils_base.py:2084] 2024-05-25 04:40:56,494 >> loading file tokenizer.model from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-05-25 04:40:56,494 >> loading file tokenizer.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 04:40:56,494 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-05-25 04:40:56,494 >> loading file special_tokens_map.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 04:40:56,494 >> loading file tokenizer_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
train dataset size 2013
test dataset size 272
2013
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
Spawning 10 processes
2024-05-25 04:40:58 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<24:12,  1.38 examples/s]total model parameters : 4505600
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:00<00:06, 272.55 examples/s]train dataset size 2013
test dataset size 272
2013
train dataset size 2013
test dataset size 272
2013
Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 446.96 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 637.36 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 639.06 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:01<00:01, 682.83 examples/s]train dataset size 2013
test dataset size 272
2013
Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 738.40 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 821.45 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<23:29,  1.43 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<24:31,  1.37 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 786.04 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:00<00:06, 276.51 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:01<00:07, 246.67 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:02<00:00, 759.81 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 479.59 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/2013 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 413.85 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 593.65 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 621.04 examples/s]
Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 570.02 examples/s]Concatenating 10 shards
2024-05-25 04:41:02 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 638.50 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:01, 623.79 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:01<00:01, 694.64 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/2013 [00:00<25:23,  1.32 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:02<00:01, 649.81 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 756.58 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 203/2013 [00:01<00:07, 240.77 examples/s]Spawning 10 processes
2024-05-25 04:41:02 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 678.77 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 405/2013 [00:01<00:03, 463.96 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 761.96 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 675.80 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:51,  2.43 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 730.70 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 607/2013 [00:01<00:02, 524.10 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 770.06 examples/s]Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 57/272 [00:00<00:01, 119.80 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:02<00:00, 800.01 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2013 [00:01<00:02, 577.05 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 111/272 [00:00<00:00, 183.89 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 632.93 examples/s]
Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1009/2013 [00:02<00:01, 684.33 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:03<00:00, 648.31 examples/s]Applying chat template to test_sft (num_proc=10):  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 165/272 [00:00<00:00, 206.26 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 245/272 [00:01<00:00, 322.66 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1210/2013 [00:02<00:01, 681.11 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 572.62 examples/s]
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 188.24 examples/s]
Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1411/2013 [00:02<00:00, 714.72 examples/s]Concatenating 10 shards
2024-05-25 04:41:04 - INFO - datasets.arrow_dataset - Concatenating 10 shards
tokenizer padding side left
Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1612/2013 [00:02<00:00, 771.28 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1813/2013 [00:03<00:00, 796.41 examples/s]Using custom data configuration default-6ab037a909b14552
2024-05-25 04:41:04 - INFO - datasets.builder - Using custom data configuration default-6ab037a909b14552
Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
2024-05-25 04:41:04 - INFO - datasets.info - Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
Overwrite dataset info from restored data version if exists.
2024-05-25 04:41:05 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
2024-05-25 04:41:05 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0)
2024-05-25 04:41:05 - INFO - datasets.builder - Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0)
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
2024-05-25 04:41:05 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-6ab037a909b14552/0.0.0
Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:37,  2.79 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2013/2013 [00:03<00:00, 603.79 examples/s]
Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 57/272 [00:00<00:01, 135.89 examples/s]Applying chat template to test_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 110/272 [00:00<00:00, 226.98 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:50,  2.46 examples/s]Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 164/272 [00:00<00:00, 272.31 examples/s]Applying chat template to test_sft (num_proc=10):  11%|‚ñà         | 29/272 [00:00<00:03, 67.55 examples/s]Applying chat template to test_sft (num_proc=10):  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 219/272 [00:00<00:00, 293.09 examples/s]Applying chat template to test_sft (num_proc=10):  31%|‚ñà‚ñà‚ñà       | 84/272 [00:00<00:00, 188.69 examples/s]Applying chat template to test_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 137/272 [00:00<00:00, 244.37 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 226.19 examples/s]
Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 191/272 [00:00<00:00, 316.26 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 245/272 [00:01<00:00, 350.68 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/272 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 216.50 examples/s]
tokenizer padding side left
Applying chat template to test_sft (num_proc=10):   0%|          | 1/272 [00:00<01:59,  2.27 examples/s]Applying chat template to test_sft (num_proc=10):  21%|‚ñà‚ñà        | 57/272 [00:00<00:01, 123.49 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 111/272 [00:00<00:00, 199.61 examples/s]Applying chat template to test_sft (num_proc=10):  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 192/272 [00:00<00:00, 311.35 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 246/272 [00:01<00:00, 320.51 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:01<00:00, 217.58 examples/s]
tokenizer padding side left
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
2024-05-25 04:41:07 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
[INFO|trainer.py:607] 2024-05-25 04:41:09,882 >> Using auto half precision backend
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:1969] 2024-05-25 04:41:10,163 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-05-25 04:41:10,163 >>   Num examples = 1,279
[INFO|trainer.py:1971] 2024-05-25 04:41:10,163 >>   Num Epochs = 5
[INFO|trainer.py:1972] 2024-05-25 04:41:10,163 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-05-25 04:41:10,163 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-05-25 04:41:10,163 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-05-25 04:41:10,163 >>   Total optimization steps = 800
[INFO|trainer.py:1978] 2024-05-25 04:41:10,165 >>   Number of trainable parameters = 4,505,600
[INFO|integration_utils.py:723] 2024-05-25 04:41:10,226 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: roy3 (ihub-drug-discovery). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home2/tathagato/summarization/MACSum/experiments/wandb/run-20240525_044113-uczqljuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-grass-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ihub-drug-discovery/huggingface
wandb: üöÄ View run at https://wandb.ai/ihub-drug-discovery/huggingface/runs/uczqljuo
  0%|          | 0/800 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/800 [00:02<32:45,  2.46s/it]  0%|          | 2/800 [00:04<32:16,  2.43s/it]  0%|          | 3/800 [00:07<32:03,  2.41s/it]  0%|          | 4/800 [00:09<31:59,  2.41s/it]  1%|          | 5/800 [00:12<31:54,  2.41s/it]  1%|          | 6/800 [00:14<31:49,  2.41s/it]  1%|          | 7/800 [00:16<31:47,  2.40s/it]  1%|          | 8/800 [00:19<31:44,  2.40s/it]  1%|          | 9/800 [00:21<31:41,  2.40s/it]  1%|‚ñè         | 10/800 [00:24<31:40,  2.41s/it]  1%|‚ñè         | 11/800 [00:26<31:38,  2.41s/it]  2%|‚ñè         | 12/800 [00:28<31:56,  2.43s/it]  2%|‚ñè         | 13/800 [00:31<31:56,  2.44s/it]  2%|‚ñè         | 14/800 [00:33<31:47,  2.43s/it]  2%|‚ñè         | 15/800 [00:36<31:40,  2.42s/it]  2%|‚ñè         | 16/800 [00:38<31:35,  2.42s/it]  2%|‚ñè         | 17/800 [00:41<31:31,  2.42s/it]  2%|‚ñè         | 18/800 [00:43<31:28,  2.41s/it]  2%|‚ñè         | 19/800 [00:45<31:25,  2.41s/it]  2%|‚ñé         | 20/800 [00:48<31:23,  2.41s/it]                                                {'loss': 0.7247, 'grad_norm': 0.5829604864120483, 'learning_rate': 6.25e-05, 'epoch': 0.12}
  2%|‚ñé         | 20/800 [00:48<31:23,  2.41s/it]  3%|‚ñé         | 21/800 [00:50<31:20,  2.41s/it]  3%|‚ñé         | 22/800 [00:53<31:17,  2.41s/it]  3%|‚ñé         | 23/800 [00:55<31:14,  2.41s/it]  3%|‚ñé         | 24/800 [00:57<31:12,  2.41s/it]  3%|‚ñé         | 25/800 [01:00<31:11,  2.42s/it]  3%|‚ñé         | 26/800 [01:02<31:16,  2.43s/it]  3%|‚ñé         | 27/800 [01:05<31:12,  2.42s/it]  4%|‚ñé         | 28/800 [01:07<31:07,  2.42s/it]  4%|‚ñé         | 29/800 [01:10<31:09,  2.43s/it]  4%|‚ñç         | 30/800 [01:12<31:06,  2.42s/it]  4%|‚ñç         | 31/800 [01:14<31:03,  2.42s/it]  4%|‚ñç         | 32/800 [01:17<30:58,  2.42s/it]  4%|‚ñç         | 33/800 [01:19<30:55,  2.42s/it]  4%|‚ñç         | 34/800 [01:22<30:52,  2.42s/it]  4%|‚ñç         | 35/800 [01:24<30:51,  2.42s/it]  4%|‚ñç         | 36/800 [01:27<30:48,  2.42s/it]  5%|‚ñç         | 37/800 [01:29<30:45,  2.42s/it]  5%|‚ñç         | 38/800 [01:31<30:43,  2.42s/it]  5%|‚ñç         | 39/800 [01:34<30:46,  2.43s/it]  5%|‚ñå         | 40/800 [01:36<30:42,  2.42s/it]                                                {'loss': 0.6589, 'grad_norm': 0.5035312175750732, 'learning_rate': 0.000125, 'epoch': 0.25}
  5%|‚ñå         | 40/800 [01:36<30:42,  2.42s/it]  5%|‚ñå         | 41/800 [01:39<30:38,  2.42s/it]  5%|‚ñå         | 42/800 [01:41<30:39,  2.43s/it]  5%|‚ñå         | 43/800 [01:44<30:36,  2.43s/it]  6%|‚ñå         | 44/800 [01:46<30:32,  2.42s/it]  6%|‚ñå         | 45/800 [01:48<30:29,  2.42s/it]  6%|‚ñå         | 46/800 [01:51<30:26,  2.42s/it]  6%|‚ñå         | 47/800 [01:53<30:22,  2.42s/it]  6%|‚ñå         | 48/800 [01:56<30:19,  2.42s/it]  6%|‚ñå         | 49/800 [01:58<30:17,  2.42s/it]  6%|‚ñã         | 50/800 [02:00<30:14,  2.42s/it]  6%|‚ñã         | 51/800 [02:03<30:11,  2.42s/it]  6%|‚ñã         | 52/800 [02:05<30:09,  2.42s/it]  7%|‚ñã         | 53/800 [02:08<30:07,  2.42s/it]  7%|‚ñã         | 54/800 [02:10<30:10,  2.43s/it]  7%|‚ñã         | 55/800 [02:13<30:06,  2.42s/it]  7%|‚ñã         | 56/800 [02:15<30:17,  2.44s/it]  7%|‚ñã         | 57/800 [02:17<30:10,  2.44s/it]  7%|‚ñã         | 58/800 [02:20<30:03,  2.43s/it]  7%|‚ñã         | 59/800 [02:22<29:58,  2.43s/it]  8%|‚ñä         | 60/800 [02:25<29:54,  2.43s/it]                                                {'loss': 0.6546, 'grad_norm': 0.46619346737861633, 'learning_rate': 0.0001875, 'epoch': 0.38}
  8%|‚ñä         | 60/800 [02:25<29:54,  2.43s/it]  8%|‚ñä         | 61/800 [02:27<29:51,  2.42s/it]  8%|‚ñä         | 62/800 [02:30<29:47,  2.42s/it]  8%|‚ñä         | 63/800 [02:32<29:45,  2.42s/it]  8%|‚ñä         | 64/800 [02:34<29:42,  2.42s/it]  8%|‚ñä         | 65/800 [02:37<29:39,  2.42s/it]  8%|‚ñä         | 66/800 [02:39<29:36,  2.42s/it]  8%|‚ñä         | 67/800 [02:42<29:34,  2.42s/it]  8%|‚ñä         | 68/800 [02:44<29:36,  2.43s/it]  9%|‚ñä         | 69/800 [02:47<29:31,  2.42s/it]  9%|‚ñâ         | 70/800 [02:49<29:32,  2.43s/it]  9%|‚ñâ         | 71/800 [02:51<29:28,  2.43s/it]  9%|‚ñâ         | 72/800 [02:54<29:24,  2.42s/it]  9%|‚ñâ         | 73/800 [02:56<29:21,  2.42s/it]  9%|‚ñâ         | 74/800 [02:59<29:18,  2.42s/it]  9%|‚ñâ         | 75/800 [03:01<29:15,  2.42s/it] 10%|‚ñâ         | 76/800 [03:03<29:13,  2.42s/it] 10%|‚ñâ         | 77/800 [03:06<29:10,  2.42s/it] 10%|‚ñâ         | 78/800 [03:08<29:07,  2.42s/it] 10%|‚ñâ         | 79/800 [03:11<29:04,  2.42s/it] 10%|‚ñà         | 80/800 [03:13<29:02,  2.42s/it]                                                {'loss': 0.6327, 'grad_norm': 0.3986881375312805, 'learning_rate': 0.00025, 'epoch': 0.5}
 10%|‚ñà         | 80/800 [03:13<29:02,  2.42s/it] 10%|‚ñà         | 81/800 [03:16<29:00,  2.42s/it] 10%|‚ñà         | 82/800 [03:18<28:58,  2.42s/it] 10%|‚ñà         | 83/800 [03:20<29:00,  2.43s/it] 10%|‚ñà         | 84/800 [03:23<28:56,  2.43s/it] 11%|‚ñà         | 85/800 [03:25<28:52,  2.42s/it] 11%|‚ñà         | 86/800 [03:28<28:49,  2.42s/it] 11%|‚ñà         | 87/800 [03:30<28:46,  2.42s/it] 11%|‚ñà         | 88/800 [03:33<28:44,  2.42s/it] 11%|‚ñà         | 89/800 [03:35<28:40,  2.42s/it] 11%|‚ñà‚ñè        | 90/800 [03:37<28:38,  2.42s/it] 11%|‚ñà‚ñè        | 91/800 [03:40<28:36,  2.42s/it] 12%|‚ñà‚ñè        | 92/800 [03:42<28:33,  2.42s/it] 12%|‚ñà‚ñè        | 93/800 [03:45<28:30,  2.42s/it] 12%|‚ñà‚ñè        | 94/800 [03:47<28:28,  2.42s/it] 12%|‚ñà‚ñè        | 95/800 [03:49<28:25,  2.42s/it] 12%|‚ñà‚ñè        | 96/800 [03:52<28:23,  2.42s/it] 12%|‚ñà‚ñè        | 97/800 [03:54<28:26,  2.43s/it] 12%|‚ñà‚ñè        | 98/800 [03:57<28:30,  2.44s/it] 12%|‚ñà‚ñè        | 99/800 [03:59<28:24,  2.43s/it] 12%|‚ñà‚ñé        | 100/800 [04:02<28:19,  2.43s/it]                                                 {'loss': 0.6265, 'grad_norm': 0.42130404710769653, 'learning_rate': 0.0003125, 'epoch': 0.62}
 12%|‚ñà‚ñé        | 100/800 [04:02<28:19,  2.43s/it] 13%|‚ñà‚ñé        | 101/800 [04:04<28:16,  2.43s/it] 13%|‚ñà‚ñé        | 102/800 [04:06<28:12,  2.42s/it] 13%|‚ñà‚ñé        | 103/800 [04:09<28:08,  2.42s/it] 13%|‚ñà‚ñé        | 104/800 [04:11<28:05,  2.42s/it] 13%|‚ñà‚ñé        | 105/800 [04:14<28:03,  2.42s/it] 13%|‚ñà‚ñé        | 106/800 [04:16<28:00,  2.42s/it] 13%|‚ñà‚ñé        | 107/800 [04:19<27:57,  2.42s/it] 14%|‚ñà‚ñé        | 108/800 [04:21<27:54,  2.42s/it] 14%|‚ñà‚ñé        | 109/800 [04:23<27:52,  2.42s/it] 14%|‚ñà‚ñç        | 110/800 [04:26<27:49,  2.42s/it] 14%|‚ñà‚ñç        | 111/800 [04:28<27:53,  2.43s/it] 14%|‚ñà‚ñç        | 112/800 [04:31<27:56,  2.44s/it] 14%|‚ñà‚ñç        | 113/800 [04:33<27:50,  2.43s/it] 14%|‚ñà‚ñç        | 114/800 [04:36<27:45,  2.43s/it] 14%|‚ñà‚ñç        | 115/800 [04:38<27:41,  2.43s/it] 14%|‚ñà‚ñç        | 116/800 [04:40<27:37,  2.42s/it] 15%|‚ñà‚ñç        | 117/800 [04:43<27:34,  2.42s/it] 15%|‚ñà‚ñç        | 118/800 [04:45<27:31,  2.42s/it] 15%|‚ñà‚ñç        | 119/800 [04:48<27:28,  2.42s/it] 15%|‚ñà‚ñå        | 120/800 [04:50<27:25,  2.42s/it]                                                 {'loss': 0.6533, 'grad_norm': 0.34104010462760925, 'learning_rate': 0.000375, 'epoch': 0.75}
 15%|‚ñà‚ñå        | 120/800 [04:50<27:25,  2.42s/it] 15%|‚ñà‚ñå        | 121/800 [04:53<27:23,  2.42s/it] 15%|‚ñà‚ñå        | 122/800 [04:55<27:21,  2.42s/it] 15%|‚ñà‚ñå        | 123/800 [04:57<27:18,  2.42s/it] 16%|‚ñà‚ñå        | 124/800 [05:00<27:16,  2.42s/it] 16%|‚ñà‚ñå        | 125/800 [05:02<27:14,  2.42s/it] 16%|‚ñà‚ñå        | 126/800 [05:05<27:24,  2.44s/it] 16%|‚ñà‚ñå        | 127/800 [05:07<27:17,  2.43s/it] 16%|‚ñà‚ñå        | 128/800 [05:10<27:13,  2.43s/it] 16%|‚ñà‚ñå        | 129/800 [05:12<27:08,  2.43s/it] 16%|‚ñà‚ñã        | 130/800 [05:14<27:04,  2.43s/it] 16%|‚ñà‚ñã        | 131/800 [05:17<27:01,  2.42s/it] 16%|‚ñà‚ñã        | 132/800 [05:19<26:57,  2.42s/it] 17%|‚ñà‚ñã        | 133/800 [05:22<26:55,  2.42s/it] 17%|‚ñà‚ñã        | 134/800 [05:24<26:52,  2.42s/it] 17%|‚ñà‚ñã        | 135/800 [05:26<26:50,  2.42s/it] 17%|‚ñà‚ñã        | 136/800 [05:29<26:47,  2.42s/it] 17%|‚ñà‚ñã        | 137/800 [05:31<26:44,  2.42s/it] 17%|‚ñà‚ñã        | 138/800 [05:34<26:42,  2.42s/it] 17%|‚ñà‚ñã        | 139/800 [05:36<26:45,  2.43s/it] 18%|‚ñà‚ñä        | 140/800 [05:39<26:41,  2.43s/it]                                                 {'loss': 0.6284, 'grad_norm': 0.32044461369514465, 'learning_rate': 0.0004375, 'epoch': 0.88}
 18%|‚ñà‚ñä        | 140/800 [05:39<26:41,  2.43s/it] 18%|‚ñà‚ñä        | 141/800 [05:41<26:40,  2.43s/it] 18%|‚ñà‚ñä        | 142/800 [05:43<26:35,  2.43s/it] 18%|‚ñà‚ñä        | 143/800 [05:46<26:32,  2.42s/it] 18%|‚ñà‚ñä        | 144/800 [05:48<26:29,  2.42s/it] 18%|‚ñà‚ñä        | 145/800 [05:51<26:26,  2.42s/it] 18%|‚ñà‚ñä        | 146/800 [05:53<26:23,  2.42s/it] 18%|‚ñà‚ñä        | 147/800 [05:56<26:20,  2.42s/it] 18%|‚ñà‚ñä        | 148/800 [05:58<26:17,  2.42s/it] 19%|‚ñà‚ñä        | 149/800 [06:00<26:15,  2.42s/it] 19%|‚ñà‚ñâ        | 150/800 [06:03<26:12,  2.42s/it] 19%|‚ñà‚ñâ        | 151/800 [06:05<26:10,  2.42s/it] 19%|‚ñà‚ñâ        | 152/800 [06:08<26:14,  2.43s/it] 19%|‚ñà‚ñâ        | 153/800 [06:10<26:10,  2.43s/it] 19%|‚ñà‚ñâ        | 154/800 [06:13<26:06,  2.42s/it] 19%|‚ñà‚ñâ        | 155/800 [06:15<26:06,  2.43s/it] 20%|‚ñà‚ñâ        | 156/800 [06:17<26:02,  2.43s/it] 20%|‚ñà‚ñâ        | 157/800 [06:20<25:58,  2.42s/it] 20%|‚ñà‚ñâ        | 158/800 [06:22<25:55,  2.42s/it] 20%|‚ñà‚ñâ        | 159/800 [06:25<25:52,  2.42s/it] 20%|‚ñà‚ñà        | 160/800 [06:27<25:48,  2.42s/it]                                                 {'loss': 0.5444, 'grad_norm': 0.44764962792396545, 'learning_rate': 0.0005, 'epoch': 1.0}
 20%|‚ñà‚ñà        | 160/800 [06:27<25:48,  2.42s/it] 20%|‚ñà‚ñà        | 161/800 [06:29<25:47,  2.42s/it] 20%|‚ñà‚ñà        | 162/800 [06:32<25:45,  2.42s/it] 20%|‚ñà‚ñà        | 163/800 [06:34<25:41,  2.42s/it] 20%|‚ñà‚ñà        | 164/800 [06:37<25:39,  2.42s/it] 21%|‚ñà‚ñà        | 165/800 [06:39<25:36,  2.42s/it] 21%|‚ñà‚ñà        | 166/800 [06:42<25:33,  2.42s/it] 21%|‚ñà‚ñà        | 167/800 [06:44<25:31,  2.42s/it] 21%|‚ñà‚ñà        | 168/800 [06:46<25:33,  2.43s/it] 21%|‚ñà‚ñà        | 169/800 [06:49<25:29,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 170/800 [06:51<25:29,  2.43s/it] 21%|‚ñà‚ñà‚ñè       | 171/800 [06:54<25:25,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 172/800 [06:56<25:21,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 173/800 [06:59<25:18,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 174/800 [07:01<25:15,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 175/800 [07:03<25:12,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 176/800 [07:06<25:09,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 177/800 [07:08<25:07,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 178/800 [07:11<25:05,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 179/800 [07:13<25:02,  2.42s/it] 22%|‚ñà‚ñà‚ñé       | 180/800 [07:15<24:59,  2.42s/it]                                                 {'loss': 0.5367, 'grad_norm': 0.291184663772583, 'learning_rate': 0.0004989134688583259, 'epoch': 1.12}
 22%|‚ñà‚ñà‚ñé       | 180/800 [07:15<24:59,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 181/800 [07:18<25:01,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 182/800 [07:20<24:57,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 183/800 [07:23<24:54,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 184/800 [07:25<24:55,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 185/800 [07:28<24:51,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 186/800 [07:30<24:47,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 187/800 [07:32<24:44,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 188/800 [07:35<24:41,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 189/800 [07:37<24:38,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 190/800 [07:40<24:36,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 191/800 [07:42<24:33,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 192/800 [07:45<24:30,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 193/800 [07:47<24:28,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 194/800 [07:49<24:26,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 195/800 [07:52<24:33,  2.44s/it] 24%|‚ñà‚ñà‚ñç       | 196/800 [07:54<24:28,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 197/800 [07:57<24:23,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 198/800 [07:59<24:19,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 199/800 [08:02<24:17,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 200/800 [08:04<24:13,  2.42s/it]                                                 {'loss': 0.5678, 'grad_norm': 0.2916456162929535, 'learning_rate': 0.0004954327768997885, 'epoch': 1.25}
 25%|‚ñà‚ñà‚ñå       | 200/800 [08:04<24:13,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 201/800 [08:06<24:11,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 202/800 [08:09<24:08,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 203/800 [08:11<24:05,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 204/800 [08:14<24:02,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 205/800 [08:16<24:00,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 206/800 [08:19<23:58,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 207/800 [08:21<23:55,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 208/800 [08:23<23:52,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 209/800 [08:26<23:54,  2.43s/it] 26%|‚ñà‚ñà‚ñã       | 210/800 [08:28<23:50,  2.43s/it] 26%|‚ñà‚ñà‚ñã       | 211/800 [08:31<23:47,  2.42s/it] 26%|‚ñà‚ñà‚ñã       | 212/800 [08:33<23:44,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 213/800 [08:35<23:42,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 214/800 [08:38<23:38,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 215/800 [08:40<23:36,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 216/800 [08:43<23:33,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 217/800 [08:45<23:30,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 218/800 [08:48<23:28,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 219/800 [08:50<23:25,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 220/800 [08:52<23:23,  2.42s/it]                                                 {'loss': 0.5694, 'grad_norm': 0.37783586978912354, 'learning_rate': 0.0004895884331325028, 'epoch': 1.38}
 28%|‚ñà‚ñà‚ñä       | 220/800 [08:52<23:23,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 221/800 [08:55<23:21,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 222/800 [08:57<23:26,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 223/800 [09:00<23:21,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 224/800 [09:02<23:17,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 225/800 [09:05<23:13,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 226/800 [09:07<23:10,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 227/800 [09:09<23:07,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 228/800 [09:12<23:11,  2.43s/it] 29%|‚ñà‚ñà‚ñä       | 229/800 [09:14<23:06,  2.43s/it] 29%|‚ñà‚ñà‚ñâ       | 230/800 [09:17<23:02,  2.43s/it] 29%|‚ñà‚ñà‚ñâ       | 231/800 [09:19<22:58,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 232/800 [09:22<22:55,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 233/800 [09:24<22:52,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 234/800 [09:26<22:49,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 235/800 [09:29<22:47,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 236/800 [09:31<22:44,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 237/800 [09:34<22:44,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 238/800 [09:36<22:41,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 239/800 [09:38<22:38,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 240/800 [09:41<22:35,  2.42s/it]                                                 {'loss': 0.5635, 'grad_norm': 0.36406001448631287, 'learning_rate': 0.000481436721781791, 'epoch': 1.5}
 30%|‚ñà‚ñà‚ñà       | 240/800 [09:41<22:35,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 241/800 [09:43<22:33,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 242/800 [09:46<22:30,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 243/800 [09:48<22:28,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 244/800 [09:51<22:25,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 245/800 [09:53<22:23,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 246/800 [09:55<22:20,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 247/800 [09:58<22:18,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 248/800 [10:00<22:16,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 249/800 [10:03<22:13,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 250/800 [10:05<22:17,  2.43s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 251/800 [10:08<22:12,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 252/800 [10:10<22:08,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 253/800 [10:12<22:05,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 254/800 [10:15<22:02,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 255/800 [10:17<21:59,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 256/800 [10:20<21:56,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 257/800 [10:22<21:59,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 258/800 [10:25<21:55,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 259/800 [10:27<21:51,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 260/800 [10:29<21:48,  2.42s/it]                                                 {'loss': 0.5666, 'grad_norm': 0.37840816378593445, 'learning_rate': 0.00047105614828413906, 'epoch': 1.62}
 32%|‚ñà‚ñà‚ñà‚ñé      | 260/800 [10:29<21:48,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 261/800 [10:32<21:45,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 262/800 [10:34<21:42,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 263/800 [10:37<21:39,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 264/800 [10:39<21:37,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 265/800 [10:41<21:42,  2.43s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 266/800 [10:44<21:37,  2.43s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 267/800 [10:46<21:33,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 268/800 [10:49<21:29,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 269/800 [10:51<21:26,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 270/800 [10:54<21:23,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 271/800 [10:56<21:23,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 272/800 [10:58<21:20,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 273/800 [11:01<21:16,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 274/800 [11:03<21:13,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 275/800 [11:06<21:10,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 276/800 [11:08<21:07,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 277/800 [11:11<21:05,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 278/800 [11:13<21:09,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 279/800 [11:15<21:04,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 280/800 [11:18<21:01,  2.43s/it]                                                 {'loss': 0.5295, 'grad_norm': 0.3589911162853241, 'learning_rate': 0.00045854668323692813, 'epoch': 1.75}
 35%|‚ñà‚ñà‚ñà‚ñå      | 280/800 [11:18<21:01,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 281/800 [11:20<20:57,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 282/800 [11:23<20:54,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 283/800 [11:25<20:51,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 284/800 [11:28<20:48,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 285/800 [11:30<20:46,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 286/800 [11:32<20:43,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 287/800 [11:35<20:41,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 288/800 [11:37<20:38,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 289/800 [11:40<20:35,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 290/800 [11:42<20:33,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 291/800 [11:44<20:31,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 292/800 [11:47<20:28,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 293/800 [11:49<20:25,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 294/800 [11:52<20:23,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 295/800 [11:54<20:21,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 296/800 [11:57<20:18,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 297/800 [11:59<20:16,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 298/800 [12:01<20:14,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 299/800 [12:04<20:11,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 300/800 [12:06<20:13,  2.43s/it]                                                 {'loss': 0.5064, 'grad_norm': 0.3543568551540375, 'learning_rate': 0.000444028799626932, 'epoch': 1.88}
 38%|‚ñà‚ñà‚ñà‚ñä      | 300/800 [12:06<20:13,  2.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 301/800 [12:09<20:10,  2.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 302/800 [12:11<20:07,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 303/800 [12:13<20:04,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 304/800 [12:16<20:00,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 305/800 [12:18<19:58,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 306/800 [12:21<19:55,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 307/800 [12:23<19:56,  2.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 308/800 [12:26<19:52,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 309/800 [12:28<19:49,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 310/800 [12:30<19:46,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 311/800 [12:33<19:43,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 312/800 [12:35<19:41,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 313/800 [12:38<19:38,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 314/800 [12:40<19:35,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 315/800 [12:43<19:35,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 316/800 [12:45<19:32,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 317/800 [12:47<19:28,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 318/800 [12:50<19:26,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 319/800 [12:52<19:23,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 320/800 [12:55<19:24,  2.43s/it]                                                 {'loss': 0.5477, 'grad_norm': 0.3580779731273651, 'learning_rate': 0.0004276423126095974, 'epoch': 2.0}
 40%|‚ñà‚ñà‚ñà‚ñà      | 320/800 [12:55<19:24,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 321/800 [12:57<19:21,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 322/800 [13:00<19:18,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 323/800 [13:02<19:15,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 324/800 [13:04<19:12,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 325/800 [13:07<19:09,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 326/800 [13:09<19:07,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 327/800 [13:12<19:05,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 328/800 [13:14<19:02,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 329/800 [13:16<19:00,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 330/800 [13:19<18:57,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 331/800 [13:21<18:55,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 332/800 [13:24<18:52,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 333/800 [13:26<18:49,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 334/800 [13:29<18:56,  2.44s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 335/800 [13:31<18:50,  2.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 336/800 [13:33<18:46,  2.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 337/800 [13:36<18:42,  2.43s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 338/800 [13:38<18:39,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 339/800 [13:41<18:36,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 340/800 [13:43<18:33,  2.42s/it]                                                 {'loss': 0.4251, 'grad_norm': 0.3414101302623749, 'learning_rate': 0.0004095450330126663, 'epoch': 2.12}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 340/800 [13:43<18:33,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 341/800 [13:46<18:31,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 342/800 [13:48<18:28,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 343/800 [13:50<18:25,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 344/800 [13:53<18:24,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 345/800 [13:55<18:21,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 346/800 [13:58<18:18,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 347/800 [14:00<18:16,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 348/800 [14:03<18:15,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 349/800 [14:05<18:12,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 350/800 [14:07<18:09,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 351/800 [14:10<18:06,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 352/800 [14:12<18:04,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 353/800 [14:15<18:02,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 354/800 [14:17<17:59,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 355/800 [14:19<17:56,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 356/800 [14:22<17:54,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 357/800 [14:24<17:51,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 358/800 [14:27<17:49,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 359/800 [14:29<17:46,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 360/800 [14:32<17:44,  2.42s/it]                                                 {'loss': 0.4626, 'grad_norm': 0.3966505527496338, 'learning_rate': 0.0003899112475316365, 'epoch': 2.25}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 360/800 [14:32<17:44,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 361/800 [14:34<17:42,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 362/800 [14:36<17:39,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 363/800 [14:39<17:37,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 364/800 [14:41<17:35,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 365/800 [14:44<17:32,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 366/800 [14:46<17:30,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 367/800 [14:48<17:27,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 368/800 [14:51<17:25,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 369/800 [14:53<17:22,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 370/800 [14:56<17:20,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 371/800 [14:58<17:17,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 372/800 [15:01<17:16,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 373/800 [15:03<17:16,  2.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 374/800 [15:05<17:12,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 375/800 [15:08<17:09,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 376/800 [15:10<17:07,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 377/800 [15:13<17:04,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 378/800 [15:15<17:02,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 379/800 [15:18<16:59,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 380/800 [15:20<16:56,  2.42s/it]                                                 {'loss': 0.4672, 'grad_norm': 0.3372878432273865, 'learning_rate': 0.00036893004025360926, 'epoch': 2.38}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 380/800 [15:20<16:56,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 381/800 [15:22<16:54,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 382/800 [15:25<16:51,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 383/800 [15:27<16:48,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 384/800 [15:30<16:46,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 385/800 [15:32<16:43,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 386/800 [15:34<16:41,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 387/800 [15:37<16:39,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 388/800 [15:39<16:38,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 389/800 [15:42<16:38,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 390/800 [15:44<16:34,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 391/800 [15:47<16:31,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 392/800 [15:49<16:28,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 393/800 [15:51<16:25,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 394/800 [15:54<16:22,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 395/800 [15:56<16:20,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 396/800 [15:59<16:17,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 397/800 [16:01<16:15,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 398/800 [16:04<16:12,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 399/800 [16:06<16:10,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 400/800 [16:08<16:07,  2.42s/it]                                                 {'loss': 0.4532, 'grad_norm': 0.340384304523468, 'learning_rate': 0.00034680347167416643, 'epoch': 2.5}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 400/800 [16:08<16:07,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 04:57:30,617 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_topic/checkpoint-400
[INFO|configuration_utils.py:726] 2024-05-25 04:57:32,159 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 04:57:32,162 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 04:57:32,255 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 04:57:32,255 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/checkpoint-400/special_tokens_map.json
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 401/800 [16:13<19:41,  2.96s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 402/800 [16:15<18:33,  2.80s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 403/800 [16:17<17:45,  2.68s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 404/800 [16:20<17:21,  2.63s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 405/800 [16:22<16:53,  2.57s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 406/800 [16:25<16:33,  2.52s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 407/800 [16:27<16:19,  2.49s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 408/800 [16:30<16:08,  2.47s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 409/800 [16:32<15:59,  2.45s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 410/800 [16:34<15:53,  2.44s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 411/800 [16:37<15:47,  2.44s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 412/800 [16:39<15:43,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 413/800 [16:42<15:40,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 414/800 [16:44<15:36,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 415/800 [16:47<15:48,  2.46s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 416/800 [16:49<15:40,  2.45s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 417/800 [16:52<15:35,  2.44s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 418/800 [16:54<15:29,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 419/800 [16:56<15:25,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 420/800 [16:59<15:22,  2.43s/it]                                                 {'loss': 0.4631, 'grad_norm': 0.43318063020706177, 'learning_rate': 0.00032374463274434097, 'epoch': 2.62}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 420/800 [16:59<15:22,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 421/800 [17:01<15:18,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 422/800 [17:04<15:16,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 423/800 [17:06<15:13,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 424/800 [17:08<15:10,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 425/800 [17:11<15:08,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 426/800 [17:13<15:05,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 427/800 [17:16<15:03,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 428/800 [17:18<15:01,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 429/800 [17:21<14:58,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 430/800 [17:23<14:57,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 431/800 [17:25<14:54,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 432/800 [17:28<14:51,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 433/800 [17:30<14:48,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 434/800 [17:33<14:45,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 435/800 [17:35<14:43,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 436/800 [17:38<14:40,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 437/800 [17:40<14:38,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 438/800 [17:42<14:36,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 439/800 [17:45<14:33,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 440/800 [17:47<14:31,  2.42s/it]                                                 {'loss': 0.4716, 'grad_norm': 0.38735485076904297, 'learning_rate': 0.00029997559268827044, 'epoch': 2.75}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 440/800 [17:47<14:31,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 441/800 [17:50<14:28,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 442/800 [17:52<14:25,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 443/800 [17:54<14:23,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 444/800 [17:57<14:20,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 445/800 [17:59<14:18,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 446/800 [18:02<14:18,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 447/800 [18:04<14:15,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 448/800 [18:07<14:12,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 449/800 [18:09<14:09,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 450/800 [18:11<14:07,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 451/800 [18:14<14:04,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 452/800 [18:16<14:02,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 453/800 [18:19<13:59,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 454/800 [18:21<13:57,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 455/800 [18:24<13:54,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 456/800 [18:26<13:52,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 457/800 [18:28<13:49,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 458/800 [18:31<13:47,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 459/800 [18:33<13:50,  2.44s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 460/800 [18:36<13:46,  2.43s/it]                                                 {'loss': 0.4158, 'grad_norm': 0.3683862090110779, 'learning_rate': 0.00027694561576068985, 'epoch': 2.88}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 460/800 [18:36<13:46,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 461/800 [18:38<13:42,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 462/800 [18:41<13:39,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 463/800 [18:43<13:36,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 464/800 [18:45<13:33,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 465/800 [18:48<13:30,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 466/800 [18:50<13:28,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 467/800 [18:53<13:25,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 468/800 [18:55<13:23,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 469/800 [18:57<13:20,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 470/800 [19:00<13:18,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 471/800 [19:02<13:15,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 472/800 [19:05<13:13,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 473/800 [19:07<13:16,  2.43s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 474/800 [19:10<13:12,  2.43s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 475/800 [19:12<13:08,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 476/800 [19:14<13:05,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 477/800 [19:17<13:02,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 478/800 [19:19<12:59,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 479/800 [19:22<12:56,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 480/800 [19:24<12:54,  2.42s/it]                                                 {'loss': 0.4199, 'grad_norm': 0.34820064902305603, 'learning_rate': 0.0002524543298342875, 'epoch': 3.0}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 480/800 [19:24<12:54,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 481/800 [19:27<12:51,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 482/800 [19:29<12:49,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 483/800 [19:31<12:47,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 484/800 [19:34<12:44,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 485/800 [19:36<12:42,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 486/800 [19:39<12:39,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 487/800 [19:41<12:37,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 488/800 [19:43<12:36,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 489/800 [19:46<12:33,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 490/800 [19:48<12:30,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 491/800 [19:51<12:27,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 492/800 [19:53<12:25,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 493/800 [19:56<12:22,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 494/800 [19:58<12:20,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 495/800 [20:00<12:17,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 496/800 [20:03<12:15,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 497/800 [20:05<12:12,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 498/800 [20:08<12:10,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 499/800 [20:10<12:07,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 500/800 [20:13<12:07,  2.43s/it]                                                 {'loss': 0.3593, 'grad_norm': 0.2820706367492676, 'learning_rate': 0.00022793940736990766, 'epoch': 3.12}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 500/800 [20:13<12:07,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 501/800 [20:15<12:05,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 502/800 [20:17<12:02,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 503/800 [20:20<11:59,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 504/800 [20:22<11:56,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 505/800 [20:25<11:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 506/800 [20:27<11:51,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 507/800 [20:29<11:48,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 508/800 [20:32<11:46,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 509/800 [20:34<11:44,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 510/800 [20:37<11:41,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 511/800 [20:39<11:39,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 512/800 [20:42<11:36,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 513/800 [20:44<11:34,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 514/800 [20:46<11:31,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 515/800 [20:49<11:31,  2.43s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 516/800 [20:51<11:28,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 517/800 [20:54<11:25,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 518/800 [20:56<11:22,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 519/800 [20:58<11:20,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 520/800 [21:01<11:17,  2.42s/it]                                                 {'loss': 0.3526, 'grad_norm': 0.32307159900665283, 'learning_rate': 0.00020363694047210228, 'epoch': 3.25}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 520/800 [21:01<11:17,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 521/800 [21:03<11:15,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 522/800 [21:06<11:12,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 523/800 [21:08<11:09,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 524/800 [21:11<11:07,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 525/800 [21:13<11:05,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 526/800 [21:15<11:02,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 527/800 [21:18<11:00,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 528/800 [21:20<10:58,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 529/800 [21:23<10:55,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 530/800 [21:25<10:53,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 531/800 [21:28<10:51,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 532/800 [21:30<10:48,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 533/800 [21:32<10:45,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 534/800 [21:35<10:43,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 535/800 [21:37<10:40,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 536/800 [21:40<10:38,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 537/800 [21:42<10:36,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 538/800 [21:44<10:33,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 539/800 [21:47<10:31,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 540/800 [21:49<10:28,  2.42s/it]                                                 {'loss': 0.3659, 'grad_norm': 0.3034501373767853, 'learning_rate': 0.00017978097518217702, 'epoch': 3.38}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 540/800 [21:49<10:28,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 541/800 [21:52<10:26,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 542/800 [21:54<10:24,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 543/800 [21:57<10:25,  2.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 544/800 [21:59<10:21,  2.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 545/800 [22:01<10:18,  2.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 546/800 [22:04<10:15,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 547/800 [22:06<10:12,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 548/800 [22:09<10:10,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 549/800 [22:11<10:07,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 550/800 [22:14<10:04,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 551/800 [22:16<10:02,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 552/800 [22:18<09:59,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 553/800 [22:21<09:57,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 554/800 [22:23<09:54,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 555/800 [22:26<09:52,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 556/800 [22:28<09:52,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 557/800 [22:30<09:49,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 558/800 [22:33<09:46,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 559/800 [22:35<09:43,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 560/800 [22:38<09:41,  2.42s/it]                                                 {'loss': 0.365, 'grad_norm': 0.31348732113838196, 'learning_rate': 0.00015660125748687094, 'epoch': 3.5}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 560/800 [22:38<09:41,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 561/800 [22:40<09:38,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 562/800 [22:43<09:36,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 563/800 [22:45<09:33,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 564/800 [22:47<09:31,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 565/800 [22:50<09:28,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 566/800 [22:52<09:25,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 567/800 [22:55<09:23,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 568/800 [22:57<09:21,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 569/800 [23:00<09:20,  2.43s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 570/800 [23:02<09:17,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 571/800 [23:04<09:15,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 572/800 [23:07<09:12,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 573/800 [23:09<09:09,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 574/800 [23:12<09:06,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 575/800 [23:14<09:06,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 576/800 [23:17<09:03,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 577/800 [23:19<09:00,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 578/800 [23:21<08:57,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 579/800 [23:24<08:55,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 580/800 [23:26<08:52,  2.42s/it]                                                 {'loss': 0.3905, 'grad_norm': 0.3257782757282257, 'learning_rate': 0.00013541031734468211, 'epoch': 3.62}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 580/800 [23:26<08:52,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 581/800 [23:29<08:50,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 582/800 [23:31<08:47,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 583/800 [23:33<08:45,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 584/800 [23:36<08:42,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 585/800 [23:38<08:41,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 586/800 [23:41<08:38,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 587/800 [23:43<08:35,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 588/800 [23:46<08:33,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 589/800 [23:48<08:30,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 590/800 [23:50<08:28,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 591/800 [23:53<08:25,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 592/800 [23:55<08:23,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 593/800 [23:58<08:20,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 594/800 [24:00<08:18,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 595/800 [24:02<08:15,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 596/800 [24:05<08:13,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 597/800 [24:07<08:10,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 598/800 [24:10<08:08,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 599/800 [24:12<08:06,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 600/800 [24:15<08:03,  2.42s/it]                                                 {'loss': 0.3719, 'grad_norm': 0.35585516691207886, 'learning_rate': 0.00011418349124044405, 'epoch': 3.75}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 600/800 [24:15<08:03,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 601/800 [24:17<08:01,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 602/800 [24:19<07:58,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 603/800 [24:22<07:56,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 604/800 [24:24<07:54,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 605/800 [24:27<07:51,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 606/800 [24:29<07:49,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 607/800 [24:32<07:46,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 608/800 [24:34<07:44,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 609/800 [24:36<07:41,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 610/800 [24:39<07:39,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 611/800 [24:41<07:37,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 612/800 [24:44<07:39,  2.44s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 613/800 [24:46<07:35,  2.44s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 614/800 [24:49<07:32,  2.43s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 615/800 [24:51<07:28,  2.43s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 616/800 [24:53<07:26,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 617/800 [24:56<07:23,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 618/800 [24:58<07:20,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 619/800 [25:01<07:18,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 620/800 [25:03<07:15,  2.42s/it]                                                 {'loss': 0.3982, 'grad_norm': 0.36036524176597595, 'learning_rate': 9.42646523604165e-05, 'epoch': 3.88}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 620/800 [25:03<07:15,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 621/800 [25:05<07:13,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 622/800 [25:08<07:10,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 623/800 [25:10<07:08,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 624/800 [25:13<07:05,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 625/800 [25:15<07:03,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 626/800 [25:18<07:01,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 627/800 [25:20<06:58,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 628/800 [25:22<06:56,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 629/800 [25:25<06:53,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 630/800 [25:27<06:51,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 631/800 [25:30<06:48,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 632/800 [25:32<06:46,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 633/800 [25:34<06:43,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 634/800 [25:37<06:41,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 635/800 [25:39<06:38,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 636/800 [25:42<06:36,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 637/800 [25:44<06:34,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 638/800 [25:47<06:31,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 639/800 [25:49<06:30,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 640/800 [25:51<06:27,  2.42s/it]                                                 {'loss': 0.3823, 'grad_norm': 0.3563460409641266, 'learning_rate': 7.584563001175895e-05, 'epoch': 4.0}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 640/800 [25:51<06:27,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 641/800 [25:54<06:25,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 642/800 [25:56<06:22,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 643/800 [25:59<06:19,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 644/800 [26:01<06:17,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 645/800 [26:04<06:14,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 646/800 [26:06<06:12,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 647/800 [26:08<06:10,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 648/800 [26:11<06:07,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 649/800 [26:13<06:05,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 650/800 [26:16<06:02,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 651/800 [26:18<06:00,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 652/800 [26:20<05:58,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 653/800 [26:23<05:55,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 654/800 [26:25<05:54,  2.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 655/800 [26:28<05:51,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 656/800 [26:30<05:48,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 657/800 [26:33<05:46,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 658/800 [26:35<05:43,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 659/800 [26:37<05:41,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 660/800 [26:40<05:38,  2.42s/it]                                                 {'loss': 0.3306, 'grad_norm': 0.2889557182788849, 'learning_rate': 5.910380944855087e-05, 'epoch': 4.12}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 660/800 [26:40<05:38,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 661/800 [26:42<05:36,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 662/800 [26:45<05:34,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 663/800 [26:47<05:31,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 664/800 [26:50<05:29,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 665/800 [26:52<05:26,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 666/800 [26:54<05:24,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 667/800 [26:57<05:22,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 668/800 [26:59<05:20,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 669/800 [27:02<05:17,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 670/800 [27:04<05:14,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 671/800 [27:06<05:12,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 672/800 [27:09<05:09,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 673/800 [27:11<05:07,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 674/800 [27:14<05:04,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 675/800 [27:16<05:02,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 676/800 [27:19<05:00,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 677/800 [27:21<04:57,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 678/800 [27:23<04:55,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 679/800 [27:26<04:52,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 680/800 [27:28<04:50,  2.42s/it]                                                 {'loss': 0.319, 'grad_norm': 0.3253490924835205, 'learning_rate': 4.420042355482601e-05, 'epoch': 4.25}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 680/800 [27:28<04:50,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 681/800 [27:31<04:47,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 682/800 [27:33<04:48,  2.44s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 683/800 [27:36<04:44,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 684/800 [27:38<04:41,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 685/800 [27:40<04:38,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 686/800 [27:43<04:36,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 687/800 [27:45<04:33,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 688/800 [27:48<04:31,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 689/800 [27:50<04:28,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 690/800 [27:52<04:26,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 691/800 [27:55<04:23,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 692/800 [27:57<04:21,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 693/800 [28:00<04:18,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 694/800 [28:02<04:16,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 695/800 [28:05<04:14,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 696/800 [28:07<04:12,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 697/800 [28:09<04:09,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 698/800 [28:12<04:06,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 699/800 [28:14<04:04,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 700/800 [28:17<04:01,  2.42s/it]                                                 {'loss': 0.3355, 'grad_norm': 0.28153544664382935, 'learning_rate': 3.127900008376044e-05, 'epoch': 4.38}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 700/800 [28:17<04:01,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 701/800 [28:19<03:59,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 702/800 [28:22<03:57,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 703/800 [28:24<03:54,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 704/800 [28:26<03:52,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 705/800 [28:29<03:49,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 706/800 [28:31<03:47,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 707/800 [28:34<03:44,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 708/800 [28:36<03:42,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 709/800 [28:38<03:40,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 710/800 [28:41<03:37,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 711/800 [28:43<03:35,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 712/800 [28:46<03:32,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 713/800 [28:48<03:30,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 714/800 [28:51<03:27,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 715/800 [28:53<03:25,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 716/800 [28:55<03:23,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 717/800 [28:58<03:20,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 718/800 [29:00<03:18,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 719/800 [29:03<03:15,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 720/800 [29:05<03:13,  2.42s/it]                                                 {'loss': 0.3498, 'grad_norm': 0.3372880816459656, 'learning_rate': 2.0463979406949023e-05, 'epoch': 4.5}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 720/800 [29:05<03:13,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 721/800 [29:08<03:11,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 722/800 [29:10<03:08,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 723/800 [29:12<03:06,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 724/800 [29:15<03:04,  2.43s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 725/800 [29:17<03:01,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 726/800 [29:20<02:59,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 727/800 [29:22<02:56,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 728/800 [29:24<02:54,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 729/800 [29:27<02:51,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 730/800 [29:29<02:49,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 731/800 [29:32<02:46,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 732/800 [29:34<02:44,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 733/800 [29:37<02:42,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 734/800 [29:39<02:39,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 735/800 [29:41<02:37,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 736/800 [29:44<02:34,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 737/800 [29:46<02:32,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 738/800 [29:49<02:29,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 739/800 [29:51<02:27,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 740/800 [29:53<02:25,  2.42s/it]                                                 {'loss': 0.3219, 'grad_norm': 0.2536163032054901, 'learning_rate': 1.185951608560118e-05, 'epoch': 4.62}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 740/800 [29:53<02:25,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 741/800 [29:56<02:22,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 742/800 [29:58<02:20,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 743/800 [30:01<02:17,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 744/800 [30:03<02:15,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 745/800 [30:06<02:13,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 746/800 [30:08<02:10,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 747/800 [30:10<02:08,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 748/800 [30:13<02:05,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 749/800 [30:15<02:03,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 750/800 [30:18<02:00,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 751/800 [30:20<01:59,  2.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 752/800 [30:23<01:56,  2.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 753/800 [30:25<01:54,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 754/800 [30:27<01:51,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 755/800 [30:30<01:49,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 756/800 [30:32<01:46,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 757/800 [30:35<01:44,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 758/800 [30:37<01:41,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 759/800 [30:40<01:39,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 760/800 [30:42<01:36,  2.42s/it]                                                 {'loss': 0.351, 'grad_norm': 0.2972838580608368, 'learning_rate': 5.548475805179587e-06, 'epoch': 4.75}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 760/800 [30:42<01:36,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 761/800 [30:44<01:34,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 762/800 [30:47<01:31,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 763/800 [30:49<01:29,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 764/800 [30:52<01:27,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 765/800 [30:54<01:24,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 766/800 [30:56<01:22,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 767/800 [30:59<01:19,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 768/800 [31:01<01:17,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 769/800 [31:04<01:15,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 770/800 [31:06<01:12,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 771/800 [31:09<01:10,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 772/800 [31:11<01:07,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 773/800 [31:13<01:05,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 774/800 [31:16<01:02,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 775/800 [31:18<01:00,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 776/800 [31:21<00:58,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 777/800 [31:23<00:55,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 778/800 [31:26<00:53,  2.43s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 779/800 [31:28<00:50,  2.43s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 780/800 [31:30<00:48,  2.42s/it]                                                 {'loss': 0.345, 'grad_norm': 0.3085359036922455, 'learning_rate': 1.5916373335503054e-06, 'epoch': 4.88}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 780/800 [31:30<00:48,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 781/800 [31:33<00:46,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 782/800 [31:35<00:43,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 783/800 [31:38<00:41,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 784/800 [31:40<00:38,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 785/800 [31:42<00:36,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 786/800 [31:45<00:33,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 787/800 [31:47<00:31,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 788/800 [31:50<00:29,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 789/800 [31:52<00:26,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 790/800 [31:55<00:24,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 791/800 [31:57<00:21,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 792/800 [31:59<00:19,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 793/800 [32:02<00:16,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 794/800 [32:04<00:14,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 795/800 [32:07<00:12,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 796/800 [32:09<00:09,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 797/800 [32:12<00:07,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 798/800 [32:14<00:04,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 799/800 [32:16<00:02,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:19<00:00,  2.42s/it]                                                 {'loss': 0.3376, 'grad_norm': 0.22933241724967957, 'learning_rate': 2.7107188222991187e-08, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:19<00:00,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 05:13:41,012 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_topic/checkpoint-800
[INFO|configuration_utils.py:726] 2024-05-25 05:13:42,084 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:13:42,089 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 05:13:42,990 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:13:42,996 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 05:13:43,048 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 05:13:43,049 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/checkpoint-800/special_tokens_map.json
[INFO|trainer.py:2231] 2024-05-25 05:13:43,186 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 1953.0212, 'train_samples_per_second': 3.274, 'train_steps_per_second': 0.41, 'train_loss': 0.4691386204957962, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:21<00:00,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [32:21<00:00,  2.43s/it]
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.4691
  train_runtime            = 0:32:33.02
  train_samples_per_second =      3.274
  train_steps_per_second   =       0.41
[INFO|trainer.py:3203] 2024-05-25 05:13:43,192 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_topic
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-05-25 05:13:45,242 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:13:45,244 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 05:13:45,775 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:13:45,777 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 05:13:45,839 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 05:13:45,840 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/special_tokens_map.json
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:471] 2024-05-25 05:13:46,650 >> Configuration saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/final_merged_model/config.json
[INFO|configuration_utils.py:697] 2024-05-25 05:13:46,651 >> Configuration saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/final_merged_model/generation_config.json
[INFO|modeling_utils.py:2474] 2024-05-25 05:13:52,589 >> Model weights saved in /scratch/tathagato/adapter_experiments/extractiveness_then_topic/final_merged_model/model.safetensors
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.029 MB uploadedwandb: \ 0.006 MB of 0.032 MB uploadedwandb: | 0.032 MB of 0.032 MB uploadedwandb: / 0.032 MB of 0.032 MB uploadedwandb: - 0.032 MB of 0.032 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ
wandb: train/learning_rate ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 8.17116991193088e+16
wandb:              train/epoch 5.0
wandb:        train/global_step 800
wandb:          train/grad_norm 0.22933
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.3376
wandb:               train_loss 0.46914
wandb:            train_runtime 1953.0212
wandb: train_samples_per_second 3.274
wandb:   train_steps_per_second 0.41
wandb: 
wandb: üöÄ View run dark-grass-100 at: https://wandb.ai/ihub-drug-discovery/huggingface/runs/uczqljuo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ihub-drug-discovery/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240525_044113-uczqljuo/logs
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-05-25 05:14:28 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 05:14:28 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 05:14:28 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0005,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/tathagato/adapter_experiments/extractiveness_then_length/runs/May25_05-14-28_gnode081,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=20,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/tathagato/adapter_experiments/extractiveness_then_length,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/tathagato/adapter_experiments/extractiveness_then_length,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=400,
save_strategy=steps,
save_total_limit=400,
seed=0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
2024-05-25 05:14:28 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'q_proj', 'k_proj', 'o_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
2024-05-25 05:14:28 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 05:14:28 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1 distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:726] 2024-05-25 05:14:28,607 >> loading configuration file config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:14:28,612 >> Model config LlamaConfig {
  "_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": false,
  "vocab_size": 32000
}

[INFO|quantizer_bnb_4bit.py:247] 2024-05-25 05:14:28,717 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[WARNING|modeling_utils.py:3058] 2024-05-25 05:14:28,717 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:3283] 2024-05-25 05:14:28,718 >> loading weights file model.safetensors from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors
[INFO|modeling_utils.py:1417] 2024-05-25 05:14:28,735 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:928] 2024-05-25 05:14:28,737 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[WARNING|modeling_utils.py:3058] 2024-05-25 05:14:29,123 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 05:14:29,168 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 05:14:29,372 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:4024] 2024-05-25 05:14:31,564 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-05-25 05:14:31,565 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-05-25 05:14:31,808 >> loading configuration file generation_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json
[INFO|configuration_utils.py:928] 2024-05-25 05:14:31,808 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

[INFO|tokenization_utils_base.py:2084] 2024-05-25 05:14:32,253 >> loading file tokenizer.model from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-05-25 05:14:32,253 >> loading file tokenizer.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 05:14:32,253 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-05-25 05:14:32,253 >> loading file special_tokens_map.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 05:14:32,253 >> loading file tokenizer_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
loading model from : /scratch/tathagato/adapter_experiments/extractiveness/extractiveness
train dataset size 4278
test dataset size 554
4278
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
Spawning 10 processes
2024-05-25 05:14:34 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:11:59,  1.01s/ examples]/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
train dataset size 4278
test dataset size 554
4278
Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 429/4278 [00:01<00:10, 383.57 examples/s]trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:05, 635.10 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:02<00:03, 885.99 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]train dataset size 4278
test dataset size 554
4278
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:02, 967.88 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:02<00:01, 1334.19 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2556/4278 [00:02<00:01, 1204.23 examples/s]train dataset size 4278
test dataset size 554
4278
Applying chat template to train_sft (num_proc=10):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2785/4278 [00:03<00:01, 1187.00 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:15:26,  1.06s/ examples]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:03<00:01, 1258.98 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:08, 469.85 examples/s]Applying chat template to train_sft (num_proc=10):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3260/4278 [00:03<00:01, 1012.89 examples/s]Applying chat template to train_sft (num_proc=10):  15%|‚ñà‚ñå        | 644/4278 [00:01<00:06, 519.82 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:20:12,  1.13s/ examples]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:06, 555.59 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:01, 808.65 examples/s] Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:02<00:03, 990.10 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1150.53 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 429/4278 [00:01<00:10, 361.68 examples/s]Applying chat template to train_sft (num_proc=10):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4067/4278 [00:04<00:00, 1094.64 examples/s]Applying chat template to train_sft (num_proc=10):  36%|‚ñà‚ñà‚ñà‚ñã      | 1554/4278 [00:02<00:03, 868.02 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:05, 651.48 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:01<00:02, 1052.77 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 795.35 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:04<00:00, 889.98 examples/s] 
Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2123/4278 [00:02<00:01, 1206.70 examples/s]Concatenating 10 shards
2024-05-25 05:14:39 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:26:50,  1.22s/ examples]Applying chat template to train_sft (num_proc=10):  35%|‚ñà‚ñà‚ñà‚ñå      | 1509/4278 [00:02<00:03, 896.39 examples/s] Applying chat template to train_sft (num_proc=10):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2384/4278 [00:03<00:01, 1019.06 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 795.93 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 429/4278 [00:01<00:11, 339.35 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:02<00:01, 1216.61 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 856/4278 [00:01<00:04, 722.96 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:03<00:02, 756.24 examples/s] Spawning 10 processes
2024-05-25 05:14:40 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2397/4278 [00:03<00:01, 1081.70 examples/s]Applying chat template to train_sft (num_proc=10):  26%|‚ñà‚ñà‚ñå       | 1119/4278 [00:02<00:04, 762.35 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:04<00:01, 867.59 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<04:41,  1.97 examples/s]Applying chat template to train_sft (num_proc=10):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2793/4278 [00:03<00:01, 980.66 examples/s] Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:02<00:04, 607.48 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:04, 120.85 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:00, 1018.36 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 210.28 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1323.34 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:03<00:01, 905.06 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:00, 350.68 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/4278 [00:03<00:00, 1283.48 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 762.02 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 375.08 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:03<00:01, 1116.75 examples/s]Applying chat template to train_sft (num_proc=10):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4076/4278 [00:04<00:00, 1064.66 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 390/554 [00:01<00:00, 444.29 examples/s]Applying chat template to train_sft (num_proc=10):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3646/4278 [00:04<00:00, 1107.73 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 500/554 [00:01<00:00, 553.05 examples/s]Applying chat template to train_sft (num_proc=10):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2365/4278 [00:03<00:01, 979.25 examples/s] Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 823.13 examples/s] 
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 349.40 examples/s]
Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3852/4278 [00:04<00:00, 932.86 examples/s] Concatenating 10 shards
2024-05-25 05:14:42 - INFO - datasets.arrow_dataset - Concatenating 10 shards
tokenizer padding side left
Applying chat template to train_sft (num_proc=10):  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 4225/4278 [00:04<00:00, 1285.77 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:03<00:02, 819.95 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:04<00:00, 861.47 examples/s] 
Using custom data configuration default-8a159e0651bd4009
2024-05-25 05:14:42 - INFO - datasets.builder - Using custom data configuration default-8a159e0651bd4009
Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
2024-05-25 05:14:42 - INFO - datasets.info - Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
Overwrite dataset info from restored data version if exists.
2024-05-25 05:14:42 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
2024-05-25 05:14:42 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0)
2024-05-25 05:14:42 - INFO - datasets.builder - Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0)
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
2024-05-25 05:14:42 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:04<00:01, 838.88 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:00, 1091.49 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1427.81 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 4266/4278 [00:04<00:00, 1258.58 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:27,  1.69 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:04, 102.42 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 194.02 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 806.95 examples/s] 
Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<04:41,  1.96 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:04, 121.13 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:01<00:01, 282.24 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:01, 222.59 examples/s]Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 335/554 [00:01<00:00, 390.71 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:00, 359.07 examples/s]Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 445/554 [00:01<00:00, 441.25 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 395.47 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 557.29 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 390/554 [00:01<00:00, 497.03 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 311.96 examples/s]
Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 633.89 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 340.17 examples/s]
tokenizer padding side left
Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<04:26,  2.07 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 208.70 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:00, 348.94 examples/s]Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 334/554 [00:00<00:00, 489.27 examples/s]Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 444/554 [00:01<00:00, 552.59 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 556.39 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 364.67 examples/s]
tokenizer padding side left
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
2024-05-25 05:14:46 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
[INFO|trainer.py:607] 2024-05-25 05:14:48,296 >> Using auto half precision backend
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:1969] 2024-05-25 05:14:49,019 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-05-25 05:14:49,019 >>   Num examples = 2,459
[INFO|trainer.py:1971] 2024-05-25 05:14:49,019 >>   Num Epochs = 5
[INFO|trainer.py:1972] 2024-05-25 05:14:49,019 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-05-25 05:14:49,019 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-05-25 05:14:49,019 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-05-25 05:14:49,019 >>   Total optimization steps = 1,535
[INFO|trainer.py:1978] 2024-05-25 05:14:49,021 >>   Number of trainable parameters = 4,505,600
[INFO|integration_utils.py:723] 2024-05-25 05:14:49,082 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: roy3 (ihub-drug-discovery). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home2/tathagato/summarization/MACSum/experiments/wandb/run-20240525_051452-3zrk9vyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-haze-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ihub-drug-discovery/huggingface
wandb: üöÄ View run at https://wandb.ai/ihub-drug-discovery/huggingface/runs/3zrk9vyz
  0%|          | 0/1535 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1535 [00:02<1:02:28,  2.44s/it]  0%|          | 2/1535 [00:04<1:01:47,  2.42s/it]  0%|          | 3/1535 [00:07<1:01:36,  2.41s/it]  0%|          | 4/1535 [00:09<1:01:26,  2.41s/it]  0%|          | 5/1535 [00:12<1:01:21,  2.41s/it]  0%|          | 6/1535 [00:14<1:01:18,  2.41s/it]  0%|          | 7/1535 [00:16<1:01:15,  2.41s/it]  1%|          | 8/1535 [00:19<1:01:13,  2.41s/it]  1%|          | 9/1535 [00:21<1:01:11,  2.41s/it]  1%|          | 10/1535 [00:24<1:01:09,  2.41s/it]  1%|          | 11/1535 [00:26<1:01:07,  2.41s/it]  1%|          | 12/1535 [00:29<1:01:54,  2.44s/it]  1%|          | 13/1535 [00:31<1:01:56,  2.44s/it]  1%|          | 14/1535 [00:33<1:01:39,  2.43s/it]  1%|          | 15/1535 [00:36<1:01:26,  2.43s/it]  1%|          | 16/1535 [00:38<1:01:18,  2.42s/it]  1%|          | 17/1535 [00:41<1:01:10,  2.42s/it]  1%|          | 18/1535 [00:43<1:01:05,  2.42s/it]  1%|          | 19/1535 [00:45<1:01:00,  2.41s/it]  1%|‚ñè         | 20/1535 [00:48<1:00:58,  2.41s/it]                                                   {'loss': 0.7191, 'grad_norm': 0.5477022528648376, 'learning_rate': 3.2573289902280134e-05, 'epoch': 0.07}
  1%|‚ñè         | 20/1535 [00:48<1:00:58,  2.41s/it]  1%|‚ñè         | 21/1535 [00:50<1:00:56,  2.42s/it]  1%|‚ñè         | 22/1535 [00:53<1:00:53,  2.41s/it]  1%|‚ñè         | 23/1535 [00:55<1:00:53,  2.42s/it]  2%|‚ñè         | 24/1535 [00:58<1:00:52,  2.42s/it]  2%|‚ñè         | 25/1535 [01:00<1:00:49,  2.42s/it]  2%|‚ñè         | 26/1535 [01:02<1:01:05,  2.43s/it]  2%|‚ñè         | 27/1535 [01:05<1:00:58,  2.43s/it]  2%|‚ñè         | 28/1535 [01:07<1:00:53,  2.42s/it]  2%|‚ñè         | 29/1535 [01:10<1:01:06,  2.43s/it]  2%|‚ñè         | 30/1535 [01:12<1:00:55,  2.43s/it]  2%|‚ñè         | 31/1535 [01:15<1:00:49,  2.43s/it]  2%|‚ñè         | 32/1535 [01:17<1:00:44,  2.42s/it]  2%|‚ñè         | 33/1535 [01:19<1:00:39,  2.42s/it]  2%|‚ñè         | 34/1535 [01:22<1:00:34,  2.42s/it]  2%|‚ñè         | 35/1535 [01:24<1:00:31,  2.42s/it]  2%|‚ñè         | 36/1535 [01:27<1:00:28,  2.42s/it]  2%|‚ñè         | 37/1535 [01:29<1:00:23,  2.42s/it]  2%|‚ñè         | 38/1535 [01:31<1:00:21,  2.42s/it]  3%|‚ñé         | 39/1535 [01:34<1:00:38,  2.43s/it]  3%|‚ñé         | 40/1535 [01:36<1:00:29,  2.43s/it]                                                   {'loss': 0.6601, 'grad_norm': 0.38682258129119873, 'learning_rate': 6.514657980456027e-05, 'epoch': 0.13}
  3%|‚ñé         | 40/1535 [01:36<1:00:29,  2.43s/it]  3%|‚ñé         | 41/1535 [01:39<1:00:23,  2.43s/it]  3%|‚ñé         | 42/1535 [01:41<1:00:35,  2.44s/it]  3%|‚ñé         | 43/1535 [01:44<1:00:26,  2.43s/it]  3%|‚ñé         | 44/1535 [01:46<1:00:18,  2.43s/it]  3%|‚ñé         | 45/1535 [01:48<1:00:12,  2.42s/it]  3%|‚ñé         | 46/1535 [01:51<1:00:08,  2.42s/it]  3%|‚ñé         | 47/1535 [01:53<1:00:04,  2.42s/it]  3%|‚ñé         | 48/1535 [01:56<1:00:00,  2.42s/it]  3%|‚ñé         | 49/1535 [01:58<59:56,  2.42s/it]    3%|‚ñé         | 50/1535 [02:01<59:54,  2.42s/it]  3%|‚ñé         | 51/1535 [02:03<59:51,  2.42s/it]  3%|‚ñé         | 52/1535 [02:05<59:47,  2.42s/it]  3%|‚ñé         | 53/1535 [02:08<59:46,  2.42s/it]  4%|‚ñé         | 54/1535 [02:10<1:00:02,  2.43s/it]  4%|‚ñé         | 55/1535 [02:13<59:53,  2.43s/it]    4%|‚ñé         | 56/1535 [02:15<1:00:23,  2.45s/it]  4%|‚ñé         | 57/1535 [02:18<1:00:07,  2.44s/it]  4%|‚ñç         | 58/1535 [02:20<59:55,  2.43s/it]    4%|‚ñç         | 59/1535 [02:22<59:46,  2.43s/it]  4%|‚ñç         | 60/1535 [02:25<59:39,  2.43s/it]                                                 {'loss': 0.6541, 'grad_norm': 0.4414440989494324, 'learning_rate': 9.771986970684039e-05, 'epoch': 0.2}
  4%|‚ñç         | 60/1535 [02:25<59:39,  2.43s/it]  4%|‚ñç         | 61/1535 [02:27<59:34,  2.43s/it]  4%|‚ñç         | 62/1535 [02:30<59:29,  2.42s/it]  4%|‚ñç         | 63/1535 [02:32<59:25,  2.42s/it]  4%|‚ñç         | 64/1535 [02:35<59:21,  2.42s/it]  4%|‚ñç         | 65/1535 [02:37<59:18,  2.42s/it]  4%|‚ñç         | 66/1535 [02:39<59:15,  2.42s/it]  4%|‚ñç         | 67/1535 [02:42<59:12,  2.42s/it]  4%|‚ñç         | 68/1535 [02:44<59:20,  2.43s/it]  4%|‚ñç         | 69/1535 [02:47<59:15,  2.43s/it]  5%|‚ñç         | 70/1535 [02:49<59:25,  2.43s/it]  5%|‚ñç         | 71/1535 [02:52<59:16,  2.43s/it]  5%|‚ñç         | 72/1535 [02:54<59:10,  2.43s/it]  5%|‚ñç         | 73/1535 [02:56<59:05,  2.42s/it]  5%|‚ñç         | 74/1535 [02:59<59:00,  2.42s/it]  5%|‚ñç         | 75/1535 [03:01<58:56,  2.42s/it]  5%|‚ñç         | 76/1535 [03:04<58:53,  2.42s/it]  5%|‚ñå         | 77/1535 [03:06<58:49,  2.42s/it]  5%|‚ñå         | 78/1535 [03:08<58:46,  2.42s/it]  5%|‚ñå         | 79/1535 [03:11<58:43,  2.42s/it]  5%|‚ñå         | 80/1535 [03:13<58:40,  2.42s/it]                                                 {'loss': 0.6705, 'grad_norm': 0.4689149856567383, 'learning_rate': 0.00013029315960912054, 'epoch': 0.26}
  5%|‚ñå         | 80/1535 [03:13<58:40,  2.42s/it]  5%|‚ñå         | 81/1535 [03:16<58:38,  2.42s/it]  5%|‚ñå         | 82/1535 [03:18<58:36,  2.42s/it]  5%|‚ñå         | 83/1535 [03:21<58:50,  2.43s/it]  5%|‚ñå         | 84/1535 [03:23<58:43,  2.43s/it]  6%|‚ñå         | 85/1535 [03:25<58:36,  2.43s/it]  6%|‚ñå         | 86/1535 [03:28<58:31,  2.42s/it]  6%|‚ñå         | 87/1535 [03:30<58:27,  2.42s/it]  6%|‚ñå         | 88/1535 [03:33<58:24,  2.42s/it]  6%|‚ñå         | 89/1535 [03:35<58:20,  2.42s/it]  6%|‚ñå         | 90/1535 [03:38<58:17,  2.42s/it]  6%|‚ñå         | 91/1535 [03:40<58:14,  2.42s/it]  6%|‚ñå         | 92/1535 [03:42<58:11,  2.42s/it]  6%|‚ñå         | 93/1535 [03:45<58:09,  2.42s/it]  6%|‚ñå         | 94/1535 [03:47<58:07,  2.42s/it]  6%|‚ñå         | 95/1535 [03:50<58:04,  2.42s/it]  6%|‚ñã         | 96/1535 [03:52<58:01,  2.42s/it]  6%|‚ñã         | 97/1535 [03:55<58:16,  2.43s/it]  6%|‚ñã         | 98/1535 [03:57<58:27,  2.44s/it]  6%|‚ñã         | 99/1535 [03:59<58:16,  2.43s/it]  7%|‚ñã         | 100/1535 [04:02<58:07,  2.43s/it]                                                  {'loss': 0.6716, 'grad_norm': 0.43029412627220154, 'learning_rate': 0.00016286644951140063, 'epoch': 0.33}
  7%|‚ñã         | 100/1535 [04:02<58:07,  2.43s/it]  7%|‚ñã         | 101/1535 [04:04<58:02,  2.43s/it]  7%|‚ñã         | 102/1535 [04:07<57:55,  2.43s/it]  7%|‚ñã         | 103/1535 [04:09<57:50,  2.42s/it]  7%|‚ñã         | 104/1535 [04:12<57:46,  2.42s/it]  7%|‚ñã         | 105/1535 [04:14<57:43,  2.42s/it]  7%|‚ñã         | 106/1535 [04:16<57:42,  2.42s/it]  7%|‚ñã         | 107/1535 [04:19<57:39,  2.42s/it]  7%|‚ñã         | 108/1535 [04:21<57:35,  2.42s/it]  7%|‚ñã         | 109/1535 [04:24<57:32,  2.42s/it]  7%|‚ñã         | 110/1535 [04:26<57:28,  2.42s/it]  7%|‚ñã         | 111/1535 [04:29<57:47,  2.44s/it]  7%|‚ñã         | 112/1535 [04:31<57:53,  2.44s/it]  7%|‚ñã         | 113/1535 [04:33<57:41,  2.43s/it]  7%|‚ñã         | 114/1535 [04:36<57:32,  2.43s/it]  7%|‚ñã         | 115/1535 [04:38<57:25,  2.43s/it]  8%|‚ñä         | 116/1535 [04:41<57:19,  2.42s/it]  8%|‚ñä         | 117/1535 [04:43<57:15,  2.42s/it]  8%|‚ñä         | 118/1535 [04:45<57:11,  2.42s/it]  8%|‚ñä         | 119/1535 [04:48<57:07,  2.42s/it]  8%|‚ñä         | 120/1535 [04:50<57:04,  2.42s/it]                                                  {'loss': 0.6508, 'grad_norm': 0.395972341299057, 'learning_rate': 0.00019543973941368078, 'epoch': 0.39}
  8%|‚ñä         | 120/1535 [04:50<57:04,  2.42s/it]  8%|‚ñä         | 121/1535 [04:53<57:02,  2.42s/it]  8%|‚ñä         | 122/1535 [04:55<56:58,  2.42s/it]  8%|‚ñä         | 123/1535 [04:58<56:56,  2.42s/it]  8%|‚ñä         | 124/1535 [05:00<56:53,  2.42s/it]  8%|‚ñä         | 125/1535 [05:02<56:51,  2.42s/it]  8%|‚ñä         | 126/1535 [05:05<57:24,  2.44s/it]  8%|‚ñä         | 127/1535 [05:07<57:10,  2.44s/it]  8%|‚ñä         | 128/1535 [05:10<57:00,  2.43s/it]  8%|‚ñä         | 129/1535 [05:12<56:53,  2.43s/it]  8%|‚ñä         | 130/1535 [05:15<56:46,  2.42s/it]  9%|‚ñä         | 131/1535 [05:17<56:42,  2.42s/it]  9%|‚ñä         | 132/1535 [05:19<56:38,  2.42s/it]  9%|‚ñä         | 133/1535 [05:22<56:34,  2.42s/it]  9%|‚ñä         | 134/1535 [05:24<56:30,  2.42s/it]  9%|‚ñâ         | 135/1535 [05:27<56:27,  2.42s/it]  9%|‚ñâ         | 136/1535 [05:29<56:24,  2.42s/it]  9%|‚ñâ         | 137/1535 [05:32<56:22,  2.42s/it]  9%|‚ñâ         | 138/1535 [05:34<56:19,  2.42s/it]  9%|‚ñâ         | 139/1535 [05:36<56:32,  2.43s/it]  9%|‚ñâ         | 140/1535 [05:39<56:25,  2.43s/it]                                                  {'loss': 0.6265, 'grad_norm': 0.3994178771972656, 'learning_rate': 0.0002280130293159609, 'epoch': 0.46}
  9%|‚ñâ         | 140/1535 [05:39<56:25,  2.43s/it]  9%|‚ñâ         | 141/1535 [05:41<56:29,  2.43s/it]  9%|‚ñâ         | 142/1535 [05:44<56:21,  2.43s/it]  9%|‚ñâ         | 143/1535 [05:46<56:16,  2.43s/it]  9%|‚ñâ         | 144/1535 [05:49<56:11,  2.42s/it]  9%|‚ñâ         | 145/1535 [05:51<56:07,  2.42s/it] 10%|‚ñâ         | 146/1535 [05:53<56:03,  2.42s/it] 10%|‚ñâ         | 147/1535 [05:56<55:59,  2.42s/it] 10%|‚ñâ         | 148/1535 [05:58<55:56,  2.42s/it] 10%|‚ñâ         | 149/1535 [06:01<55:53,  2.42s/it] 10%|‚ñâ         | 150/1535 [06:03<55:50,  2.42s/it] 10%|‚ñâ         | 151/1535 [06:05<55:47,  2.42s/it] 10%|‚ñâ         | 152/1535 [06:08<55:55,  2.43s/it] 10%|‚ñâ         | 153/1535 [06:10<55:50,  2.42s/it] 10%|‚ñà         | 154/1535 [06:13<55:46,  2.42s/it] 10%|‚ñà         | 155/1535 [06:15<55:44,  2.42s/it] 10%|‚ñà         | 156/1535 [06:18<55:41,  2.42s/it] 10%|‚ñà         | 157/1535 [06:20<55:37,  2.42s/it] 10%|‚ñà         | 158/1535 [06:22<55:35,  2.42s/it] 10%|‚ñà         | 159/1535 [06:25<55:32,  2.42s/it] 10%|‚ñà         | 160/1535 [06:27<55:29,  2.42s/it]                                                  {'loss': 0.611, 'grad_norm': 0.3212507665157318, 'learning_rate': 0.0002605863192182411, 'epoch': 0.52}
 10%|‚ñà         | 160/1535 [06:27<55:29,  2.42s/it] 10%|‚ñà         | 161/1535 [06:30<55:28,  2.42s/it] 11%|‚ñà         | 162/1535 [06:32<55:26,  2.42s/it] 11%|‚ñà         | 163/1535 [06:35<55:24,  2.42s/it] 11%|‚ñà         | 164/1535 [06:37<55:20,  2.42s/it] 11%|‚ñà         | 165/1535 [06:39<55:17,  2.42s/it] 11%|‚ñà         | 166/1535 [06:42<55:15,  2.42s/it] 11%|‚ñà         | 167/1535 [06:44<55:12,  2.42s/it] 11%|‚ñà         | 168/1535 [06:47<55:19,  2.43s/it] 11%|‚ñà         | 169/1535 [06:49<55:15,  2.43s/it] 11%|‚ñà         | 170/1535 [06:52<55:19,  2.43s/it] 11%|‚ñà         | 171/1535 [06:54<55:13,  2.43s/it] 11%|‚ñà         | 172/1535 [06:56<55:08,  2.43s/it] 11%|‚ñà‚ñè        | 173/1535 [06:59<55:02,  2.42s/it] 11%|‚ñà‚ñè        | 174/1535 [07:01<54:59,  2.42s/it] 11%|‚ñà‚ñè        | 175/1535 [07:04<54:56,  2.42s/it] 11%|‚ñà‚ñè        | 176/1535 [07:06<54:53,  2.42s/it] 12%|‚ñà‚ñè        | 177/1535 [07:08<54:50,  2.42s/it] 12%|‚ñà‚ñè        | 178/1535 [07:11<54:47,  2.42s/it] 12%|‚ñà‚ñè        | 179/1535 [07:13<54:45,  2.42s/it] 12%|‚ñà‚ñè        | 180/1535 [07:16<54:42,  2.42s/it]                                                  {'loss': 0.6118, 'grad_norm': 0.29577863216400146, 'learning_rate': 0.0002915309446254072, 'epoch': 0.59}
 12%|‚ñà‚ñè        | 180/1535 [07:16<54:42,  2.42s/it] 12%|‚ñà‚ñè        | 181/1535 [07:18<54:55,  2.43s/it] 12%|‚ñà‚ñè        | 182/1535 [07:21<54:48,  2.43s/it] 12%|‚ñà‚ñè        | 183/1535 [07:23<54:42,  2.43s/it] 12%|‚ñà‚ñè        | 184/1535 [07:26<54:46,  2.43s/it] 12%|‚ñà‚ñè        | 185/1535 [07:28<54:39,  2.43s/it] 12%|‚ñà‚ñè        | 186/1535 [07:30<54:34,  2.43s/it] 12%|‚ñà‚ñè        | 187/1535 [07:33<54:29,  2.43s/it] 12%|‚ñà‚ñè        | 188/1535 [07:35<54:25,  2.42s/it] 12%|‚ñà‚ñè        | 189/1535 [07:38<54:22,  2.42s/it] 12%|‚ñà‚ñè        | 190/1535 [07:40<54:19,  2.42s/it] 12%|‚ñà‚ñè        | 191/1535 [07:42<54:16,  2.42s/it] 13%|‚ñà‚ñé        | 192/1535 [07:45<54:13,  2.42s/it] 13%|‚ñà‚ñé        | 193/1535 [07:47<54:10,  2.42s/it] 13%|‚ñà‚ñé        | 194/1535 [07:50<54:07,  2.42s/it] 13%|‚ñà‚ñé        | 195/1535 [07:52<54:22,  2.43s/it] 13%|‚ñà‚ñé        | 196/1535 [07:55<54:15,  2.43s/it] 13%|‚ñà‚ñé        | 197/1535 [07:57<54:09,  2.43s/it] 13%|‚ñà‚ñé        | 198/1535 [07:59<54:04,  2.43s/it] 13%|‚ñà‚ñé        | 199/1535 [08:02<54:08,  2.43s/it] 13%|‚ñà‚ñé        | 200/1535 [08:04<54:02,  2.43s/it]                                                  {'loss': 0.6168, 'grad_norm': 0.3810480535030365, 'learning_rate': 0.0003241042345276873, 'epoch': 0.65}
 13%|‚ñà‚ñé        | 200/1535 [08:04<54:02,  2.43s/it] 13%|‚ñà‚ñé        | 201/1535 [08:07<53:58,  2.43s/it] 13%|‚ñà‚ñé        | 202/1535 [08:09<53:53,  2.43s/it] 13%|‚ñà‚ñé        | 203/1535 [08:12<53:50,  2.43s/it] 13%|‚ñà‚ñé        | 204/1535 [08:14<53:46,  2.42s/it] 13%|‚ñà‚ñé        | 205/1535 [08:16<53:43,  2.42s/it] 13%|‚ñà‚ñé        | 206/1535 [08:19<53:40,  2.42s/it] 13%|‚ñà‚ñé        | 207/1535 [08:21<53:37,  2.42s/it] 14%|‚ñà‚ñé        | 208/1535 [08:24<53:35,  2.42s/it] 14%|‚ñà‚ñé        | 209/1535 [08:26<53:42,  2.43s/it] 14%|‚ñà‚ñé        | 210/1535 [08:29<53:36,  2.43s/it] 14%|‚ñà‚ñé        | 211/1535 [08:31<53:32,  2.43s/it] 14%|‚ñà‚ñç        | 212/1535 [08:33<53:28,  2.42s/it] 14%|‚ñà‚ñç        | 213/1535 [08:36<53:32,  2.43s/it] 14%|‚ñà‚ñç        | 214/1535 [08:38<53:26,  2.43s/it] 14%|‚ñà‚ñç        | 215/1535 [08:41<53:21,  2.43s/it] 14%|‚ñà‚ñç        | 216/1535 [08:43<53:17,  2.42s/it] 14%|‚ñà‚ñç        | 217/1535 [08:46<53:14,  2.42s/it] 14%|‚ñà‚ñç        | 218/1535 [08:48<53:11,  2.42s/it] 14%|‚ñà‚ñç        | 219/1535 [08:50<53:08,  2.42s/it] 14%|‚ñà‚ñç        | 220/1535 [08:53<53:05,  2.42s/it]                                                  {'loss': 0.5755, 'grad_norm': 0.35255399346351624, 'learning_rate': 0.0003566775244299674, 'epoch': 0.72}
 14%|‚ñà‚ñç        | 220/1535 [08:53<53:05,  2.42s/it] 14%|‚ñà‚ñç        | 221/1535 [08:55<53:03,  2.42s/it] 14%|‚ñà‚ñç        | 222/1535 [08:58<53:09,  2.43s/it] 15%|‚ñà‚ñç        | 223/1535 [09:00<53:04,  2.43s/it] 15%|‚ñà‚ñç        | 224/1535 [09:03<52:59,  2.43s/it] 15%|‚ñà‚ñç        | 225/1535 [09:05<52:55,  2.42s/it] 15%|‚ñà‚ñç        | 226/1535 [09:07<52:52,  2.42s/it] 15%|‚ñà‚ñç        | 227/1535 [09:10<52:50,  2.42s/it] 15%|‚ñà‚ñç        | 228/1535 [09:12<53:02,  2.43s/it] 15%|‚ñà‚ñç        | 229/1535 [09:15<52:54,  2.43s/it] 15%|‚ñà‚ñç        | 230/1535 [09:17<52:49,  2.43s/it] 15%|‚ñà‚ñå        | 231/1535 [09:20<52:43,  2.43s/it] 15%|‚ñà‚ñå        | 232/1535 [09:22<52:39,  2.42s/it] 15%|‚ñà‚ñå        | 233/1535 [09:24<52:35,  2.42s/it] 15%|‚ñà‚ñå        | 234/1535 [09:27<52:32,  2.42s/it] 15%|‚ñà‚ñå        | 235/1535 [09:29<52:29,  2.42s/it] 15%|‚ñà‚ñå        | 236/1535 [09:32<52:26,  2.42s/it] 15%|‚ñà‚ñå        | 237/1535 [09:34<52:29,  2.43s/it] 16%|‚ñà‚ñå        | 238/1535 [09:36<52:25,  2.43s/it] 16%|‚ñà‚ñå        | 239/1535 [09:39<52:21,  2.42s/it] 16%|‚ñà‚ñå        | 240/1535 [09:41<52:18,  2.42s/it]                                                  {'loss': 0.5786, 'grad_norm': 0.32808059453964233, 'learning_rate': 0.0003892508143322476, 'epoch': 0.78}
 16%|‚ñà‚ñå        | 240/1535 [09:41<52:18,  2.42s/it] 16%|‚ñà‚ñå        | 241/1535 [09:44<52:16,  2.42s/it] 16%|‚ñà‚ñå        | 242/1535 [09:46<52:21,  2.43s/it] 16%|‚ñà‚ñå        | 243/1535 [09:49<52:15,  2.43s/it] 16%|‚ñà‚ñå        | 244/1535 [09:51<52:11,  2.43s/it] 16%|‚ñà‚ñå        | 245/1535 [09:53<52:07,  2.42s/it] 16%|‚ñà‚ñå        | 246/1535 [09:56<52:04,  2.42s/it] 16%|‚ñà‚ñå        | 247/1535 [09:58<52:01,  2.42s/it] 16%|‚ñà‚ñå        | 248/1535 [10:01<51:59,  2.42s/it] 16%|‚ñà‚ñå        | 249/1535 [10:03<51:56,  2.42s/it] 16%|‚ñà‚ñã        | 250/1535 [10:06<52:08,  2.43s/it] 16%|‚ñà‚ñã        | 251/1535 [10:08<52:00,  2.43s/it] 16%|‚ñà‚ñã        | 252/1535 [10:10<51:54,  2.43s/it] 16%|‚ñà‚ñã        | 253/1535 [10:13<51:50,  2.43s/it] 17%|‚ñà‚ñã        | 254/1535 [10:15<51:46,  2.43s/it] 17%|‚ñà‚ñã        | 255/1535 [10:18<51:42,  2.42s/it] 17%|‚ñà‚ñã        | 256/1535 [10:20<51:39,  2.42s/it] 17%|‚ñà‚ñã        | 257/1535 [10:23<51:45,  2.43s/it] 17%|‚ñà‚ñã        | 258/1535 [10:25<51:39,  2.43s/it] 17%|‚ñà‚ñã        | 259/1535 [10:27<51:35,  2.43s/it] 17%|‚ñà‚ñã        | 260/1535 [10:30<51:31,  2.42s/it]                                                  {'loss': 0.5911, 'grad_norm': 0.39393800497055054, 'learning_rate': 0.0004218241042345277, 'epoch': 0.85}
 17%|‚ñà‚ñã        | 260/1535 [10:30<51:31,  2.42s/it] 17%|‚ñà‚ñã        | 261/1535 [10:32<51:28,  2.42s/it] 17%|‚ñà‚ñã        | 262/1535 [10:35<51:24,  2.42s/it] 17%|‚ñà‚ñã        | 263/1535 [10:37<51:21,  2.42s/it] 17%|‚ñà‚ñã        | 264/1535 [10:40<51:18,  2.42s/it] 17%|‚ñà‚ñã        | 265/1535 [10:42<51:28,  2.43s/it] 17%|‚ñà‚ñã        | 266/1535 [10:44<51:21,  2.43s/it] 17%|‚ñà‚ñã        | 267/1535 [10:47<51:16,  2.43s/it] 17%|‚ñà‚ñã        | 268/1535 [10:49<51:12,  2.42s/it] 18%|‚ñà‚ñä        | 269/1535 [10:52<51:08,  2.42s/it] 18%|‚ñà‚ñä        | 270/1535 [10:54<51:05,  2.42s/it] 18%|‚ñà‚ñä        | 271/1535 [10:57<51:10,  2.43s/it] 18%|‚ñà‚ñä        | 272/1535 [10:59<51:05,  2.43s/it] 18%|‚ñà‚ñä        | 273/1535 [11:01<51:00,  2.43s/it] 18%|‚ñà‚ñä        | 274/1535 [11:04<50:57,  2.42s/it] 18%|‚ñà‚ñä        | 275/1535 [11:06<50:53,  2.42s/it] 18%|‚ñà‚ñä        | 276/1535 [11:09<50:50,  2.42s/it] 18%|‚ñà‚ñä        | 277/1535 [11:11<50:47,  2.42s/it] 18%|‚ñà‚ñä        | 278/1535 [11:14<50:55,  2.43s/it] 18%|‚ñà‚ñä        | 279/1535 [11:16<50:49,  2.43s/it] 18%|‚ñà‚ñä        | 280/1535 [11:18<50:44,  2.43s/it]                                                  {'loss': 0.5928, 'grad_norm': 0.3561767339706421, 'learning_rate': 0.0004543973941368078, 'epoch': 0.91}
 18%|‚ñà‚ñä        | 280/1535 [11:18<50:44,  2.43s/it] 18%|‚ñà‚ñä        | 281/1535 [11:21<50:41,  2.43s/it] 18%|‚ñà‚ñä        | 282/1535 [11:23<50:37,  2.42s/it] 18%|‚ñà‚ñä        | 283/1535 [11:26<50:34,  2.42s/it] 19%|‚ñà‚ñä        | 284/1535 [11:28<50:31,  2.42s/it] 19%|‚ñà‚ñä        | 285/1535 [11:30<50:28,  2.42s/it] 19%|‚ñà‚ñä        | 286/1535 [11:33<50:33,  2.43s/it] 19%|‚ñà‚ñä        | 287/1535 [11:35<50:28,  2.43s/it] 19%|‚ñà‚ñâ        | 288/1535 [11:38<50:24,  2.43s/it] 19%|‚ñà‚ñâ        | 289/1535 [11:40<50:20,  2.42s/it] 19%|‚ñà‚ñâ        | 290/1535 [11:43<50:17,  2.42s/it] 19%|‚ñà‚ñâ        | 291/1535 [11:45<50:14,  2.42s/it] 19%|‚ñà‚ñâ        | 292/1535 [11:47<50:11,  2.42s/it] 19%|‚ñà‚ñâ        | 293/1535 [11:50<50:08,  2.42s/it] 19%|‚ñà‚ñâ        | 294/1535 [11:52<50:05,  2.42s/it] 19%|‚ñà‚ñâ        | 295/1535 [11:55<50:02,  2.42s/it] 19%|‚ñà‚ñâ        | 296/1535 [11:57<50:00,  2.42s/it] 19%|‚ñà‚ñâ        | 297/1535 [12:00<49:57,  2.42s/it] 19%|‚ñà‚ñâ        | 298/1535 [12:02<49:55,  2.42s/it] 19%|‚ñà‚ñâ        | 299/1535 [12:04<49:52,  2.42s/it] 20%|‚ñà‚ñâ        | 300/1535 [12:07<49:51,  2.42s/it]                                                  {'loss': 0.5946, 'grad_norm': 0.35801902413368225, 'learning_rate': 0.00048697068403908794, 'epoch': 0.98}
 20%|‚ñà‚ñâ        | 300/1535 [12:07<49:51,  2.42s/it] 20%|‚ñà‚ñâ        | 301/1535 [12:09<49:49,  2.42s/it] 20%|‚ñà‚ñâ        | 302/1535 [12:12<49:47,  2.42s/it] 20%|‚ñà‚ñâ        | 303/1535 [12:14<49:44,  2.42s/it] 20%|‚ñà‚ñâ        | 304/1535 [12:17<49:41,  2.42s/it] 20%|‚ñà‚ñâ        | 305/1535 [12:19<49:39,  2.42s/it] 20%|‚ñà‚ñâ        | 306/1535 [12:21<49:36,  2.42s/it] 20%|‚ñà‚ñà        | 307/1535 [12:24<49:38,  2.43s/it] 20%|‚ñà‚ñà        | 308/1535 [12:26<49:34,  2.42s/it] 20%|‚ñà‚ñà        | 309/1535 [12:29<49:30,  2.42s/it] 20%|‚ñà‚ñà        | 310/1535 [12:31<49:27,  2.42s/it] 20%|‚ñà‚ñà        | 311/1535 [12:33<49:24,  2.42s/it] 20%|‚ñà‚ñà        | 312/1535 [12:36<49:21,  2.42s/it] 20%|‚ñà‚ñà        | 313/1535 [12:38<49:19,  2.42s/it] 20%|‚ñà‚ñà        | 314/1535 [12:41<49:16,  2.42s/it] 21%|‚ñà‚ñà        | 315/1535 [12:43<49:21,  2.43s/it] 21%|‚ñà‚ñà        | 316/1535 [12:46<49:16,  2.43s/it] 21%|‚ñà‚ñà        | 317/1535 [12:48<49:12,  2.42s/it] 21%|‚ñà‚ñà        | 318/1535 [12:50<49:09,  2.42s/it] 21%|‚ñà‚ñà        | 319/1535 [12:53<49:06,  2.42s/it] 21%|‚ñà‚ñà        | 320/1535 [12:55<49:12,  2.43s/it]                                                  {'loss': 0.5805, 'grad_norm': 0.32812991738319397, 'learning_rate': 0.0004998822010531848, 'epoch': 1.04}
 21%|‚ñà‚ñà        | 320/1535 [12:55<49:12,  2.43s/it] 21%|‚ñà‚ñà        | 321/1535 [12:58<49:08,  2.43s/it] 21%|‚ñà‚ñà        | 322/1535 [13:00<49:02,  2.43s/it] 21%|‚ñà‚ñà        | 323/1535 [13:03<48:58,  2.42s/it] 21%|‚ñà‚ñà        | 324/1535 [13:05<48:54,  2.42s/it] 21%|‚ñà‚ñà        | 325/1535 [13:07<48:51,  2.42s/it] 21%|‚ñà‚ñà        | 326/1535 [13:10<48:49,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 327/1535 [13:12<48:46,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 328/1535 [13:15<48:43,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 329/1535 [13:17<48:48,  2.43s/it] 21%|‚ñà‚ñà‚ñè       | 330/1535 [13:20<48:43,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 331/1535 [13:22<48:39,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 332/1535 [13:24<48:35,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 333/1535 [13:27<48:32,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 334/1535 [13:29<48:41,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 335/1535 [13:32<48:35,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 336/1535 [13:34<48:30,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 337/1535 [13:37<48:25,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 338/1535 [13:39<48:21,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 339/1535 [13:41<48:18,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 340/1535 [13:44<48:16,  2.42s/it]                                                  {'loss': 0.5769, 'grad_norm': 0.3721354603767395, 'learning_rate': 0.0004991627205825621, 'epoch': 1.11}
 22%|‚ñà‚ñà‚ñè       | 340/1535 [13:44<48:16,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 341/1535 [13:46<48:14,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 342/1535 [13:49<48:10,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 343/1535 [13:51<48:07,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 344/1535 [13:54<48:15,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 345/1535 [13:56<48:09,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 346/1535 [13:58<48:04,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 347/1535 [14:01<48:00,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 348/1535 [14:03<48:04,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 349/1535 [14:06<47:59,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 350/1535 [14:08<47:54,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 351/1535 [14:10<47:50,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 352/1535 [14:13<47:47,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 353/1535 [14:15<47:45,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 354/1535 [14:18<47:41,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 355/1535 [14:20<47:38,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 356/1535 [14:23<47:35,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 357/1535 [14:25<47:32,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 358/1535 [14:27<47:33,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 359/1535 [14:30<47:30,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 360/1535 [14:32<47:26,  2.42s/it]                                                  {'loss': 0.5174, 'grad_norm': 0.48570215702056885, 'learning_rate': 0.0004977910843763777, 'epoch': 1.17}
 23%|‚ñà‚ñà‚ñé       | 360/1535 [14:32<47:26,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 361/1535 [14:35<47:24,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 362/1535 [14:37<47:21,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 363/1535 [14:40<47:19,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 364/1535 [14:42<47:16,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 365/1535 [14:44<47:13,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 366/1535 [14:47<47:10,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 367/1535 [14:49<47:08,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 368/1535 [14:52<47:05,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 369/1535 [14:54<47:02,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 370/1535 [14:57<47:00,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 371/1535 [14:59<46:58,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 372/1535 [15:01<46:55,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 373/1535 [15:04<47:00,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 374/1535 [15:06<46:57,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 375/1535 [15:09<46:52,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 376/1535 [15:11<46:53,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 377/1535 [15:13<46:49,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 378/1535 [15:16<46:45,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 379/1535 [15:18<46:41,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 380/1535 [15:21<46:38,  2.42s/it]                                                  {'loss': 0.5128, 'grad_norm': 0.3361925482749939, 'learning_rate': 0.0004957708825399927, 'epoch': 1.24}
 25%|‚ñà‚ñà‚ñç       | 380/1535 [15:21<46:38,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 381/1535 [15:23<46:36,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 382/1535 [15:26<46:33,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 383/1535 [15:28<46:30,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 384/1535 [15:30<46:27,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 385/1535 [15:33<46:24,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 386/1535 [15:35<46:21,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 387/1535 [15:38<46:20,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 388/1535 [15:40<46:17,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 389/1535 [15:43<46:23,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 390/1535 [15:45<46:18,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 391/1535 [15:47<46:14,  2.43s/it] 26%|‚ñà‚ñà‚ñå       | 392/1535 [15:50<46:10,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 393/1535 [15:52<46:07,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 394/1535 [15:55<46:04,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 395/1535 [15:57<46:01,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 396/1535 [16:00<45:58,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 397/1535 [16:02<45:55,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 398/1535 [16:04<45:52,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 399/1535 [16:07<45:50,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 400/1535 [16:09<45:47,  2.42s/it]                                                  {'loss': 0.528, 'grad_norm': 0.3597891628742218, 'learning_rate': 0.0004931074027272406, 'epoch': 1.3}
 26%|‚ñà‚ñà‚ñå       | 400/1535 [16:09<45:47,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 05:31:09,098 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-400
[INFO|configuration_utils.py:726] 2024-05-25 05:31:10,603 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:31:10,606 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 05:31:10,688 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 05:31:10,689 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-400/special_tokens_map.json
 26%|‚ñà‚ñà‚ñå       | 401/1535 [16:13<55:43,  2.95s/it] 26%|‚ñà‚ñà‚ñå       | 402/1535 [16:16<52:40,  2.79s/it] 26%|‚ñà‚ñà‚ñã       | 403/1535 [16:18<50:31,  2.68s/it] 26%|‚ñà‚ñà‚ñã       | 404/1535 [16:21<49:10,  2.61s/it] 26%|‚ñà‚ñà‚ñã       | 405/1535 [16:23<48:03,  2.55s/it] 26%|‚ñà‚ñà‚ñã       | 406/1535 [16:26<47:16,  2.51s/it] 27%|‚ñà‚ñà‚ñã       | 407/1535 [16:28<46:42,  2.48s/it] 27%|‚ñà‚ñà‚ñã       | 408/1535 [16:30<46:17,  2.46s/it] 27%|‚ñà‚ñà‚ñã       | 409/1535 [16:33<46:00,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 410/1535 [16:35<45:46,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 411/1535 [16:38<45:35,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 412/1535 [16:40<45:28,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 413/1535 [16:42<45:22,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 414/1535 [16:45<45:17,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 415/1535 [16:47<45:57,  2.46s/it] 27%|‚ñà‚ñà‚ñã       | 416/1535 [16:50<45:40,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 417/1535 [16:52<45:37,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 418/1535 [16:55<45:23,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 419/1535 [16:57<45:15,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 420/1535 [17:00<45:07,  2.43s/it]                                                  {'loss': 0.5196, 'grad_norm': 0.40811651945114136, 'learning_rate': 0.0004899875912715296, 'epoch': 1.37}
 27%|‚ñà‚ñà‚ñã       | 420/1535 [17:00<45:07,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 421/1535 [17:02<45:02,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 422/1535 [17:04<44:58,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 423/1535 [17:07<44:54,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 424/1535 [17:09<44:50,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 425/1535 [17:12<44:46,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 426/1535 [17:14<44:43,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 427/1535 [17:16<44:41,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 428/1535 [17:19<44:38,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 429/1535 [17:21<44:35,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 430/1535 [17:24<44:43,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 431/1535 [17:26<44:37,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 432/1535 [17:29<44:32,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 433/1535 [17:31<44:28,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 434/1535 [17:33<44:25,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 435/1535 [17:36<44:22,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 436/1535 [17:38<44:19,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 437/1535 [17:41<44:16,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 438/1535 [17:43<44:14,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 439/1535 [17:46<44:11,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 440/1535 [17:48<44:08,  2.42s/it]                                                  {'loss': 0.5617, 'grad_norm': 0.3522901237010956, 'learning_rate': 0.0004860912879566511, 'epoch': 1.43}
 29%|‚ñà‚ñà‚ñä       | 440/1535 [17:48<44:08,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 441/1535 [17:50<44:08,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 442/1535 [17:53<44:05,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 443/1535 [17:55<44:02,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 444/1535 [17:58<43:59,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 445/1535 [18:00<43:57,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 446/1535 [18:02<43:59,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 447/1535 [18:05<43:56,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 448/1535 [18:07<43:54,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 449/1535 [18:10<43:51,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 450/1535 [18:12<43:48,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 451/1535 [18:15<43:45,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 452/1535 [18:17<43:42,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 453/1535 [18:19<43:39,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 454/1535 [18:22<43:37,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 455/1535 [18:24<43:35,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 456/1535 [18:27<43:32,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 457/1535 [18:29<43:30,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 458/1535 [18:32<43:27,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 459/1535 [18:34<43:35,  2.43s/it] 30%|‚ñà‚ñà‚ñâ       | 460/1535 [18:36<43:29,  2.43s/it]                                                  {'loss': 0.5333, 'grad_norm': 0.3467969596385956, 'learning_rate': 0.000481577041928685, 'epoch': 1.5}
 30%|‚ñà‚ñà‚ñâ       | 460/1535 [18:36<43:29,  2.43s/it] 30%|‚ñà‚ñà‚ñà       | 461/1535 [18:39<43:25,  2.43s/it] 30%|‚ñà‚ñà‚ñà       | 462/1535 [18:41<43:21,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 463/1535 [18:44<43:17,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 464/1535 [18:46<43:14,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 465/1535 [18:49<43:12,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 466/1535 [18:51<43:09,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 467/1535 [18:53<43:06,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 468/1535 [18:56<43:03,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 469/1535 [18:58<43:00,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 470/1535 [19:01<42:59,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 471/1535 [19:03<42:56,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 472/1535 [19:05<42:53,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 473/1535 [19:08<43:07,  2.44s/it] 31%|‚ñà‚ñà‚ñà       | 474/1535 [19:10<43:00,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 475/1535 [19:13<42:54,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 476/1535 [19:15<42:49,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 477/1535 [19:18<42:45,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 478/1535 [19:20<42:42,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 479/1535 [19:22<42:38,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 480/1535 [19:25<42:36,  2.42s/it]                                                  {'loss': 0.5276, 'grad_norm': 0.33194389939308167, 'learning_rate': 0.000476456668725012, 'epoch': 1.56}
 31%|‚ñà‚ñà‚ñà‚ñè      | 480/1535 [19:25<42:36,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 481/1535 [19:27<42:33,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 482/1535 [19:30<42:30,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 483/1535 [19:32<42:27,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 484/1535 [19:35<42:25,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 485/1535 [19:37<42:22,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 486/1535 [19:39<42:19,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 487/1535 [19:42<42:27,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 488/1535 [19:44<42:22,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 489/1535 [19:47<42:17,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 490/1535 [19:49<42:13,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 491/1535 [19:52<42:09,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 492/1535 [19:54<42:06,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 493/1535 [19:56<42:03,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 494/1535 [19:59<42:00,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 495/1535 [20:01<41:58,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 496/1535 [20:04<41:56,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 497/1535 [20:06<41:53,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 498/1535 [20:08<41:51,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 499/1535 [20:11<41:48,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 500/1535 [20:13<41:46,  2.42s/it]                                                  {'loss': 0.5211, 'grad_norm': 0.29971131682395935, 'learning_rate': 0.0004707435703535453, 'epoch': 1.63}
 33%|‚ñà‚ñà‚ñà‚ñé      | 500/1535 [20:13<41:46,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 501/1535 [20:16<41:47,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 502/1535 [20:18<41:44,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 503/1535 [20:21<41:40,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 504/1535 [20:23<41:37,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 505/1535 [20:25<41:34,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 506/1535 [20:28<41:31,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 507/1535 [20:30<41:29,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 508/1535 [20:33<41:26,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 509/1535 [20:35<41:24,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 510/1535 [20:38<41:21,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 511/1535 [20:40<41:19,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 512/1535 [20:42<41:16,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 513/1535 [20:45<41:14,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 514/1535 [20:47<41:11,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 515/1535 [20:50<41:10,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 516/1535 [20:52<41:07,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 517/1535 [20:55<41:07,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 518/1535 [20:57<41:05,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 519/1535 [20:59<41:02,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1535 [21:02<40:58,  2.42s/it]                                                  {'loss': 0.4895, 'grad_norm': 0.3427269160747528, 'learning_rate': 0.00046445270021446504, 'epoch': 1.69}
 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1535 [21:02<40:58,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 521/1535 [21:04<40:56,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 522/1535 [21:07<40:53,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 523/1535 [21:09<40:50,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 524/1535 [21:11<40:47,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 525/1535 [21:14<40:45,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 526/1535 [21:16<40:42,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 527/1535 [21:19<40:40,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 528/1535 [21:21<40:42,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 529/1535 [21:24<40:38,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 530/1535 [21:26<40:35,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 531/1535 [21:28<40:32,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 532/1535 [21:31<40:29,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 533/1535 [21:33<40:26,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 534/1535 [21:36<40:23,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 535/1535 [21:38<40:20,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 536/1535 [21:41<40:18,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 537/1535 [21:43<40:15,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 538/1535 [21:45<40:13,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 539/1535 [21:48<40:11,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1535 [21:50<40:08,  2.42s/it]                                                  {'loss': 0.4908, 'grad_norm': 0.33904391527175903, 'learning_rate': 0.00045760052396135386, 'epoch': 1.76}
 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1535 [21:50<40:08,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 541/1535 [21:53<40:06,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 542/1535 [21:55<40:04,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 543/1535 [21:58<40:12,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 544/1535 [22:00<40:07,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 545/1535 [22:02<40:01,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 546/1535 [22:05<39:58,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 547/1535 [22:07<39:54,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 548/1535 [22:10<39:53,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 549/1535 [22:12<39:49,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 550/1535 [22:14<39:46,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 551/1535 [22:17<39:43,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 552/1535 [22:19<39:42,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 553/1535 [22:22<39:39,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 554/1535 [22:24<39:36,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 555/1535 [22:27<39:33,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 556/1535 [22:29<39:38,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 557/1535 [22:31<39:33,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 558/1535 [22:34<39:29,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 559/1535 [22:36<39:25,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1535 [22:39<39:22,  2.42s/it]                                                  {'loss': 0.4881, 'grad_norm': 0.45041418075561523, 'learning_rate': 0.00045020497640417914, 'epoch': 1.82}
 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1535 [22:39<39:22,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 561/1535 [22:41<39:19,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 562/1535 [22:44<39:16,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 563/1535 [22:46<39:13,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 564/1535 [22:48<39:11,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 565/1535 [22:51<39:09,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 566/1535 [22:53<39:06,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 567/1535 [22:56<39:04,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 568/1535 [22:58<39:01,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 569/1535 [23:01<38:58,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 570/1535 [23:03<38:56,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 571/1535 [23:05<38:54,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 572/1535 [23:08<38:51,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 573/1535 [23:10<38:49,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 574/1535 [23:13<38:46,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 575/1535 [23:15<38:44,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 576/1535 [23:17<38:42,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 577/1535 [23:20<38:39,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 578/1535 [23:22<38:37,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 579/1535 [23:25<38:34,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1535 [23:27<38:33,  2.42s/it]                                                  {'loss': 0.475, 'grad_norm': 0.3754814863204956, 'learning_rate': 0.0004422854145669198, 'epoch': 1.89}
 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1535 [23:27<38:33,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 581/1535 [23:30<38:31,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 582/1535 [23:32<38:28,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 583/1535 [23:34<38:25,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 584/1535 [23:37<38:22,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 585/1535 [23:39<38:26,  2.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 586/1535 [23:42<38:21,  2.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 587/1535 [23:44<38:17,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 588/1535 [23:47<38:14,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 589/1535 [23:49<38:11,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 590/1535 [23:51<38:09,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 591/1535 [23:54<38:06,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 592/1535 [23:56<38:03,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 593/1535 [23:59<38:01,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 594/1535 [24:01<37:58,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 595/1535 [24:03<37:55,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 596/1535 [24:06<37:53,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 597/1535 [24:08<37:50,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 598/1535 [24:11<37:49,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 599/1535 [24:13<37:46,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1535 [24:16<37:45,  2.42s/it]                                                  {'loss': 0.5044, 'grad_norm': 0.40352994203567505, 'learning_rate': 0.00043386256702270773, 'epoch': 1.95}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1535 [24:16<37:45,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 601/1535 [24:18<37:42,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 602/1535 [24:20<37:39,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 603/1535 [24:23<37:37,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 604/1535 [24:25<37:40,  2.43s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 605/1535 [24:28<37:35,  2.43s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 606/1535 [24:30<37:32,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 607/1535 [24:33<37:28,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 608/1535 [24:35<37:25,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 609/1535 [24:37<37:22,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 610/1535 [24:40<37:20,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 611/1535 [24:42<37:17,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 612/1535 [24:45<37:22,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 613/1535 [24:47<37:17,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 614/1535 [24:50<37:13,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 615/1535 [24:52<37:09,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 616/1535 [24:54<37:07,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 617/1535 [24:57<37:04,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 618/1535 [24:59<37:01,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 619/1535 [25:02<36:58,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1535 [25:04<36:55,  2.42s/it]                                                  {'loss': 0.4601, 'grad_norm': 0.3429182171821594, 'learning_rate': 0.0004249584796390903, 'epoch': 2.02}
 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1535 [25:04<36:55,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 621/1535 [25:06<36:53,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 622/1535 [25:09<36:50,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 623/1535 [25:11<36:48,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 624/1535 [25:14<36:45,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 625/1535 [25:16<36:43,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 626/1535 [25:19<36:47,  2.43s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 627/1535 [25:21<36:43,  2.43s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 628/1535 [25:23<36:39,  2.43s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 629/1535 [25:26<36:36,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 630/1535 [25:28<36:32,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 631/1535 [25:31<36:31,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 632/1535 [25:33<36:29,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 633/1535 [25:36<36:25,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 634/1535 [25:38<36:22,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 635/1535 [25:40<36:19,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 636/1535 [25:43<36:16,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 637/1535 [25:45<36:15,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 638/1535 [25:48<36:13,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 639/1535 [25:50<36:10,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1535 [25:53<36:07,  2.42s/it]                                                  {'loss': 0.4197, 'grad_norm': 0.32660481333732605, 'learning_rate': 0.000415596457875422, 'epoch': 2.08}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1535 [25:53<36:07,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 641/1535 [25:55<36:05,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 642/1535 [25:57<36:02,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 643/1535 [26:00<35:59,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 644/1535 [26:02<35:57,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 645/1535 [26:05<35:54,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 646/1535 [26:07<35:52,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 647/1535 [26:09<35:49,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 648/1535 [26:12<35:47,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 649/1535 [26:14<35:45,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 650/1535 [26:17<35:42,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 651/1535 [26:19<35:40,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 652/1535 [26:22<35:37,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 653/1535 [26:24<35:35,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 654/1535 [26:26<35:38,  2.43s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 655/1535 [26:29<35:34,  2.43s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 656/1535 [26:31<35:30,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 657/1535 [26:34<35:27,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 658/1535 [26:36<35:24,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 659/1535 [26:39<35:21,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1535 [26:41<35:18,  2.42s/it]                                                  {'loss': 0.447, 'grad_norm': 0.327488511800766, 'learning_rate': 0.00040580100578341385, 'epoch': 2.15}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1535 [26:41<35:18,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 661/1535 [26:43<35:16,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 662/1535 [26:46<35:13,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 663/1535 [26:48<35:10,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 664/1535 [26:51<35:08,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 665/1535 [26:53<35:06,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 666/1535 [26:55<35:04,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 667/1535 [26:58<35:05,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 668/1535 [27:00<35:02,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 669/1535 [27:03<34:59,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 670/1535 [27:05<34:56,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 671/1535 [27:08<34:53,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 672/1535 [27:10<34:50,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 673/1535 [27:12<34:47,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 674/1535 [27:15<34:45,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 675/1535 [27:17<34:48,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 676/1535 [27:20<34:44,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 677/1535 [27:22<34:40,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 678/1535 [27:25<34:37,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 679/1535 [27:27<34:34,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1535 [27:29<34:31,  2.42s/it]                                                  {'loss': 0.4034, 'grad_norm': 0.406791627407074, 'learning_rate': 0.000395597761870501, 'epoch': 2.21}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1535 [27:29<34:31,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 681/1535 [27:32<34:28,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 682/1535 [27:34<34:39,  2.44s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 683/1535 [27:37<34:32,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 684/1535 [27:39<34:27,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 685/1535 [27:42<34:22,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 686/1535 [27:44<34:18,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 687/1535 [27:46<34:15,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 688/1535 [27:49<34:12,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 689/1535 [27:51<34:09,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 690/1535 [27:54<34:06,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 691/1535 [27:56<34:10,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 692/1535 [27:59<34:05,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 693/1535 [28:01<34:01,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 694/1535 [28:03<33:58,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 695/1535 [28:06<34:00,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 696/1535 [28:08<33:56,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 697/1535 [28:11<33:52,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 698/1535 [28:13<33:48,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 699/1535 [28:16<33:45,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1535 [28:18<33:42,  2.42s/it]                                                  {'loss': 0.4077, 'grad_norm': 0.3274359405040741, 'learning_rate': 0.0003850134319938983, 'epoch': 2.28}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1535 [28:18<33:42,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 701/1535 [28:20<33:40,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 702/1535 [28:23<33:37,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 703/1535 [28:25<33:34,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 704/1535 [28:28<33:37,  2.43s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 705/1535 [28:30<33:33,  2.43s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 706/1535 [28:32<33:29,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 707/1535 [28:35<33:26,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 708/1535 [28:37<33:23,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 709/1535 [28:40<33:20,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 710/1535 [28:42<33:17,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 711/1535 [28:45<33:15,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 712/1535 [28:47<33:12,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 713/1535 [28:49<33:09,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 714/1535 [28:52<33:07,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 715/1535 [28:54<33:04,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 716/1535 [28:57<33:02,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 717/1535 [28:59<33:00,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 718/1535 [29:02<32:57,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 719/1535 [29:04<32:55,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1535 [29:06<32:52,  2.42s/it]                                                  {'loss': 0.414, 'grad_norm': 0.4189653694629669, 'learning_rate': 0.0003740757194609865, 'epoch': 2.34}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1535 [29:06<32:52,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 721/1535 [29:09<32:51,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 722/1535 [29:11<32:48,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 723/1535 [29:14<32:45,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 724/1535 [29:16<32:49,  2.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 725/1535 [29:19<32:44,  2.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 726/1535 [29:21<32:41,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 727/1535 [29:23<32:37,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 728/1535 [29:26<32:34,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 729/1535 [29:28<32:32,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 730/1535 [29:31<32:29,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 731/1535 [29:33<32:26,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 732/1535 [29:35<32:23,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 733/1535 [29:38<32:27,  2.43s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 734/1535 [29:40<32:23,  2.43s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 735/1535 [29:43<32:19,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 736/1535 [29:45<32:16,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 737/1535 [29:48<32:15,  2.43s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 738/1535 [29:50<32:12,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 739/1535 [29:52<32:08,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1535 [29:55<32:05,  2.42s/it]                                                  {'loss': 0.4094, 'grad_norm': 0.40143823623657227, 'learning_rate': 0.00036281325251898323, 'epoch': 2.41}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1535 [29:55<32:05,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 741/1535 [29:57<32:03,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 742/1535 [30:00<32:00,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 743/1535 [30:02<31:58,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 744/1535 [30:05<31:55,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 745/1535 [30:07<31:52,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 746/1535 [30:09<31:50,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 747/1535 [30:12<31:47,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 748/1535 [30:14<31:45,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 749/1535 [30:17<31:42,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 750/1535 [30:19<31:40,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 751/1535 [30:22<31:52,  2.44s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 752/1535 [30:24<31:45,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 753/1535 [30:26<31:40,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 754/1535 [30:29<31:35,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 755/1535 [30:31<31:31,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 756/1535 [30:34<31:28,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 757/1535 [30:36<31:25,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 758/1535 [30:38<31:22,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 759/1535 [30:41<31:19,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1535 [30:43<31:16,  2.42s/it]                                                  {'loss': 0.4132, 'grad_norm': 0.41986024379730225, 'learning_rate': 0.00035125550942368696, 'epoch': 2.47}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1535 [30:43<31:16,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 761/1535 [30:46<31:14,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 762/1535 [30:48<31:11,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 763/1535 [30:51<31:08,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 764/1535 [30:53<31:06,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 765/1535 [30:55<31:06,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 766/1535 [30:58<31:02,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 767/1535 [31:00<30:59,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 768/1535 [31:03<30:57,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 769/1535 [31:05<30:54,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 770/1535 [31:08<30:52,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 771/1535 [31:10<30:49,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 772/1535 [31:12<30:47,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 773/1535 [31:15<30:44,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 774/1535 [31:17<30:41,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 775/1535 [31:20<30:39,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 776/1535 [31:22<30:36,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 777/1535 [31:24<30:34,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 778/1535 [31:27<30:32,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 779/1535 [31:29<30:29,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1535 [31:32<30:27,  2.42s/it]                                                  {'loss': 0.3998, 'grad_norm': 0.3652585744857788, 'learning_rate': 0.0003400296989439203, 'epoch': 2.54}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1535 [31:32<30:27,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 781/1535 [31:34<30:25,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 782/1535 [31:37<30:22,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 783/1535 [31:39<30:20,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 784/1535 [31:41<30:17,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 785/1535 [31:44<30:15,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 786/1535 [31:46<30:13,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 787/1535 [31:49<30:10,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 788/1535 [31:51<30:08,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 789/1535 [31:54<30:05,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 790/1535 [31:56<30:03,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 791/1535 [31:58<30:05,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 792/1535 [32:01<30:01,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 793/1535 [32:03<30:03,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 794/1535 [32:06<29:58,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 795/1535 [32:08<29:54,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 796/1535 [32:11<29:50,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 797/1535 [32:13<29:47,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 798/1535 [32:15<29:44,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 799/1535 [32:18<29:42,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1535 [32:20<29:39,  2.42s/it]                                                  {'loss': 0.423, 'grad_norm': 0.4252341091632843, 'learning_rate': 0.00032798380982472774, 'epoch': 2.6}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1535 [32:20<29:39,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 05:47:20,097 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-800
[INFO|configuration_utils.py:726] 2024-05-25 05:47:21,142 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:47:21,145 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 05:47:22,159 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 05:47:22,162 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 05:47:22,212 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 05:47:22,213 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-800/special_tokens_map.json
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 801/1535 [32:25<37:51,  3.09s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 802/1535 [32:27<35:19,  2.89s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 803/1535 [32:30<33:32,  2.75s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 804/1535 [32:32<32:16,  2.65s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 805/1535 [32:35<31:23,  2.58s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 806/1535 [32:37<30:49,  2.54s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 807/1535 [32:39<30:27,  2.51s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 808/1535 [32:42<30:04,  2.48s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 809/1535 [32:44<29:48,  2.46s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 810/1535 [32:47<29:36,  2.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 811/1535 [32:49<29:27,  2.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 812/1535 [32:52<29:20,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 813/1535 [32:54<29:14,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 814/1535 [32:56<29:09,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 815/1535 [32:59<29:05,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 816/1535 [33:01<29:01,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 817/1535 [33:04<28:58,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 818/1535 [33:06<28:55,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 819/1535 [33:08<28:52,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1535 [33:11<28:49,  2.42s/it]                                                  {'loss': 0.3975, 'grad_norm': 0.351152628660202, 'learning_rate': 0.0003157338067484422, 'epoch': 2.67}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1535 [33:11<28:49,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 821/1535 [33:13<29:21,  2.47s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 822/1535 [33:16<29:08,  2.45s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 823/1535 [33:18<28:58,  2.44s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 824/1535 [33:21<28:51,  2.44s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 825/1535 [33:23<28:45,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 826/1535 [33:26<28:40,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 827/1535 [33:28<28:36,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 828/1535 [33:30<28:32,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 829/1535 [33:33<28:29,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 830/1535 [33:35<28:26,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 831/1535 [33:38<28:24,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 832/1535 [33:40<28:21,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 833/1535 [33:42<28:18,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 834/1535 [33:45<28:16,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 835/1535 [33:47<28:13,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 836/1535 [33:50<28:10,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 837/1535 [33:52<28:08,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 838/1535 [33:55<28:05,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 839/1535 [33:57<28:03,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1535 [33:59<28:01,  2.42s/it]                                                  {'loss': 0.4011, 'grad_norm': 0.3768521547317505, 'learning_rate': 0.0003033117527369644, 'epoch': 2.73}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1535 [33:59<28:01,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 841/1535 [34:02<27:58,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 842/1535 [34:04<27:56,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 843/1535 [34:07<27:54,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 844/1535 [34:09<27:51,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 845/1535 [34:12<27:48,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 846/1535 [34:14<27:46,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 847/1535 [34:16<27:46,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 848/1535 [34:19<27:43,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 849/1535 [34:21<27:44,  2.43s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 850/1535 [34:24<27:40,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 851/1535 [34:26<27:36,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 852/1535 [34:28<27:33,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 853/1535 [34:31<27:31,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 854/1535 [34:33<27:28,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 855/1535 [34:36<27:25,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 856/1535 [34:38<27:23,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 857/1535 [34:41<27:20,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 858/1535 [34:43<27:17,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 859/1535 [34:45<27:15,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1535 [34:48<27:12,  2.42s/it]                                                  {'loss': 0.3873, 'grad_norm': 0.3639216721057892, 'learning_rate': 0.00029075016113640033, 'epoch': 2.8}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1535 [34:48<27:12,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 861/1535 [34:50<27:10,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 862/1535 [34:53<27:07,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 863/1535 [34:55<27:10,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 864/1535 [34:58<27:06,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 865/1535 [35:00<27:02,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 866/1535 [35:02<26:59,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 867/1535 [35:05<26:56,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 868/1535 [35:07<26:53,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 869/1535 [35:10<26:51,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 870/1535 [35:12<26:48,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 871/1535 [35:14<26:45,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 872/1535 [35:17<26:43,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 873/1535 [35:19<26:41,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 874/1535 [35:22<26:38,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 875/1535 [35:24<26:36,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 876/1535 [35:27<26:36,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 877/1535 [35:29<26:32,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 878/1535 [35:31<26:29,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 879/1535 [35:34<26:27,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1535 [35:36<26:24,  2.42s/it]                                                  {'loss': 0.4273, 'grad_norm': 0.4193864166736603, 'learning_rate': 0.000278081910516991, 'epoch': 2.86}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1535 [35:36<26:24,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 881/1535 [35:39<26:22,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 882/1535 [35:41<26:19,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 883/1535 [35:43<26:17,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 884/1535 [35:46<26:14,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 885/1535 [35:48<26:12,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 886/1535 [35:51<26:09,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 887/1535 [35:53<26:06,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 888/1535 [35:56<26:04,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 889/1535 [35:58<26:01,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 890/1535 [36:00<26:12,  2.44s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 891/1535 [36:03<26:06,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 892/1535 [36:05<26:01,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 893/1535 [36:08<26:01,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 894/1535 [36:10<25:56,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 895/1535 [36:13<25:52,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 896/1535 [36:15<25:48,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 897/1535 [36:17<25:45,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 898/1535 [36:20<25:42,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 899/1535 [36:22<25:39,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1535 [36:25<25:36,  2.42s/it]                                                  {'loss': 0.3892, 'grad_norm': 0.3689459562301636, 'learning_rate': 0.0002653401586171077, 'epoch': 2.93}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1535 [36:25<25:36,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 901/1535 [36:27<25:34,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 902/1535 [36:30<25:32,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 903/1535 [36:32<25:29,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 904/1535 [36:34<25:28,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 905/1535 [36:37<25:25,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 906/1535 [36:39<25:23,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 907/1535 [36:42<25:20,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 908/1535 [36:44<25:17,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 909/1535 [36:46<25:15,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 910/1535 [36:49<25:12,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 911/1535 [36:51<25:10,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 912/1535 [36:54<25:07,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 913/1535 [36:56<25:05,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 914/1535 [36:59<25:03,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 915/1535 [37:01<25:00,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 916/1535 [37:03<24:58,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 917/1535 [37:06<24:59,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 918/1535 [37:08<24:55,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 919/1535 [37:11<24:52,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1535 [37:13<24:49,  2.42s/it]                                                  {'loss': 0.3917, 'grad_norm': 0.32466310262680054, 'learning_rate': 0.00025255825555655644, 'epoch': 2.99}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1535 [37:13<24:49,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 921/1535 [37:16<24:47,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 922/1535 [37:18<24:44,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 923/1535 [37:20<24:41,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 924/1535 [37:23<24:39,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 925/1535 [37:25<24:36,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 926/1535 [37:28<24:34,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 927/1535 [37:30<24:32,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 928/1535 [37:32<24:29,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 929/1535 [37:35<24:27,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 930/1535 [37:37<24:24,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 931/1535 [37:40<24:22,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 932/1535 [37:42<24:23,  2.43s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 933/1535 [37:45<24:19,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 934/1535 [37:47<24:16,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 935/1535 [37:49<24:13,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 936/1535 [37:52<24:11,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 937/1535 [37:54<24:08,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 938/1535 [37:57<24:05,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 939/1535 [37:59<24:03,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1535 [38:02<24:00,  2.42s/it]                                                  {'loss': 0.3803, 'grad_norm': 0.449515700340271, 'learning_rate': 0.0002397696565463449, 'epoch': 3.06}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1535 [38:02<24:00,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 941/1535 [38:04<23:58,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 942/1535 [38:06<23:55,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 943/1535 [38:09<23:52,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 944/1535 [38:11<23:50,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 945/1535 [38:14<23:48,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 946/1535 [38:16<23:46,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 947/1535 [38:19<23:43,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 948/1535 [38:21<23:40,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 949/1535 [38:23<23:38,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 950/1535 [38:26<23:35,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 951/1535 [38:28<23:33,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 952/1535 [38:31<23:31,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 953/1535 [38:33<23:28,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 954/1535 [38:35<23:26,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 955/1535 [38:38<23:23,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 956/1535 [38:40<23:21,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 957/1535 [38:43<23:19,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 958/1535 [38:45<23:16,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 959/1535 [38:48<23:14,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 960/1535 [38:50<23:23,  2.44s/it]                                                  {'loss': 0.3371, 'grad_norm': 0.3396831154823303, 'learning_rate': 0.00022764477333910645, 'epoch': 3.12}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 960/1535 [38:50<23:23,  2.44s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 961/1535 [38:52<23:18,  2.44s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 962/1535 [38:55<23:13,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 963/1535 [38:57<23:08,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 964/1535 [39:00<23:05,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 965/1535 [39:02<23:06,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 966/1535 [39:05<23:01,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 967/1535 [39:07<22:58,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 968/1535 [39:09<22:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 969/1535 [39:12<22:51,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 970/1535 [39:14<22:48,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 971/1535 [39:17<22:46,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 972/1535 [39:19<22:43,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 973/1535 [39:22<22:40,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 974/1535 [39:24<22:38,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 975/1535 [39:26<22:35,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 976/1535 [39:29<22:33,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 977/1535 [39:31<22:30,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 978/1535 [39:34<22:28,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 979/1535 [39:36<22:25,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 980/1535 [39:38<22:23,  2.42s/it]                                                  {'loss': 0.3225, 'grad_norm': 0.3892490863800049, 'learning_rate': 0.0002149393303482419, 'epoch': 3.19}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 980/1535 [39:38<22:23,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 981/1535 [39:41<22:21,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 982/1535 [39:43<22:18,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 983/1535 [39:46<22:16,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 984/1535 [39:48<22:13,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 985/1535 [39:51<22:11,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 986/1535 [39:53<22:09,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 987/1535 [39:55<22:07,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 988/1535 [39:58<22:04,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 989/1535 [40:00<22:02,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 990/1535 [40:03<21:59,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 991/1535 [40:05<21:57,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 992/1535 [40:08<21:54,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 993/1535 [40:10<21:52,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 994/1535 [40:12<21:49,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 995/1535 [40:15<21:47,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 996/1535 [40:17<21:44,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 997/1535 [40:20<21:42,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 998/1535 [40:22<21:39,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 999/1535 [40:24<21:37,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1000/1535 [40:27<21:34,  2.42s/it]                                                   {'loss': 0.3385, 'grad_norm': 0.37954235076904297, 'learning_rate': 0.00020232565476444598, 'epoch': 3.25}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1000/1535 [40:27<21:34,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1001/1535 [40:29<21:32,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1002/1535 [40:32<21:36,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1003/1535 [40:34<21:32,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1004/1535 [40:37<21:28,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1005/1535 [40:39<21:25,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1006/1535 [40:41<21:21,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1007/1535 [40:44<21:19,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1008/1535 [40:46<21:16,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1009/1535 [40:49<21:14,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1010/1535 [40:51<21:11,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1011/1535 [40:54<21:08,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1012/1535 [40:56<21:06,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1013/1535 [40:58<21:03,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1014/1535 [41:01<21:01,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1015/1535 [41:03<20:58,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1016/1535 [41:06<20:56,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1017/1535 [41:08<20:54,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1018/1535 [41:11<20:51,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1019/1535 [41:13<20:49,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1020/1535 [41:15<20:46,  2.42s/it]                                                   {'loss': 0.3733, 'grad_norm': 0.3266822099685669, 'learning_rate': 0.00018983676148199847, 'epoch': 3.32}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1020/1535 [41:15<20:46,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1021/1535 [41:18<20:44,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1022/1535 [41:20<20:41,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1023/1535 [41:23<20:40,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1024/1535 [41:25<20:37,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1025/1535 [41:27<20:34,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1026/1535 [41:30<20:32,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1027/1535 [41:32<20:29,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1028/1535 [41:35<20:27,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1029/1535 [41:37<20:37,  2.45s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1030/1535 [41:40<20:31,  2.44s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1031/1535 [41:42<20:26,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1032/1535 [41:44<20:22,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1033/1535 [41:47<20:17,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1034/1535 [41:49<20:14,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1035/1535 [41:52<20:11,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1036/1535 [41:54<20:08,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1037/1535 [41:57<20:05,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1038/1535 [41:59<20:03,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1039/1535 [42:01<20:01,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1535 [42:04<19:58,  2.42s/it]                                                   {'loss': 0.345, 'grad_norm': 0.2849625051021576, 'learning_rate': 0.0001781176698634246, 'epoch': 3.38}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1535 [42:04<19:58,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1041/1535 [42:06<19:56,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1042/1535 [42:09<19:53,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1043/1535 [42:11<19:51,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1044/1535 [42:14<19:48,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1045/1535 [42:16<19:46,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1046/1535 [42:18<19:43,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1047/1535 [42:21<19:41,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1048/1535 [42:23<19:38,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1049/1535 [42:26<19:36,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1050/1535 [42:28<19:33,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1051/1535 [42:30<19:31,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1052/1535 [42:33<19:28,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1053/1535 [42:35<19:26,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1054/1535 [42:38<19:24,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1055/1535 [42:40<19:21,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1056/1535 [42:43<19:21,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1057/1535 [42:45<19:18,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1058/1535 [42:47<19:15,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1059/1535 [42:50<19:12,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1535 [42:52<19:10,  2.42s/it]                                                   {'loss': 0.346, 'grad_norm': 0.332626074552536, 'learning_rate': 0.00016596574732671287, 'epoch': 3.45}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1535 [42:52<19:10,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1061/1535 [42:55<19:07,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1062/1535 [42:57<19:05,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1063/1535 [43:00<19:02,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1064/1535 [43:02<19:00,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1065/1535 [43:04<18:57,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1066/1535 [43:07<18:55,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1067/1535 [43:09<18:52,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1068/1535 [43:12<18:50,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1069/1535 [43:14<18:47,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1070/1535 [43:16<18:45,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1071/1535 [43:19<18:44,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1072/1535 [43:21<18:41,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1073/1535 [43:24<18:38,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1074/1535 [43:26<18:36,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1075/1535 [43:29<18:33,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1076/1535 [43:31<18:30,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1077/1535 [43:33<18:28,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1078/1535 [43:36<18:26,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1079/1535 [43:38<18:23,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1535 [43:41<18:21,  2.42s/it]                                                   {'loss': 0.3323, 'grad_norm': 0.32714009284973145, 'learning_rate': 0.00015403377510895899, 'epoch': 3.51}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1535 [43:41<18:21,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1081/1535 [43:43<18:20,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1082/1535 [43:46<18:17,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1083/1535 [43:48<18:14,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1084/1535 [43:50<18:12,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1085/1535 [43:53<18:09,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1086/1535 [43:55<18:07,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1087/1535 [43:58<18:04,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1088/1535 [44:00<18:02,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1089/1535 [44:02<17:59,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1090/1535 [44:05<17:57,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1091/1535 [44:07<17:54,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1092/1535 [44:10<17:52,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1093/1535 [44:12<17:49,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1094/1535 [44:15<17:47,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1095/1535 [44:17<17:45,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1096/1535 [44:19<17:42,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1097/1535 [44:22<17:40,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1098/1535 [44:24<17:37,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1099/1535 [44:27<17:44,  2.44s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1535 [44:29<17:39,  2.44s/it]                                                   {'loss': 0.3324, 'grad_norm': 0.33847305178642273, 'learning_rate': 0.00014235298382162898, 'epoch': 3.58}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1535 [44:29<17:39,  2.44s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1101/1535 [44:32<17:35,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1102/1535 [44:34<17:31,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1103/1535 [44:36<17:28,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1104/1535 [44:39<17:25,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1105/1535 [44:41<17:22,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1106/1535 [44:44<17:19,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1107/1535 [44:46<17:16,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1108/1535 [44:49<17:13,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1109/1535 [44:51<17:11,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1110/1535 [44:53<17:09,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1111/1535 [44:56<17:06,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1112/1535 [44:58<17:06,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1113/1535 [45:01<17:03,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1114/1535 [45:03<17:00,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1115/1535 [45:06<16:57,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1116/1535 [45:08<16:54,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1117/1535 [45:10<16:51,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1118/1535 [45:13<16:49,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1119/1535 [45:15<16:46,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1535 [45:18<16:44,  2.42s/it]                                                   {'loss': 0.3476, 'grad_norm': 0.35946354269981384, 'learning_rate': 0.00013095394663801348, 'epoch': 3.64}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1535 [45:18<16:44,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1121/1535 [45:20<16:42,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1122/1535 [45:22<16:39,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1123/1535 [45:25<16:37,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1124/1535 [45:27<16:34,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1125/1535 [45:30<16:36,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1126/1535 [45:32<16:32,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1127/1535 [45:35<16:29,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1128/1535 [45:37<16:26,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1129/1535 [45:39<16:23,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1130/1535 [45:42<16:20,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1131/1535 [45:44<16:18,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1132/1535 [45:47<16:15,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1133/1535 [45:49<16:13,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1134/1535 [45:52<16:10,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1135/1535 [45:54<16:08,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1136/1535 [45:56<16:05,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1137/1535 [45:59<16:03,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1138/1535 [46:01<16:01,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1139/1535 [46:04<16:01,  2.43s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1535 [46:06<15:58,  2.43s/it]                                                   {'loss': 0.3397, 'grad_norm': 0.2762756049633026, 'learning_rate': 0.00011986649927134372, 'epoch': 3.71}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1535 [46:06<15:58,  2.43s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1141/1535 [46:09<15:56,  2.43s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1142/1535 [46:11<15:53,  2.43s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1143/1535 [46:13<15:50,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1144/1535 [46:16<15:47,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1145/1535 [46:18<15:44,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1146/1535 [46:21<15:41,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1147/1535 [46:23<15:39,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1148/1535 [46:25<15:37,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1149/1535 [46:28<15:34,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1150/1535 [46:30<15:32,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1151/1535 [46:33<15:29,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1152/1535 [46:35<15:27,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1153/1535 [46:38<15:24,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1154/1535 [46:40<15:27,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1155/1535 [46:42<15:23,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1156/1535 [46:45<15:19,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1157/1535 [46:47<15:16,  2.43s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1158/1535 [46:50<15:13,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1159/1535 [46:52<15:11,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1535 [46:55<15:08,  2.42s/it]                                                   {'loss': 0.3076, 'grad_norm': 0.2934170663356781, 'learning_rate': 0.00010911966188312681, 'epoch': 3.77}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1535 [46:55<15:08,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1161/1535 [46:57<15:06,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1162/1535 [46:59<15:03,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1163/1535 [47:02<15:00,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1164/1535 [47:04<14:58,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1165/1535 [47:07<14:55,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1166/1535 [47:09<14:53,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1167/1535 [47:11<14:50,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1168/1535 [47:14<14:55,  2.44s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1169/1535 [47:16<14:51,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1170/1535 [47:19<14:47,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1171/1535 [47:21<14:43,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1172/1535 [47:24<14:40,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1173/1535 [47:26<14:37,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1174/1535 [47:28<14:34,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1175/1535 [47:31<14:31,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1176/1535 [47:33<14:29,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1177/1535 [47:36<14:26,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1178/1535 [47:38<14:24,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1179/1535 [47:41<14:21,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1535 [47:43<14:19,  2.42s/it]                                                   {'loss': 0.342, 'grad_norm': 0.3451685607433319, 'learning_rate': 9.874156312609836e-05, 'epoch': 3.84}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1535 [47:43<14:19,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1181/1535 [47:45<14:16,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1182/1535 [47:48<14:14,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1183/1535 [47:50<14:12,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1184/1535 [47:53<14:09,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1185/1535 [47:55<14:07,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1186/1535 [47:58<14:04,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1187/1535 [48:00<14:02,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1188/1535 [48:02<13:59,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1189/1535 [48:05<13:57,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1190/1535 [48:07<13:55,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1191/1535 [48:10<13:52,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1192/1535 [48:12<13:50,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1193/1535 [48:14<13:47,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1194/1535 [48:17<13:45,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1195/1535 [48:19<13:44,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1196/1535 [48:22<13:41,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1197/1535 [48:24<13:41,  2.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1198/1535 [48:27<13:37,  2.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1199/1535 [48:29<13:34,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1535 [48:31<13:31,  2.42s/it]                                                   {'loss': 0.3357, 'grad_norm': 0.3438768684864044, 'learning_rate': 8.875936652059871e-05, 'epoch': 3.9}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1535 [48:31<13:31,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 06:03:31,354 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-1200
[INFO|configuration_utils.py:726] 2024-05-25 06:03:32,737 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:03:32,739 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 06:03:33,285 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:03:33,287 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 06:03:33,338 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 06:03:33,339 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/checkpoint-1200/special_tokens_map.json
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1201/1535 [48:36<17:03,  3.07s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1202/1535 [48:38<15:55,  2.87s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1203/1535 [48:41<15:08,  2.74s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1204/1535 [48:43<14:33,  2.64s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1205/1535 [48:46<14:09,  2.57s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1206/1535 [48:48<13:51,  2.53s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1207/1535 [48:51<13:38,  2.49s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1208/1535 [48:53<13:28,  2.47s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1209/1535 [48:55<13:20,  2.46s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1210/1535 [48:58<13:15,  2.45s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1211/1535 [49:00<13:10,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1212/1535 [49:03<13:10,  2.45s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1213/1535 [49:05<13:05,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1214/1535 [49:08<13:00,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1215/1535 [49:10<12:56,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1216/1535 [49:12<12:53,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1217/1535 [49:15<12:50,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1218/1535 [49:17<12:47,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1219/1535 [49:20<12:44,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1535 [49:22<12:42,  2.42s/it]                                                   {'loss': 0.3325, 'grad_norm': 0.3620160222053528, 'learning_rate': 7.9199199357077e-05, 'epoch': 3.97}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1535 [49:22<12:42,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1221/1535 [49:24<12:39,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1222/1535 [49:27<12:37,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1223/1535 [49:29<12:34,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1224/1535 [49:32<12:32,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1225/1535 [49:34<12:29,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1226/1535 [49:37<12:29,  2.43s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1227/1535 [49:39<12:26,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1228/1535 [49:41<12:23,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1229/1535 [49:44<12:20,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1230/1535 [49:46<12:17,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1231/1535 [49:49<12:15,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1232/1535 [49:51<12:13,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1233/1535 [49:53<12:10,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1234/1535 [49:56<12:07,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1235/1535 [49:58<12:05,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1236/1535 [50:01<12:04,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1237/1535 [50:03<12:01,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1238/1535 [50:06<12:04,  2.44s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1239/1535 [50:08<12:00,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1535 [50:11<11:56,  2.43s/it]                                                   {'loss': 0.3303, 'grad_norm': 0.3192557692527771, 'learning_rate': 7.008608431081178e-05, 'epoch': 4.03}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1535 [50:11<11:56,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1241/1535 [50:13<11:55,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1242/1535 [50:15<11:51,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1243/1535 [50:18<11:48,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1244/1535 [50:20<11:45,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1245/1535 [50:23<11:42,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1246/1535 [50:25<11:39,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1247/1535 [50:27<11:37,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1248/1535 [50:30<11:34,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1249/1535 [50:32<11:31,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1250/1535 [50:35<11:29,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1251/1535 [50:37<11:28,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1252/1535 [50:40<11:25,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1253/1535 [50:42<11:22,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1254/1535 [50:44<11:19,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1255/1535 [50:47<11:18,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1256/1535 [50:49<11:15,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1257/1535 [50:52<11:12,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1258/1535 [50:54<11:10,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1259/1535 [50:57<11:08,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1535 [50:59<11:05,  2.42s/it]                                                   {'loss': 0.2844, 'grad_norm': 0.2730634808540344, 'learning_rate': 6.14438739478383e-05, 'epoch': 4.1}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1535 [50:59<11:05,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1261/1535 [51:01<11:03,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1262/1535 [51:04<11:00,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1263/1535 [51:06<10:58,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1264/1535 [51:09<10:57,  2.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1265/1535 [51:11<10:54,  2.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1266/1535 [51:13<10:51,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1267/1535 [51:16<10:49,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1268/1535 [51:18<10:46,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1269/1535 [51:21<10:44,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1270/1535 [51:23<10:42,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1271/1535 [51:26<10:39,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1272/1535 [51:28<10:36,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1273/1535 [51:30<10:34,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1274/1535 [51:33<10:31,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1275/1535 [51:35<10:29,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1276/1535 [51:38<10:26,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1277/1535 [51:40<10:24,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1278/1535 [51:43<10:21,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1279/1535 [51:45<10:19,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1535 [51:47<10:18,  2.42s/it]                                                   {'loss': 0.3215, 'grad_norm': 0.2759706377983093, 'learning_rate': 5.329518829350788e-05, 'epoch': 4.16}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1535 [51:47<10:18,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1281/1535 [51:50<10:15,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1282/1535 [51:52<10:12,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1283/1535 [51:55<10:10,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1284/1535 [51:57<10:07,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1285/1535 [51:59<10:05,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1286/1535 [52:02<10:02,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1287/1535 [52:04<10:00,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1288/1535 [52:07<09:57,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1289/1535 [52:09<09:55,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1290/1535 [52:12<09:52,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1291/1535 [52:14<09:50,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1292/1535 [52:16<09:48,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1293/1535 [52:19<09:46,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1294/1535 [52:21<09:43,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1295/1535 [52:24<09:41,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1296/1535 [52:26<09:38,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1297/1535 [52:29<09:36,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1298/1535 [52:31<09:33,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1299/1535 [52:33<09:31,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1535 [52:36<09:28,  2.42s/it]                                                   {'loss': 0.2971, 'grad_norm': 0.2868780195713043, 'learning_rate': 4.566135562708437e-05, 'epoch': 4.23}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1535 [52:36<09:28,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1301/1535 [52:38<09:26,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1302/1535 [52:41<09:23,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1303/1535 [52:43<09:21,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1304/1535 [52:45<09:19,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1305/1535 [52:48<09:16,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1306/1535 [52:50<09:14,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1307/1535 [52:53<09:15,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1308/1535 [52:55<09:11,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1309/1535 [52:58<09:08,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1310/1535 [53:00<09:05,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1311/1535 [53:02<09:02,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1312/1535 [53:05<09:00,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1313/1535 [53:07<08:58,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1314/1535 [53:10<08:55,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1315/1535 [53:12<08:52,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1316/1535 [53:15<08:50,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1317/1535 [53:17<08:47,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1318/1535 [53:19<08:45,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1319/1535 [53:22<08:42,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1535 [53:24<08:40,  2.42s/it]                                                   {'loss': 0.3168, 'grad_norm': 0.3072579503059387, 'learning_rate': 3.8562356657343586e-05, 'epoch': 4.29}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1535 [53:24<08:40,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1321/1535 [53:27<08:38,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1322/1535 [53:29<08:36,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1323/1535 [53:32<08:33,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1324/1535 [53:34<08:31,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1325/1535 [53:36<08:28,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1326/1535 [53:39<08:26,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1327/1535 [53:41<08:23,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1328/1535 [53:44<08:21,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1329/1535 [53:46<08:18,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1330/1535 [53:48<08:16,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1331/1535 [53:51<08:13,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1332/1535 [53:53<08:11,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1333/1535 [53:56<08:08,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1334/1535 [53:58<08:08,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1335/1535 [54:01<08:05,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1336/1535 [54:03<08:02,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1337/1535 [54:05<07:59,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1338/1535 [54:08<07:57,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1339/1535 [54:10<07:54,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1535 [54:13<07:52,  2.42s/it]                                                   {'loss': 0.3199, 'grad_norm': 0.3304714858531952, 'learning_rate': 3.2016772225287845e-05, 'epoch': 4.36}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1535 [54:13<07:52,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1341/1535 [54:15<07:49,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1342/1535 [54:18<07:48,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1343/1535 [54:20<07:45,  2.43s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1344/1535 [54:22<07:43,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1345/1535 [54:25<07:40,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1346/1535 [54:27<07:37,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1347/1535 [54:30<07:35,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1348/1535 [54:32<07:33,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1349/1535 [54:35<07:30,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1350/1535 [54:37<07:28,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1351/1535 [54:39<07:25,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1352/1535 [54:42<07:23,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1353/1535 [54:44<07:20,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1354/1535 [54:47<07:18,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1355/1535 [54:49<07:15,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1356/1535 [54:51<07:13,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1357/1535 [54:54<07:12,  2.43s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1358/1535 [54:56<07:09,  2.43s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1359/1535 [54:59<07:06,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1535 [55:01<07:04,  2.42s/it]                                                   {'loss': 0.3014, 'grad_norm': 0.2683049440383911, 'learning_rate': 2.604173467085949e-05, 'epoch': 4.42}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1535 [55:01<07:04,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1361/1535 [55:04<07:01,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1362/1535 [55:06<06:59,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1363/1535 [55:08<06:56,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1364/1535 [55:11<06:54,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1365/1535 [55:13<06:51,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1366/1535 [55:16<06:49,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1367/1535 [55:18<06:46,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1368/1535 [55:21<06:44,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1369/1535 [55:23<06:41,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1370/1535 [55:25<06:39,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1371/1535 [55:28<06:38,  2.43s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1372/1535 [55:30<06:35,  2.43s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1373/1535 [55:33<06:32,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1374/1535 [55:35<06:30,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1375/1535 [55:38<06:27,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1376/1535 [55:40<06:24,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1377/1535 [55:42<06:24,  2.44s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1378/1535 [55:45<06:21,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1379/1535 [55:47<06:18,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1535 [55:50<06:15,  2.43s/it]                                                   {'loss': 0.3082, 'grad_norm': 0.2667210102081299, 'learning_rate': 2.0652882990944534e-05, 'epoch': 4.49}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1535 [55:50<06:15,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1381/1535 [55:52<06:13,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1382/1535 [55:54<06:10,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1383/1535 [55:57<06:08,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1384/1535 [55:59<06:05,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1385/1535 [56:02<06:03,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1386/1535 [56:04<06:00,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1387/1535 [56:07<05:58,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1388/1535 [56:09<05:55,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1389/1535 [56:11<05:53,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1390/1535 [56:14<05:51,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1391/1535 [56:16<05:48,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1392/1535 [56:19<05:46,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1393/1535 [56:21<05:43,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1394/1535 [56:24<05:41,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1395/1535 [56:26<05:38,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1396/1535 [56:28<05:36,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1397/1535 [56:31<05:34,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1398/1535 [56:33<05:31,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1399/1535 [56:36<05:29,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1535 [56:38<05:26,  2.42s/it]                                                   {'loss': 0.3158, 'grad_norm': 0.28500425815582275, 'learning_rate': 1.586432190603626e-05, 'epoch': 4.55}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1535 [56:38<05:26,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1401/1535 [56:40<05:24,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1402/1535 [56:43<05:21,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1403/1535 [56:45<05:20,  2.43s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1404/1535 [56:48<05:17,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1405/1535 [56:50<05:15,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1406/1535 [56:53<05:12,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1407/1535 [56:55<05:10,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1408/1535 [56:57<05:07,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1409/1535 [57:00<05:05,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1410/1535 [57:02<05:02,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1411/1535 [57:05<05:00,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1412/1535 [57:07<04:57,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1413/1535 [57:10<04:55,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1414/1535 [57:12<04:53,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1415/1535 [57:14<04:50,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1416/1535 [57:17<04:48,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1417/1535 [57:19<04:45,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1418/1535 [57:22<04:43,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1419/1535 [57:24<04:41,  2.43s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1420/1535 [57:27<04:38,  2.43s/it]                                                   {'loss': 0.2959, 'grad_norm': 0.28616198897361755, 'learning_rate': 1.1688584942696367e-05, 'epoch': 4.62}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1420/1535 [57:27<04:38,  2.43s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1421/1535 [57:29<04:36,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1422/1535 [57:31<04:33,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1423/1535 [57:34<04:31,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1424/1535 [57:36<04:28,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1425/1535 [57:39<04:26,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1426/1535 [57:41<04:23,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1427/1535 [57:43<04:21,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1428/1535 [57:46<04:18,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1429/1535 [57:48<04:17,  2.43s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1430/1535 [57:51<04:14,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1431/1535 [57:53<04:12,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1432/1535 [57:56<04:10,  2.43s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1433/1535 [57:58<04:07,  2.43s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1434/1535 [58:00<04:04,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1435/1535 [58:03<04:02,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1436/1535 [58:05<03:59,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1437/1535 [58:08<03:57,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1438/1535 [58:10<03:54,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1439/1535 [58:13<03:52,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1440/1535 [58:15<03:49,  2.42s/it]                                                   {'loss': 0.3064, 'grad_norm': 0.2694741487503052, 'learning_rate': 8.136601628441876e-06, 'epoch': 4.68}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1440/1535 [58:15<03:49,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1441/1535 [58:17<03:47,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1442/1535 [58:20<03:45,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1443/1535 [58:22<03:42,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1444/1535 [58:25<03:40,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1445/1535 [58:27<03:37,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1446/1535 [58:30<03:36,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1447/1535 [58:32<03:33,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1448/1535 [58:34<03:31,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1449/1535 [58:37<03:28,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1450/1535 [58:39<03:25,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1451/1535 [58:42<03:23,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1452/1535 [58:44<03:20,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1453/1535 [58:46<03:18,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1454/1535 [58:49<03:16,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1455/1535 [58:51<03:13,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1456/1535 [58:54<03:11,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1457/1535 [58:56<03:08,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1458/1535 [58:59<03:06,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1459/1535 [59:01<03:03,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1460/1535 [59:03<03:01,  2.42s/it]                                                   {'loss': 0.314, 'grad_norm': 0.30857518315315247, 'learning_rate': 5.217668884921506e-06, 'epoch': 4.75}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1460/1535 [59:03<03:01,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1461/1535 [59:06<02:59,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1462/1535 [59:08<02:56,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1463/1535 [59:11<02:54,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1464/1535 [59:13<02:51,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1465/1535 [59:16<02:49,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1466/1535 [59:18<02:46,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1467/1535 [59:20<02:44,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1468/1535 [59:23<02:42,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1469/1535 [59:25<02:39,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1470/1535 [59:28<02:37,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1471/1535 [59:30<02:34,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1472/1535 [59:32<02:32,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1473/1535 [59:35<02:30,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1474/1535 [59:37<02:27,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1475/1535 [59:40<02:25,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1476/1535 [59:42<02:22,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1477/1535 [59:45<02:20,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1478/1535 [59:47<02:18,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1479/1535 [59:49<02:15,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1480/1535 [59:52<02:13,  2.42s/it]                                                   {'loss': 0.3023, 'grad_norm': 0.30392852425575256, 'learning_rate': 2.9394266942558978e-06, 'epoch': 4.81}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1480/1535 [59:52<02:13,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1481/1535 [59:54<02:10,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1482/1535 [59:57<02:08,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1483/1535 [59:59<02:05,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1484/1535 [1:00:02<02:03,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1485/1535 [1:00:04<02:01,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1486/1535 [1:00:06<01:58,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1487/1535 [1:00:09<01:56,  2.43s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1488/1535 [1:00:11<01:54,  2.43s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1489/1535 [1:00:14<01:51,  2.43s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1490/1535 [1:00:16<01:49,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1491/1535 [1:00:19<01:46,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1492/1535 [1:00:21<01:44,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1493/1535 [1:00:23<01:41,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1494/1535 [1:00:26<01:39,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1495/1535 [1:00:28<01:36,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1496/1535 [1:00:31<01:34,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1497/1535 [1:00:33<01:31,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1498/1535 [1:00:35<01:29,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1499/1535 [1:00:38<01:27,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1500/1535 [1:00:40<01:24,  2.42s/it]                                                     {'loss': 0.3001, 'grad_norm': 0.33405908942222595, 'learning_rate': 1.3078381022336715e-06, 'epoch': 4.88}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1500/1535 [1:00:40<01:24,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1501/1535 [1:00:43<01:22,  2.43s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1502/1535 [1:00:45<01:20,  2.43s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1503/1535 [1:00:48<01:17,  2.43s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1504/1535 [1:00:50<01:15,  2.43s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1505/1535 [1:00:52<01:12,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1506/1535 [1:00:55<01:10,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1507/1535 [1:00:57<01:07,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1508/1535 [1:01:00<01:05,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1509/1535 [1:01:02<01:02,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1510/1535 [1:01:05<01:00,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1511/1535 [1:01:07<00:58,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1512/1535 [1:01:09<00:55,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1513/1535 [1:01:12<00:53,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1514/1535 [1:01:14<00:50,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1515/1535 [1:01:17<00:48,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1516/1535 [1:01:19<00:46,  2.44s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1517/1535 [1:01:22<00:43,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1518/1535 [1:01:24<00:41,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1519/1535 [1:01:26<00:38,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1520/1535 [1:01:29<00:36,  2.42s/it]                                                     {'loss': 0.2817, 'grad_norm': 0.2866583466529846, 'learning_rate': 3.271736107015033e-07, 'epoch': 4.94}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1520/1535 [1:01:29<00:36,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1521/1535 [1:01:31<00:33,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1522/1535 [1:01:34<00:31,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1523/1535 [1:01:36<00:29,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1524/1535 [1:01:38<00:26,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1525/1535 [1:01:41<00:24,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1526/1535 [1:01:43<00:21,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1527/1535 [1:01:46<00:19,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1528/1535 [1:01:48<00:16,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1529/1535 [1:01:51<00:14,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1530/1535 [1:01:53<00:12,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1531/1535 [1:01:55<00:09,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1532/1535 [1:01:58<00:07,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1533/1535 [1:02:00<00:04,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1534/1535 [1:02:03<00:02,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1535/1535 [1:02:05<00:00,  2.42s/it][INFO|trainer.py:2231] 2024-05-25 06:17:04,997 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 3735.9759, 'train_samples_per_second': 3.291, 'train_steps_per_second': 0.411, 'train_loss': 0.4406219469996151, 'epoch': 4.99}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1535/1535 [1:02:05<00:00,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1535/1535 [1:02:05<00:00,  2.43s/it]
***** train metrics *****
  epoch                    =       4.99
  train_loss               =     0.4406
  train_runtime            = 1:02:15.97
  train_samples_per_second =      3.291
  train_steps_per_second   =      0.411
[INFO|trainer.py:3203] 2024-05-25 06:17:05,002 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/extractiveness_then_length
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-05-25 06:17:05,637 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:17:05,639 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 06:17:06,160 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:17:06,163 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 06:17:06,211 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 06:17:06,211 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/special_tokens_map.json
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:471] 2024-05-25 06:17:06,544 >> Configuration saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/final_merged_model/config.json
[INFO|configuration_utils.py:697] 2024-05-25 06:17:06,545 >> Configuration saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/final_merged_model/generation_config.json
[INFO|modeling_utils.py:2474] 2024-05-25 06:17:13,267 >> Model weights saved in /scratch/tathagato/adapter_experiments/extractiveness_then_length/final_merged_model/model.safetensors
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.034 MB uploadedwandb: - 0.006 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb: | 0.038 MB of 0.038 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb: train/learning_rate ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 1.567843226180649e+17
wandb:              train/epoch 4.99
wandb:        train/global_step 1535
wandb:          train/grad_norm 0.28666
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.2817
wandb:               train_loss 0.44062
wandb:            train_runtime 3735.9759
wandb: train_samples_per_second 3.291
wandb:   train_steps_per_second 0.411
wandb: 
wandb: üöÄ View run firm-haze-101 at: https://wandb.ai/ihub-drug-discovery/huggingface/runs/3zrk9vyz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ihub-drug-discovery/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240525_051452-3zrk9vyz/logs
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-05-25 06:17:46 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 06:17:46 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 06:17:46 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 06:17:46 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0005,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/tathagato/adapter_experiments/topic_then_length/runs/May25_06-17-46_gnode081,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=20,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/tathagato/adapter_experiments/topic_then_length,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/tathagato/adapter_experiments/topic_then_length,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=400,
save_strategy=steps,
save_total_limit=400,
seed=0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
2024-05-25 06:17:46 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'v_proj', 'k_proj', 'q_proj', 'o_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
2024-05-25 06:17:46 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1 distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:726] 2024-05-25 06:17:46,989 >> loading configuration file config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:17:46,994 >> Model config LlamaConfig {
  "_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": false,
  "vocab_size": 32000
}

[INFO|quantizer_bnb_4bit.py:247] 2024-05-25 06:17:47,103 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[WARNING|modeling_utils.py:3058] 2024-05-25 06:17:47,104 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:3283] 2024-05-25 06:17:47,104 >> loading weights file model.safetensors from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors
[INFO|modeling_utils.py:1417] 2024-05-25 06:17:47,124 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:928] 2024-05-25 06:17:47,128 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[WARNING|modeling_utils.py:3058] 2024-05-25 06:17:47,433 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 06:17:47,447 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 06:17:47,499 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:4024] 2024-05-25 06:17:50,279 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-05-25 06:17:50,280 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-05-25 06:17:50,510 >> loading configuration file generation_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json
[INFO|configuration_utils.py:928] 2024-05-25 06:17:50,511 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

loading model from : /scratch/tathagato/adapter_experiments/topic/topic
[INFO|tokenization_utils_base.py:2084] 2024-05-25 06:17:51,310 >> loading file tokenizer.model from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-05-25 06:17:51,310 >> loading file tokenizer.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 06:17:51,310 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-05-25 06:17:51,310 >> loading file special_tokens_map.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 06:17:51,310 >> loading file tokenizer_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json
loading model from : /scratch/tathagato/adapter_experiments/topic/topic
loading model from : /scratch/tathagato/adapter_experiments/topic/topic
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
loading model from : /scratch/tathagato/adapter_experiments/topic/topic
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
train dataset size 4278
test dataset size 554
4278
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Spawning 10 processes
2024-05-25 06:17:54 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
train dataset size 4278
test dataset size 554
4278
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
train dataset size 4278
test dataset size 554
4278
Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:14:49,  1.05s/ examples]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]train dataset size 4278
test dataset size 554
4278
Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 429/4278 [00:01<00:09, 389.78 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñâ        | 853/4278 [00:01<00:04, 810.26 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  26%|‚ñà‚ñà‚ñå       | 1091/4278 [00:01<00:03, 799.55 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:01<00:03, 940.96 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  36%|‚ñà‚ñà‚ñà‚ñã      | 1554/4278 [00:02<00:02, 911.44 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:15:08,  1.05s/ examples]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:07, 505.62 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 708.76 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:14:36,  1.05s/ examples]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2123/4278 [00:02<00:01, 1125.09 examples/s]Applying chat template to train_sft (num_proc=10):  16%|‚ñà‚ñå        | 684/4278 [00:01<00:06, 583.63 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:07, 484.55 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:21:57,  1.15s/ examples]Applying chat template to train_sft (num_proc=10):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2385/4278 [00:03<00:02, 935.36 examples/s] Applying chat template to train_sft (num_proc=10):  15%|‚ñà‚ñç        | 629/4278 [00:01<00:07, 504.61 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:06, 514.13 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:08, 470.10 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2568/4278 [00:03<00:01, 1022.43 examples/s]Applying chat template to train_sft (num_proc=10):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2824/4278 [00:03<00:01, 987.60 examples/s] Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:06, 546.24 examples/s]Applying chat template to train_sft (num_proc=10):  16%|‚ñà‚ñå        | 686/4278 [00:01<00:06, 548.04 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:02<00:04, 680.33 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:03<00:01, 1069.36 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:02<00:03, 971.82 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 830.83 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:02<00:06, 492.10 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:02<00:01, 1178.73 examples/s]Applying chat template to train_sft (num_proc=10):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3216/4278 [00:04<00:01, 762.27 examples/s] Applying chat template to train_sft (num_proc=10):  36%|‚ñà‚ñà‚ñà‚ñå      | 1528/4278 [00:02<00:03, 754.24 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/4278 [00:04<00:01, 844.36 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:02<00:04, 673.10 examples/s]Applying chat template to train_sft (num_proc=10):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2356/4278 [00:03<00:02, 921.27 examples/s] Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:04, 640.97 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:03<00:02, 789.01 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 735.55 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:03<00:01, 1136.22 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:03<00:02, 1068.68 examples/s]Applying chat template to train_sft (num_proc=10):  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1937/4278 [00:03<00:04, 559.43 examples/s]Applying chat template to train_sft (num_proc=10):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3637/4278 [00:05<00:01, 515.66 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2141/4278 [00:03<00:03, 632.83 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 936.72 examples/s]Applying chat template to train_sft (num_proc=10):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2371/4278 [00:03<00:02, 929.38 examples/s] Applying chat template to train_sft (num_proc=10):  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2468/4278 [00:03<00:02, 893.19 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 766.25 examples/s]
Concatenating 10 shards
2024-05-25 06:17:59 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Applying chat template to train_sft (num_proc=10):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3243/4278 [00:04<00:01, 745.98 examples/s] Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:03<00:02, 833.39 examples/s]Applying chat template to train_sft (num_proc=10):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2806/4278 [00:04<00:01, 853.49 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:04<00:01, 940.66 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:01, 705.00 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:04<00:01, 899.36 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1026.50 examples/s]Applying chat template to train_sft (num_proc=10):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3218/4278 [00:04<00:01, 835.74 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:04<00:00, 1004.69 examples/s]Spawning 10 processes
2024-05-25 06:18:00 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 4034/4278 [00:05<00:00, 828.98 examples/s] Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:04<00:00, 1320.94 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3425/4278 [00:05<00:01, 735.39 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:05<00:00, 1107.38 examples/s]Applying chat template to train_sft (num_proc=10):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4110/4278 [00:04<00:00, 1184.20 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 746.54 examples/s]
Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<04:22,  2.11 examples/s]Applying chat template to train_sft (num_proc=10):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4074/4278 [00:05<00:00, 1058.09 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:03, 126.01 examples/s]Applying chat template to test_sft (num_proc=10):  31%|‚ñà‚ñà‚ñà       | 169/554 [00:00<00:01, 303.95 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 802.59 examples/s] 
Applying chat template to test_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 279/554 [00:00<00:00, 480.82 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 733.38 examples/s] 
Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 389/554 [00:01<00:00, 541.34 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 503.40 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 348.61 examples/s]
Concatenating 10 shards
2024-05-25 06:18:02 - INFO - datasets.arrow_dataset - Concatenating 10 shards
tokenizer padding side left
Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:09,  1.79 examples/s]Applying chat template to test_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 168/554 [00:00<00:01, 296.48 examples/s]Using custom data configuration default-8a159e0651bd4009
2024-05-25 06:18:02 - INFO - datasets.builder - Using custom data configuration default-8a159e0651bd4009
Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
2024-05-25 06:18:02 - INFO - datasets.info - Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
Overwrite dataset info from restored data version if exists.
2024-05-25 06:18:02 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
2024-05-25 06:18:02 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0)
2024-05-25 06:18:02 - INFO - datasets.builder - Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0)
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
2024-05-25 06:18:02 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-8a159e0651bd4009/0.0.0
Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:01, 291.93 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 297.25 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<06:18,  1.46 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 390/554 [00:01<00:00, 449.41 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<07:24,  1.24 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:05, 86.25 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 500/554 [00:01<00:00, 524.76 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 112/554 [00:00<00:02, 166.86 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:00, 360.51 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 341.40 examples/s]
Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 226/554 [00:01<00:01, 286.65 examples/s]Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 334/554 [00:01<00:00, 411.31 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 335/554 [00:01<00:00, 369.34 examples/s]Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 445/554 [00:01<00:00, 430.15 examples/s]Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 445/554 [00:01<00:00, 476.27 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 334.80 examples/s]
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 321.04 examples/s]
tokenizer padding side left
tokenizer padding side left
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
2024-05-25 06:18:04 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
[INFO|trainer.py:607] 2024-05-25 06:18:07,139 >> Using auto half precision backend
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:1969] 2024-05-25 06:18:07,402 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-05-25 06:18:07,402 >>   Num examples = 2,459
[INFO|trainer.py:1971] 2024-05-25 06:18:07,402 >>   Num Epochs = 5
[INFO|trainer.py:1972] 2024-05-25 06:18:07,402 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-05-25 06:18:07,402 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-05-25 06:18:07,402 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-05-25 06:18:07,402 >>   Total optimization steps = 1,535
[INFO|trainer.py:1978] 2024-05-25 06:18:07,404 >>   Number of trainable parameters = 4,505,600
[INFO|integration_utils.py:723] 2024-05-25 06:18:07,467 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: roy3 (ihub-drug-discovery). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home2/tathagato/summarization/MACSum/experiments/wandb/run-20240525_061813-mzcv67nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-snowflake-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ihub-drug-discovery/huggingface
wandb: üöÄ View run at https://wandb.ai/ihub-drug-discovery/huggingface/runs/mzcv67nv
  0%|          | 0/1535 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1535 [00:02<1:03:18,  2.48s/it]  0%|          | 2/1535 [00:04<1:02:08,  2.43s/it]  0%|          | 3/1535 [00:07<1:01:43,  2.42s/it]  0%|          | 4/1535 [00:09<1:01:29,  2.41s/it]  0%|          | 5/1535 [00:12<1:01:23,  2.41s/it]  0%|          | 6/1535 [00:14<1:01:21,  2.41s/it]  0%|          | 7/1535 [00:16<1:01:18,  2.41s/it]  1%|          | 8/1535 [00:19<1:01:15,  2.41s/it]  1%|          | 9/1535 [00:21<1:01:42,  2.43s/it]  1%|          | 10/1535 [00:24<1:01:30,  2.42s/it]  1%|          | 11/1535 [00:26<1:01:21,  2.42s/it]  1%|          | 12/1535 [00:29<1:01:54,  2.44s/it]  1%|          | 13/1535 [00:31<1:01:57,  2.44s/it]  1%|          | 14/1535 [00:33<1:01:39,  2.43s/it]  1%|          | 15/1535 [00:36<1:01:26,  2.43s/it]  1%|          | 16/1535 [00:38<1:01:18,  2.42s/it]  1%|          | 17/1535 [00:41<1:01:11,  2.42s/it]  1%|          | 18/1535 [00:43<1:01:05,  2.42s/it]  1%|          | 19/1535 [00:45<1:01:01,  2.42s/it]  1%|‚ñè         | 20/1535 [00:48<1:00:57,  2.41s/it]                                                   {'loss': 0.995, 'grad_norm': 0.4360886216163635, 'learning_rate': 3.2573289902280134e-05, 'epoch': 0.07}
  1%|‚ñè         | 20/1535 [00:48<1:00:57,  2.41s/it]  1%|‚ñè         | 21/1535 [00:50<1:00:55,  2.41s/it]  1%|‚ñè         | 22/1535 [00:53<1:00:51,  2.41s/it]  1%|‚ñè         | 23/1535 [00:55<1:00:48,  2.41s/it]  2%|‚ñè         | 24/1535 [00:58<1:00:46,  2.41s/it]  2%|‚ñè         | 25/1535 [01:00<1:00:44,  2.41s/it]  2%|‚ñè         | 26/1535 [01:02<1:00:55,  2.42s/it]  2%|‚ñè         | 27/1535 [01:05<1:00:51,  2.42s/it]  2%|‚ñè         | 28/1535 [01:07<1:00:45,  2.42s/it]  2%|‚ñè         | 29/1535 [01:10<1:00:55,  2.43s/it]  2%|‚ñè         | 30/1535 [01:12<1:00:47,  2.42s/it]  2%|‚ñè         | 31/1535 [01:15<1:00:42,  2.42s/it]  2%|‚ñè         | 32/1535 [01:17<1:00:38,  2.42s/it]  2%|‚ñè         | 33/1535 [01:19<1:00:33,  2.42s/it]  2%|‚ñè         | 34/1535 [01:22<1:00:28,  2.42s/it]  2%|‚ñè         | 35/1535 [01:24<1:00:25,  2.42s/it]  2%|‚ñè         | 36/1535 [01:27<1:00:24,  2.42s/it]  2%|‚ñè         | 37/1535 [01:29<1:00:22,  2.42s/it]  2%|‚ñè         | 38/1535 [01:31<1:00:18,  2.42s/it]  3%|‚ñé         | 39/1535 [01:34<1:00:15,  2.42s/it]  3%|‚ñé         | 40/1535 [01:36<1:00:13,  2.42s/it]                                                   {'loss': 0.922, 'grad_norm': 0.3298640847206116, 'learning_rate': 6.514657980456027e-05, 'epoch': 0.13}
  3%|‚ñé         | 40/1535 [01:36<1:00:13,  2.42s/it]  3%|‚ñé         | 41/1535 [01:39<1:00:13,  2.42s/it]  3%|‚ñé         | 42/1535 [01:41<1:00:24,  2.43s/it]  3%|‚ñé         | 43/1535 [01:44<1:00:17,  2.42s/it]  3%|‚ñé         | 44/1535 [01:46<1:00:11,  2.42s/it]  3%|‚ñé         | 45/1535 [01:48<1:00:08,  2.42s/it]  3%|‚ñé         | 46/1535 [01:51<1:00:04,  2.42s/it]  3%|‚ñé         | 47/1535 [01:53<1:00:00,  2.42s/it]  3%|‚ñé         | 48/1535 [01:56<59:59,  2.42s/it]    3%|‚ñé         | 49/1535 [01:58<59:56,  2.42s/it]  3%|‚ñé         | 50/1535 [02:00<59:54,  2.42s/it]  3%|‚ñé         | 51/1535 [02:03<59:50,  2.42s/it]  3%|‚ñé         | 52/1535 [02:05<59:48,  2.42s/it]  3%|‚ñé         | 53/1535 [02:08<59:48,  2.42s/it]  4%|‚ñé         | 54/1535 [02:10<59:51,  2.43s/it]  4%|‚ñé         | 55/1535 [02:13<59:46,  2.42s/it]  4%|‚ñé         | 56/1535 [02:15<1:00:13,  2.44s/it]  4%|‚ñé         | 57/1535 [02:18<1:00:01,  2.44s/it]  4%|‚ñç         | 58/1535 [02:20<59:52,  2.43s/it]    4%|‚ñç         | 59/1535 [02:22<59:44,  2.43s/it]  4%|‚ñç         | 60/1535 [02:25<59:38,  2.43s/it]                                                 {'loss': 0.9145, 'grad_norm': 0.3781942129135132, 'learning_rate': 9.771986970684039e-05, 'epoch': 0.2}
  4%|‚ñç         | 60/1535 [02:25<59:38,  2.43s/it]  4%|‚ñç         | 61/1535 [02:27<59:34,  2.43s/it]  4%|‚ñç         | 62/1535 [02:30<59:30,  2.42s/it]  4%|‚ñç         | 63/1535 [02:32<59:26,  2.42s/it]  4%|‚ñç         | 64/1535 [02:34<59:22,  2.42s/it]  4%|‚ñç         | 65/1535 [02:37<59:19,  2.42s/it]  4%|‚ñç         | 66/1535 [02:39<59:16,  2.42s/it]  4%|‚ñç         | 67/1535 [02:42<59:13,  2.42s/it]  4%|‚ñç         | 68/1535 [02:44<59:28,  2.43s/it]  4%|‚ñç         | 69/1535 [02:47<59:20,  2.43s/it]  5%|‚ñç         | 70/1535 [02:49<59:17,  2.43s/it]  5%|‚ñç         | 71/1535 [02:51<59:11,  2.43s/it]  5%|‚ñç         | 72/1535 [02:54<59:06,  2.42s/it]  5%|‚ñç         | 73/1535 [02:56<59:02,  2.42s/it]  5%|‚ñç         | 74/1535 [02:59<58:58,  2.42s/it]  5%|‚ñç         | 75/1535 [03:01<58:56,  2.42s/it]  5%|‚ñç         | 76/1535 [03:04<58:52,  2.42s/it]  5%|‚ñå         | 77/1535 [03:06<58:49,  2.42s/it]  5%|‚ñå         | 78/1535 [03:08<58:47,  2.42s/it]  5%|‚ñå         | 79/1535 [03:11<58:44,  2.42s/it]  5%|‚ñå         | 80/1535 [03:13<58:43,  2.42s/it]                                                 {'loss': 0.9484, 'grad_norm': 0.3839850425720215, 'learning_rate': 0.00013029315960912054, 'epoch': 0.26}
  5%|‚ñå         | 80/1535 [03:13<58:43,  2.42s/it]  5%|‚ñå         | 81/1535 [03:16<58:41,  2.42s/it]  5%|‚ñå         | 82/1535 [03:18<58:38,  2.42s/it]  5%|‚ñå         | 83/1535 [03:21<58:45,  2.43s/it]  5%|‚ñå         | 84/1535 [03:23<58:39,  2.43s/it]  6%|‚ñå         | 85/1535 [03:25<58:35,  2.42s/it]  6%|‚ñå         | 86/1535 [03:28<58:31,  2.42s/it]  6%|‚ñå         | 87/1535 [03:30<58:26,  2.42s/it]  6%|‚ñå         | 88/1535 [03:33<58:23,  2.42s/it]  6%|‚ñå         | 89/1535 [03:35<58:21,  2.42s/it]  6%|‚ñå         | 90/1535 [03:37<58:18,  2.42s/it]  6%|‚ñå         | 91/1535 [03:40<58:15,  2.42s/it]  6%|‚ñå         | 92/1535 [03:42<58:13,  2.42s/it]  6%|‚ñå         | 93/1535 [03:45<58:10,  2.42s/it]  6%|‚ñå         | 94/1535 [03:47<58:07,  2.42s/it]  6%|‚ñå         | 95/1535 [03:50<58:05,  2.42s/it]  6%|‚ñã         | 96/1535 [03:52<58:03,  2.42s/it]  6%|‚ñã         | 97/1535 [03:54<58:00,  2.42s/it]  6%|‚ñã         | 98/1535 [03:57<58:02,  2.42s/it]  6%|‚ñã         | 99/1535 [03:59<57:59,  2.42s/it]  7%|‚ñã         | 100/1535 [04:02<57:56,  2.42s/it]                                                  {'loss': 0.9398, 'grad_norm': 0.3480112552642822, 'learning_rate': 0.00016286644951140063, 'epoch': 0.33}
  7%|‚ñã         | 100/1535 [04:02<57:56,  2.42s/it]  7%|‚ñã         | 101/1535 [04:04<57:53,  2.42s/it]  7%|‚ñã         | 102/1535 [04:07<57:50,  2.42s/it]  7%|‚ñã         | 103/1535 [04:09<57:47,  2.42s/it]  7%|‚ñã         | 104/1535 [04:11<57:44,  2.42s/it]  7%|‚ñã         | 105/1535 [04:14<57:42,  2.42s/it]  7%|‚ñã         | 106/1535 [04:16<57:39,  2.42s/it]  7%|‚ñã         | 107/1535 [04:19<57:36,  2.42s/it]  7%|‚ñã         | 108/1535 [04:21<57:34,  2.42s/it]  7%|‚ñã         | 109/1535 [04:23<57:32,  2.42s/it]  7%|‚ñã         | 110/1535 [04:26<57:29,  2.42s/it]  7%|‚ñã         | 111/1535 [04:28<57:30,  2.42s/it]  7%|‚ñã         | 112/1535 [04:31<57:43,  2.43s/it]  7%|‚ñã         | 113/1535 [04:33<57:35,  2.43s/it]  7%|‚ñã         | 114/1535 [04:36<57:28,  2.43s/it]  7%|‚ñã         | 115/1535 [04:38<57:23,  2.43s/it]  8%|‚ñä         | 116/1535 [04:40<57:19,  2.42s/it]  8%|‚ñä         | 117/1535 [04:43<57:15,  2.42s/it]  8%|‚ñä         | 118/1535 [04:45<57:13,  2.42s/it]  8%|‚ñä         | 119/1535 [04:48<57:09,  2.42s/it]  8%|‚ñä         | 120/1535 [04:50<57:05,  2.42s/it]                                                  {'loss': 0.9182, 'grad_norm': 0.3665439784526825, 'learning_rate': 0.00019543973941368078, 'epoch': 0.39}
  8%|‚ñä         | 120/1535 [04:50<57:05,  2.42s/it]  8%|‚ñä         | 121/1535 [04:53<57:03,  2.42s/it]  8%|‚ñä         | 122/1535 [04:55<57:00,  2.42s/it]  8%|‚ñä         | 123/1535 [04:57<56:56,  2.42s/it]  8%|‚ñä         | 124/1535 [05:00<56:53,  2.42s/it]  8%|‚ñä         | 125/1535 [05:02<56:50,  2.42s/it]  8%|‚ñä         | 126/1535 [05:05<57:18,  2.44s/it]  8%|‚ñä         | 127/1535 [05:07<57:06,  2.43s/it]  8%|‚ñä         | 128/1535 [05:10<56:57,  2.43s/it]  8%|‚ñä         | 129/1535 [05:12<56:50,  2.43s/it]  8%|‚ñä         | 130/1535 [05:14<56:45,  2.42s/it]  9%|‚ñä         | 131/1535 [05:17<56:40,  2.42s/it]  9%|‚ñä         | 132/1535 [05:19<56:37,  2.42s/it]  9%|‚ñä         | 133/1535 [05:22<56:33,  2.42s/it]  9%|‚ñä         | 134/1535 [05:24<56:30,  2.42s/it]  9%|‚ñâ         | 135/1535 [05:27<56:27,  2.42s/it]  9%|‚ñâ         | 136/1535 [05:29<56:24,  2.42s/it]  9%|‚ñâ         | 137/1535 [05:31<56:21,  2.42s/it]  9%|‚ñâ         | 138/1535 [05:34<56:19,  2.42s/it]  9%|‚ñâ         | 139/1535 [05:36<56:33,  2.43s/it]  9%|‚ñâ         | 140/1535 [05:39<56:25,  2.43s/it]                                                  {'loss': 0.9011, 'grad_norm': 0.32195115089416504, 'learning_rate': 0.0002280130293159609, 'epoch': 0.46}
  9%|‚ñâ         | 140/1535 [05:39<56:25,  2.43s/it]  9%|‚ñâ         | 141/1535 [05:41<56:29,  2.43s/it]  9%|‚ñâ         | 142/1535 [05:43<56:21,  2.43s/it]  9%|‚ñâ         | 143/1535 [05:46<56:15,  2.43s/it]  9%|‚ñâ         | 144/1535 [05:48<56:10,  2.42s/it]  9%|‚ñâ         | 145/1535 [05:51<56:06,  2.42s/it] 10%|‚ñâ         | 146/1535 [05:53<56:02,  2.42s/it] 10%|‚ñâ         | 147/1535 [05:56<55:59,  2.42s/it] 10%|‚ñâ         | 148/1535 [05:58<55:56,  2.42s/it] 10%|‚ñâ         | 149/1535 [06:00<55:53,  2.42s/it] 10%|‚ñâ         | 150/1535 [06:03<55:50,  2.42s/it] 10%|‚ñâ         | 151/1535 [06:05<55:47,  2.42s/it] 10%|‚ñâ         | 152/1535 [06:08<55:46,  2.42s/it] 10%|‚ñâ         | 153/1535 [06:10<55:43,  2.42s/it] 10%|‚ñà         | 154/1535 [06:13<55:41,  2.42s/it] 10%|‚ñà         | 155/1535 [06:15<55:38,  2.42s/it] 10%|‚ñà         | 156/1535 [06:17<55:35,  2.42s/it] 10%|‚ñà         | 157/1535 [06:20<55:34,  2.42s/it] 10%|‚ñà         | 158/1535 [06:22<55:31,  2.42s/it] 10%|‚ñà         | 159/1535 [06:25<55:33,  2.42s/it] 10%|‚ñà         | 160/1535 [06:27<55:30,  2.42s/it]                                                  {'loss': 0.8921, 'grad_norm': 0.27384600043296814, 'learning_rate': 0.0002605863192182411, 'epoch': 0.52}
 10%|‚ñà         | 160/1535 [06:27<55:30,  2.42s/it] 10%|‚ñà         | 161/1535 [06:29<55:28,  2.42s/it] 11%|‚ñà         | 162/1535 [06:32<55:26,  2.42s/it] 11%|‚ñà         | 163/1535 [06:34<55:24,  2.42s/it] 11%|‚ñà         | 164/1535 [06:37<55:20,  2.42s/it] 11%|‚ñà         | 165/1535 [06:39<55:17,  2.42s/it] 11%|‚ñà         | 166/1535 [06:42<55:14,  2.42s/it] 11%|‚ñà         | 167/1535 [06:44<55:11,  2.42s/it] 11%|‚ñà         | 168/1535 [06:46<55:20,  2.43s/it] 11%|‚ñà         | 169/1535 [06:49<55:14,  2.43s/it] 11%|‚ñà         | 170/1535 [06:51<55:18,  2.43s/it] 11%|‚ñà         | 171/1535 [06:54<55:11,  2.43s/it] 11%|‚ñà         | 172/1535 [06:56<55:06,  2.43s/it] 11%|‚ñà‚ñè        | 173/1535 [06:59<55:01,  2.42s/it] 11%|‚ñà‚ñè        | 174/1535 [07:01<54:57,  2.42s/it] 11%|‚ñà‚ñè        | 175/1535 [07:03<54:55,  2.42s/it] 11%|‚ñà‚ñè        | 176/1535 [07:06<54:51,  2.42s/it] 12%|‚ñà‚ñè        | 177/1535 [07:08<54:48,  2.42s/it] 12%|‚ñà‚ñè        | 178/1535 [07:11<54:46,  2.42s/it] 12%|‚ñà‚ñè        | 179/1535 [07:13<54:42,  2.42s/it] 12%|‚ñà‚ñè        | 180/1535 [07:16<54:40,  2.42s/it]                                                  {'loss': 0.8794, 'grad_norm': 0.273595929145813, 'learning_rate': 0.0002931596091205212, 'epoch': 0.59}
 12%|‚ñà‚ñè        | 180/1535 [07:16<54:40,  2.42s/it] 12%|‚ñà‚ñè        | 181/1535 [07:18<54:47,  2.43s/it] 12%|‚ñà‚ñè        | 182/1535 [07:20<54:41,  2.43s/it] 12%|‚ñà‚ñè        | 183/1535 [07:23<54:37,  2.42s/it] 12%|‚ñà‚ñè        | 184/1535 [07:25<54:33,  2.42s/it] 12%|‚ñà‚ñè        | 185/1535 [07:28<54:30,  2.42s/it] 12%|‚ñà‚ñè        | 186/1535 [07:30<54:27,  2.42s/it] 12%|‚ñà‚ñè        | 187/1535 [07:32<54:24,  2.42s/it] 12%|‚ñà‚ñè        | 188/1535 [07:35<54:21,  2.42s/it] 12%|‚ñà‚ñè        | 189/1535 [07:37<54:18,  2.42s/it] 12%|‚ñà‚ñè        | 190/1535 [07:40<54:16,  2.42s/it] 12%|‚ñà‚ñè        | 191/1535 [07:42<54:13,  2.42s/it] 13%|‚ñà‚ñé        | 192/1535 [07:45<54:11,  2.42s/it] 13%|‚ñà‚ñé        | 193/1535 [07:47<54:09,  2.42s/it] 13%|‚ñà‚ñé        | 194/1535 [07:49<54:06,  2.42s/it] 13%|‚ñà‚ñé        | 195/1535 [07:52<54:31,  2.44s/it] 13%|‚ñà‚ñé        | 196/1535 [07:54<54:20,  2.44s/it] 13%|‚ñà‚ñé        | 197/1535 [07:57<54:12,  2.43s/it] 13%|‚ñà‚ñé        | 198/1535 [07:59<54:05,  2.43s/it] 13%|‚ñà‚ñé        | 199/1535 [08:02<54:00,  2.43s/it] 13%|‚ñà‚ñé        | 200/1535 [08:04<53:56,  2.42s/it]                                                  {'loss': 0.869, 'grad_norm': 0.5656566619873047, 'learning_rate': 0.00032573289902280126, 'epoch': 0.65}
 13%|‚ñà‚ñé        | 200/1535 [08:04<53:56,  2.42s/it] 13%|‚ñà‚ñé        | 201/1535 [08:06<53:53,  2.42s/it] 13%|‚ñà‚ñé        | 202/1535 [08:09<53:49,  2.42s/it] 13%|‚ñà‚ñé        | 203/1535 [08:11<53:46,  2.42s/it] 13%|‚ñà‚ñé        | 204/1535 [08:14<53:43,  2.42s/it] 13%|‚ñà‚ñé        | 205/1535 [08:16<53:40,  2.42s/it] 13%|‚ñà‚ñé        | 206/1535 [08:19<53:37,  2.42s/it] 13%|‚ñà‚ñé        | 207/1535 [08:21<53:35,  2.42s/it] 14%|‚ñà‚ñé        | 208/1535 [08:23<53:32,  2.42s/it] 14%|‚ñà‚ñé        | 209/1535 [08:26<53:30,  2.42s/it] 14%|‚ñà‚ñé        | 210/1535 [08:28<53:28,  2.42s/it] 14%|‚ñà‚ñé        | 211/1535 [08:31<53:25,  2.42s/it] 14%|‚ñà‚ñç        | 212/1535 [08:33<53:22,  2.42s/it] 14%|‚ñà‚ñç        | 213/1535 [08:35<53:20,  2.42s/it] 14%|‚ñà‚ñç        | 214/1535 [08:38<53:17,  2.42s/it] 14%|‚ñà‚ñç        | 215/1535 [08:40<53:14,  2.42s/it] 14%|‚ñà‚ñç        | 216/1535 [08:43<53:12,  2.42s/it] 14%|‚ñà‚ñç        | 217/1535 [08:45<53:10,  2.42s/it] 14%|‚ñà‚ñç        | 218/1535 [08:48<53:08,  2.42s/it] 14%|‚ñà‚ñç        | 219/1535 [08:50<53:05,  2.42s/it] 14%|‚ñà‚ñç        | 220/1535 [08:52<53:03,  2.42s/it]                                                  {'loss': 0.8115, 'grad_norm': 0.3522568941116333, 'learning_rate': 0.00035830618892508144, 'epoch': 0.72}
 14%|‚ñà‚ñç        | 220/1535 [08:52<53:03,  2.42s/it] 14%|‚ñà‚ñç        | 221/1535 [08:55<53:03,  2.42s/it] 14%|‚ñà‚ñç        | 222/1535 [08:57<53:11,  2.43s/it] 15%|‚ñà‚ñç        | 223/1535 [09:00<53:08,  2.43s/it] 15%|‚ñà‚ñç        | 224/1535 [09:02<53:04,  2.43s/it] 15%|‚ñà‚ñç        | 225/1535 [09:05<53:02,  2.43s/it] 15%|‚ñà‚ñç        | 226/1535 [09:07<52:59,  2.43s/it] 15%|‚ñà‚ñç        | 227/1535 [09:09<52:59,  2.43s/it] 15%|‚ñà‚ñç        | 228/1535 [09:12<53:10,  2.44s/it] 15%|‚ñà‚ñç        | 229/1535 [09:14<53:00,  2.44s/it] 15%|‚ñà‚ñç        | 230/1535 [09:17<52:55,  2.43s/it] 15%|‚ñà‚ñå        | 231/1535 [09:19<52:51,  2.43s/it] 15%|‚ñà‚ñå        | 232/1535 [09:22<52:46,  2.43s/it] 15%|‚ñà‚ñå        | 233/1535 [09:24<52:43,  2.43s/it] 15%|‚ñà‚ñå        | 234/1535 [09:26<52:40,  2.43s/it] 15%|‚ñà‚ñå        | 235/1535 [09:29<52:40,  2.43s/it] 15%|‚ñà‚ñå        | 236/1535 [09:31<52:39,  2.43s/it] 15%|‚ñà‚ñå        | 237/1535 [09:34<52:49,  2.44s/it] 16%|‚ñà‚ñå        | 238/1535 [09:36<52:41,  2.44s/it] 16%|‚ñà‚ñå        | 239/1535 [09:39<52:35,  2.43s/it] 16%|‚ñà‚ñå        | 240/1535 [09:41<52:29,  2.43s/it]                                                  {'loss': 0.8413, 'grad_norm': 0.28503161668777466, 'learning_rate': 0.0003892508143322476, 'epoch': 0.78}
 16%|‚ñà‚ñå        | 240/1535 [09:41<52:29,  2.43s/it] 16%|‚ñà‚ñå        | 241/1535 [09:44<52:29,  2.43s/it] 16%|‚ñà‚ñå        | 242/1535 [09:46<52:23,  2.43s/it] 16%|‚ñà‚ñå        | 243/1535 [09:48<52:19,  2.43s/it] 16%|‚ñà‚ñå        | 244/1535 [09:51<52:16,  2.43s/it] 16%|‚ñà‚ñå        | 245/1535 [09:53<52:12,  2.43s/it] 16%|‚ñà‚ñå        | 246/1535 [09:56<52:10,  2.43s/it] 16%|‚ñà‚ñå        | 247/1535 [09:58<52:08,  2.43s/it] 16%|‚ñà‚ñå        | 248/1535 [10:01<52:05,  2.43s/it] 16%|‚ñà‚ñå        | 249/1535 [10:03<52:01,  2.43s/it] 16%|‚ñà‚ñã        | 250/1535 [10:05<52:04,  2.43s/it] 16%|‚ñà‚ñã        | 251/1535 [10:08<52:00,  2.43s/it] 16%|‚ñà‚ñã        | 252/1535 [10:10<51:57,  2.43s/it] 16%|‚ñà‚ñã        | 253/1535 [10:13<51:54,  2.43s/it] 17%|‚ñà‚ñã        | 254/1535 [10:15<51:54,  2.43s/it] 17%|‚ñà‚ñã        | 255/1535 [10:18<51:51,  2.43s/it] 17%|‚ñà‚ñã        | 256/1535 [10:20<51:47,  2.43s/it] 17%|‚ñà‚ñã        | 257/1535 [10:22<51:56,  2.44s/it] 17%|‚ñà‚ñã        | 258/1535 [10:25<51:49,  2.43s/it] 17%|‚ñà‚ñã        | 259/1535 [10:27<51:43,  2.43s/it] 17%|‚ñà‚ñã        | 260/1535 [10:30<51:39,  2.43s/it]                                                  {'loss': 0.8306, 'grad_norm': 0.3644712269306183, 'learning_rate': 0.0004218241042345277, 'epoch': 0.85}
 17%|‚ñà‚ñã        | 260/1535 [10:30<51:39,  2.43s/it] 17%|‚ñà‚ñã        | 261/1535 [10:32<51:35,  2.43s/it] 17%|‚ñà‚ñã        | 262/1535 [10:35<51:32,  2.43s/it] 17%|‚ñà‚ñã        | 263/1535 [10:37<51:29,  2.43s/it] 17%|‚ñà‚ñã        | 264/1535 [10:39<51:25,  2.43s/it] 17%|‚ñà‚ñã        | 265/1535 [10:42<51:48,  2.45s/it] 17%|‚ñà‚ñã        | 266/1535 [10:44<51:37,  2.44s/it] 17%|‚ñà‚ñã        | 267/1535 [10:47<51:30,  2.44s/it] 17%|‚ñà‚ñã        | 268/1535 [10:49<51:24,  2.43s/it] 18%|‚ñà‚ñä        | 269/1535 [10:52<51:21,  2.43s/it] 18%|‚ñà‚ñä        | 270/1535 [10:54<51:17,  2.43s/it] 18%|‚ñà‚ñä        | 271/1535 [10:57<51:23,  2.44s/it] 18%|‚ñà‚ñä        | 272/1535 [10:59<51:17,  2.44s/it] 18%|‚ñà‚ñä        | 273/1535 [11:01<51:13,  2.44s/it] 18%|‚ñà‚ñä        | 274/1535 [11:04<51:07,  2.43s/it] 18%|‚ñà‚ñä        | 275/1535 [11:06<51:04,  2.43s/it] 18%|‚ñà‚ñä        | 276/1535 [11:09<51:00,  2.43s/it] 18%|‚ñà‚ñä        | 277/1535 [11:11<50:56,  2.43s/it] 18%|‚ñà‚ñä        | 278/1535 [11:14<51:07,  2.44s/it] 18%|‚ñà‚ñä        | 279/1535 [11:16<50:59,  2.44s/it] 18%|‚ñà‚ñä        | 280/1535 [11:18<50:53,  2.43s/it]                                                  {'loss': 0.8388, 'grad_norm': 0.5672602653503418, 'learning_rate': 0.0004543973941368078, 'epoch': 0.91}
 18%|‚ñà‚ñä        | 280/1535 [11:18<50:53,  2.43s/it] 18%|‚ñà‚ñä        | 281/1535 [11:21<50:51,  2.43s/it] 18%|‚ñà‚ñä        | 282/1535 [11:23<50:47,  2.43s/it] 18%|‚ñà‚ñä        | 283/1535 [11:26<50:42,  2.43s/it] 19%|‚ñà‚ñä        | 284/1535 [11:28<50:38,  2.43s/it] 19%|‚ñà‚ñä        | 285/1535 [11:31<50:36,  2.43s/it] 19%|‚ñà‚ñä        | 286/1535 [11:33<50:34,  2.43s/it] 19%|‚ñà‚ñä        | 287/1535 [11:35<50:31,  2.43s/it] 19%|‚ñà‚ñâ        | 288/1535 [11:38<50:29,  2.43s/it] 19%|‚ñà‚ñâ        | 289/1535 [11:40<50:27,  2.43s/it] 19%|‚ñà‚ñâ        | 290/1535 [11:43<50:24,  2.43s/it] 19%|‚ñà‚ñâ        | 291/1535 [11:45<50:21,  2.43s/it] 19%|‚ñà‚ñâ        | 292/1535 [11:48<50:18,  2.43s/it] 19%|‚ñà‚ñâ        | 293/1535 [11:50<50:15,  2.43s/it] 19%|‚ñà‚ñâ        | 294/1535 [11:52<50:13,  2.43s/it] 19%|‚ñà‚ñâ        | 295/1535 [11:55<50:11,  2.43s/it] 19%|‚ñà‚ñâ        | 296/1535 [11:57<50:08,  2.43s/it] 19%|‚ñà‚ñâ        | 297/1535 [12:00<50:05,  2.43s/it] 19%|‚ñà‚ñâ        | 298/1535 [12:02<50:03,  2.43s/it] 19%|‚ñà‚ñâ        | 299/1535 [12:05<50:00,  2.43s/it] 20%|‚ñà‚ñâ        | 300/1535 [12:07<50:14,  2.44s/it]                                                  {'loss': 0.8518, 'grad_norm': 0.4071104824542999, 'learning_rate': 0.00048697068403908794, 'epoch': 0.98}
 20%|‚ñà‚ñâ        | 300/1535 [12:07<50:14,  2.44s/it] 20%|‚ñà‚ñâ        | 301/1535 [12:09<50:07,  2.44s/it] 20%|‚ñà‚ñâ        | 302/1535 [12:12<50:00,  2.43s/it] 20%|‚ñà‚ñâ        | 303/1535 [12:14<49:55,  2.43s/it] 20%|‚ñà‚ñâ        | 304/1535 [12:17<49:52,  2.43s/it] 20%|‚ñà‚ñâ        | 305/1535 [12:19<49:49,  2.43s/it] 20%|‚ñà‚ñâ        | 306/1535 [12:22<49:45,  2.43s/it] 20%|‚ñà‚ñà        | 307/1535 [12:24<49:47,  2.43s/it] 20%|‚ñà‚ñà        | 308/1535 [12:26<49:46,  2.43s/it] 20%|‚ñà‚ñà        | 309/1535 [12:29<49:41,  2.43s/it] 20%|‚ñà‚ñà        | 310/1535 [12:31<49:39,  2.43s/it] 20%|‚ñà‚ñà        | 311/1535 [12:34<49:34,  2.43s/it] 20%|‚ñà‚ñà        | 312/1535 [12:36<49:29,  2.43s/it] 20%|‚ñà‚ñà        | 313/1535 [12:39<49:25,  2.43s/it] 20%|‚ñà‚ñà        | 314/1535 [12:41<49:25,  2.43s/it] 21%|‚ñà‚ñà        | 315/1535 [12:44<49:34,  2.44s/it] 21%|‚ñà‚ñà        | 316/1535 [12:46<49:26,  2.43s/it] 21%|‚ñà‚ñà        | 317/1535 [12:48<49:22,  2.43s/it] 21%|‚ñà‚ñà        | 318/1535 [12:51<49:17,  2.43s/it] 21%|‚ñà‚ñà        | 319/1535 [12:53<49:14,  2.43s/it] 21%|‚ñà‚ñà        | 320/1535 [12:56<49:22,  2.44s/it]                                                  {'loss': 0.7975, 'grad_norm': 0.421007364988327, 'learning_rate': 0.0004998822010531848, 'epoch': 1.04}
 21%|‚ñà‚ñà        | 320/1535 [12:56<49:22,  2.44s/it] 21%|‚ñà‚ñà        | 321/1535 [12:58<49:17,  2.44s/it] 21%|‚ñà‚ñà        | 322/1535 [13:01<49:10,  2.43s/it] 21%|‚ñà‚ñà        | 323/1535 [13:03<49:05,  2.43s/it] 21%|‚ñà‚ñà        | 324/1535 [13:05<49:00,  2.43s/it] 21%|‚ñà‚ñà        | 325/1535 [13:08<48:59,  2.43s/it] 21%|‚ñà‚ñà        | 326/1535 [13:10<48:56,  2.43s/it] 21%|‚ñà‚ñà‚ñè       | 327/1535 [13:13<48:52,  2.43s/it] 21%|‚ñà‚ñà‚ñè       | 328/1535 [13:15<48:48,  2.43s/it] 21%|‚ñà‚ñà‚ñè       | 329/1535 [13:18<48:57,  2.44s/it] 21%|‚ñà‚ñà‚ñè       | 330/1535 [13:20<48:54,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 331/1535 [13:22<48:48,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 332/1535 [13:25<48:44,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 333/1535 [13:27<48:40,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 334/1535 [13:30<48:54,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 335/1535 [13:32<48:46,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 336/1535 [13:35<48:40,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 337/1535 [13:37<48:34,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 338/1535 [13:39<48:28,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 339/1535 [13:42<48:25,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 340/1535 [13:44<48:21,  2.43s/it]                                                  {'loss': 0.8239, 'grad_norm': 0.33487609028816223, 'learning_rate': 0.0004991627205825621, 'epoch': 1.11}
 22%|‚ñà‚ñà‚ñè       | 340/1535 [13:44<48:21,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 341/1535 [13:47<48:19,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 342/1535 [13:49<48:18,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 343/1535 [13:52<48:18,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 344/1535 [13:54<48:24,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 345/1535 [13:56<48:18,  2.44s/it] 23%|‚ñà‚ñà‚ñé       | 346/1535 [13:59<48:11,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 347/1535 [14:01<48:08,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 348/1535 [14:04<48:25,  2.45s/it] 23%|‚ñà‚ñà‚ñé       | 349/1535 [14:06<48:14,  2.44s/it] 23%|‚ñà‚ñà‚ñé       | 350/1535 [14:09<48:04,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 351/1535 [14:11<48:00,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 352/1535 [14:14<47:56,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 353/1535 [14:16<47:51,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 354/1535 [14:18<47:48,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 355/1535 [14:21<47:44,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 356/1535 [14:23<47:40,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 357/1535 [14:26<47:37,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 358/1535 [14:28<47:40,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 359/1535 [14:30<47:36,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 360/1535 [14:33<47:32,  2.43s/it]                                                  {'loss': 0.7519, 'grad_norm': 0.4019373953342438, 'learning_rate': 0.0004978751063614575, 'epoch': 1.17}
 23%|‚ñà‚ñà‚ñé       | 360/1535 [14:33<47:32,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 361/1535 [14:35<47:31,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 362/1535 [14:38<47:28,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 363/1535 [14:40<47:24,  2.43s/it] 24%|‚ñà‚ñà‚ñé       | 364/1535 [14:43<47:20,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 365/1535 [14:45<47:19,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 366/1535 [14:47<47:18,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 367/1535 [14:50<47:18,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 368/1535 [14:52<47:15,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 369/1535 [14:55<47:11,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 370/1535 [14:57<47:07,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 371/1535 [15:00<47:04,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 372/1535 [15:02<47:02,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 373/1535 [15:05<47:11,  2.44s/it] 24%|‚ñà‚ñà‚ñç       | 374/1535 [15:07<47:05,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 375/1535 [15:09<47:01,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 376/1535 [15:12<46:57,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 377/1535 [15:14<46:52,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 378/1535 [15:17<46:52,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 379/1535 [15:19<46:48,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 380/1535 [15:22<46:42,  2.43s/it]                                                  {'loss': 0.7089, 'grad_norm': 0.3233855366706848, 'learning_rate': 0.0004958872212869485, 'epoch': 1.24}
 25%|‚ñà‚ñà‚ñç       | 380/1535 [15:22<46:42,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 381/1535 [15:24<46:38,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 382/1535 [15:26<46:34,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 383/1535 [15:29<46:29,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 384/1535 [15:31<46:26,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 385/1535 [15:34<46:22,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 386/1535 [15:36<46:20,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 387/1535 [15:38<46:16,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 388/1535 [15:41<46:14,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 389/1535 [15:43<46:13,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 390/1535 [15:46<46:10,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 391/1535 [15:48<46:07,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 392/1535 [15:51<46:04,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 393/1535 [15:53<46:01,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 394/1535 [15:55<45:59,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 395/1535 [15:58<45:56,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 396/1535 [16:00<45:54,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 397/1535 [16:03<45:51,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 398/1535 [16:05<45:49,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 399/1535 [16:07<45:47,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 400/1535 [16:10<45:44,  2.42s/it]                                                  {'loss': 0.7683, 'grad_norm': 0.4505038559436798, 'learning_rate': 0.0004932557537323291, 'epoch': 1.3}
 26%|‚ñà‚ñà‚ñå       | 400/1535 [16:10<45:44,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 06:34:39,842 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-400
[INFO|configuration_utils.py:726] 2024-05-25 06:34:41,198 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:34:41,203 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 06:34:41,290 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 06:34:41,290 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-400/special_tokens_map.json
 26%|‚ñà‚ñà‚ñå       | 401/1535 [16:14<54:48,  2.90s/it] 26%|‚ñà‚ñà‚ñå       | 402/1535 [16:16<52:01,  2.76s/it] 26%|‚ñà‚ñà‚ñã       | 403/1535 [16:19<50:04,  2.65s/it] 26%|‚ñà‚ñà‚ñã       | 404/1535 [16:21<49:05,  2.60s/it] 26%|‚ñà‚ñà‚ñã       | 405/1535 [16:24<48:00,  2.55s/it] 26%|‚ñà‚ñà‚ñã       | 406/1535 [16:26<47:13,  2.51s/it] 27%|‚ñà‚ñà‚ñã       | 407/1535 [16:28<46:40,  2.48s/it] 27%|‚ñà‚ñà‚ñã       | 408/1535 [16:31<46:16,  2.46s/it] 27%|‚ñà‚ñà‚ñã       | 409/1535 [16:33<45:58,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 410/1535 [16:36<45:46,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 411/1535 [16:38<45:35,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 412/1535 [16:41<45:28,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 413/1535 [16:43<45:21,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 414/1535 [16:45<45:16,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 415/1535 [16:48<45:56,  2.46s/it] 27%|‚ñà‚ñà‚ñã       | 416/1535 [16:50<45:39,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 417/1535 [16:53<45:26,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 418/1535 [16:55<45:20,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 419/1535 [16:58<45:13,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 420/1535 [17:00<45:06,  2.43s/it]                                                  {'loss': 0.7405, 'grad_norm': 0.5857354998588562, 'learning_rate': 0.0004899875912715296, 'epoch': 1.37}
 27%|‚ñà‚ñà‚ñã       | 420/1535 [17:00<45:06,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 421/1535 [17:02<45:01,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 422/1535 [17:05<44:57,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 423/1535 [17:07<44:53,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 424/1535 [17:10<44:49,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 425/1535 [17:12<44:45,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 426/1535 [17:15<44:42,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 427/1535 [17:17<44:41,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 428/1535 [17:19<44:38,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 429/1535 [17:22<44:35,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 430/1535 [17:24<44:45,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 431/1535 [17:27<44:38,  2.43s/it] 28%|‚ñà‚ñà‚ñä       | 432/1535 [17:29<44:33,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 433/1535 [17:32<44:29,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 434/1535 [17:34<44:25,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 435/1535 [17:36<44:21,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 436/1535 [17:39<44:19,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 437/1535 [17:41<44:16,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 438/1535 [17:44<44:13,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 439/1535 [17:46<44:10,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 440/1535 [17:48<44:08,  2.42s/it]                                                  {'loss': 0.7827, 'grad_norm': 0.3485219180583954, 'learning_rate': 0.0004860912879566511, 'epoch': 1.43}
 29%|‚ñà‚ñà‚ñä       | 440/1535 [17:48<44:08,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 441/1535 [17:51<44:06,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 442/1535 [17:53<44:03,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 443/1535 [17:56<44:02,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 444/1535 [17:58<43:59,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 445/1535 [18:01<43:56,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 446/1535 [18:03<44:03,  2.43s/it] 29%|‚ñà‚ñà‚ñâ       | 447/1535 [18:05<43:57,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 448/1535 [18:08<43:52,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 449/1535 [18:10<43:49,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 450/1535 [18:13<43:45,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 451/1535 [18:15<43:42,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 452/1535 [18:18<43:40,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 453/1535 [18:20<43:38,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 454/1535 [18:22<43:35,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 455/1535 [18:25<43:32,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 456/1535 [18:27<43:29,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 457/1535 [18:30<43:27,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 458/1535 [18:32<43:24,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 459/1535 [18:34<43:32,  2.43s/it] 30%|‚ñà‚ñà‚ñâ       | 460/1535 [18:37<43:27,  2.43s/it]                                                  {'loss': 0.7592, 'grad_norm': 0.38668933510780334, 'learning_rate': 0.000481577041928685, 'epoch': 1.5}
 30%|‚ñà‚ñà‚ñâ       | 460/1535 [18:37<43:27,  2.43s/it] 30%|‚ñà‚ñà‚ñà       | 461/1535 [18:39<43:23,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 462/1535 [18:42<43:18,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 463/1535 [18:44<43:15,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 464/1535 [18:47<43:12,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 465/1535 [18:49<43:08,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 466/1535 [18:51<43:06,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 467/1535 [18:54<43:03,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 468/1535 [18:56<43:00,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 469/1535 [18:59<42:57,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 470/1535 [19:01<42:55,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 471/1535 [19:03<42:53,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 472/1535 [19:06<42:54,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 473/1535 [19:08<43:06,  2.44s/it] 31%|‚ñà‚ñà‚ñà       | 474/1535 [19:11<42:58,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 475/1535 [19:13<42:52,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 476/1535 [19:16<42:47,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 477/1535 [19:18<42:42,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 478/1535 [19:20<42:38,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 479/1535 [19:23<42:35,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 480/1535 [19:25<42:32,  2.42s/it]                                                  {'loss': 0.7399, 'grad_norm': 0.4345325827598572, 'learning_rate': 0.000476456668725012, 'epoch': 1.56}
 31%|‚ñà‚ñà‚ñà‚ñè      | 480/1535 [19:25<42:32,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 481/1535 [19:28<42:30,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 482/1535 [19:30<42:27,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 483/1535 [19:33<42:24,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 484/1535 [19:35<42:22,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 485/1535 [19:37<42:19,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 486/1535 [19:40<42:16,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 487/1535 [19:42<42:23,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 488/1535 [19:45<42:20,  2.43s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 489/1535 [19:47<42:15,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 490/1535 [19:50<42:11,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 491/1535 [19:52<42:07,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 492/1535 [19:54<42:04,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 493/1535 [19:57<42:00,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 494/1535 [19:59<41:58,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 495/1535 [20:02<41:55,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 496/1535 [20:04<41:53,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 497/1535 [20:06<41:50,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 498/1535 [20:09<41:48,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 499/1535 [20:11<41:45,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 500/1535 [20:14<41:44,  2.42s/it]                                                  {'loss': 0.7225, 'grad_norm': 0.3290550410747528, 'learning_rate': 0.0004707435703535453, 'epoch': 1.63}
 33%|‚ñà‚ñà‚ñà‚ñé      | 500/1535 [20:14<41:44,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 501/1535 [20:16<41:47,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 502/1535 [20:19<41:42,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 503/1535 [20:21<41:39,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 504/1535 [20:23<41:35,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 505/1535 [20:26<41:32,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 506/1535 [20:28<41:29,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 507/1535 [20:31<41:26,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 508/1535 [20:33<41:24,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 509/1535 [20:36<41:21,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 510/1535 [20:38<41:19,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 511/1535 [20:40<41:16,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 512/1535 [20:43<41:13,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 513/1535 [20:45<41:12,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 514/1535 [20:48<41:09,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 515/1535 [20:50<41:14,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 516/1535 [20:52<41:10,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 517/1535 [20:55<41:06,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 518/1535 [20:57<41:02,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 519/1535 [21:00<40:58,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1535 [21:02<40:55,  2.42s/it]                                                  {'loss': 0.7036, 'grad_norm': 0.43005672097206116, 'learning_rate': 0.00046445270021446504, 'epoch': 1.69}
 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1535 [21:02<40:55,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 521/1535 [21:05<40:53,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 522/1535 [21:07<40:51,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 523/1535 [21:09<40:48,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 524/1535 [21:12<40:45,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 525/1535 [21:14<40:43,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 526/1535 [21:17<40:42,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 527/1535 [21:19<40:39,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 528/1535 [21:22<40:44,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 529/1535 [21:24<40:39,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 530/1535 [21:26<40:36,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 531/1535 [21:29<40:32,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 532/1535 [21:31<40:28,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 533/1535 [21:34<40:24,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 534/1535 [21:36<40:21,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 535/1535 [21:38<40:18,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 536/1535 [21:41<40:16,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 537/1535 [21:43<40:13,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 538/1535 [21:46<40:12,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 539/1535 [21:48<40:09,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1535 [21:51<40:06,  2.42s/it]                                                  {'loss': 0.6789, 'grad_norm': 0.42975887656211853, 'learning_rate': 0.00045760052396135386, 'epoch': 1.76}
 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1535 [21:51<40:06,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 541/1535 [21:53<40:04,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 542/1535 [21:55<40:01,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 543/1535 [21:58<40:14,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 544/1535 [22:00<40:07,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 545/1535 [22:03<40:01,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 546/1535 [22:05<40:04,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 547/1535 [22:08<39:57,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 548/1535 [22:10<39:53,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 549/1535 [22:12<39:48,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 550/1535 [22:15<39:45,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 551/1535 [22:17<39:41,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 552/1535 [22:20<39:38,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 553/1535 [22:22<39:35,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 554/1535 [22:24<39:32,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 555/1535 [22:27<39:30,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 556/1535 [22:29<39:33,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 557/1535 [22:32<39:28,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 558/1535 [22:34<39:25,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 559/1535 [22:37<39:22,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1535 [22:39<39:19,  2.42s/it]                                                  {'loss': 0.6908, 'grad_norm': 0.5068284869194031, 'learning_rate': 0.00045020497640417914, 'epoch': 1.82}
 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1535 [22:39<39:19,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 561/1535 [22:41<39:16,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 562/1535 [22:44<39:13,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 563/1535 [22:46<39:11,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 564/1535 [22:49<39:08,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 565/1535 [22:51<39:06,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 566/1535 [22:54<39:03,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 567/1535 [22:56<39:00,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 568/1535 [22:58<38:57,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 569/1535 [23:01<38:59,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 570/1535 [23:03<38:56,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 571/1535 [23:06<38:53,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 572/1535 [23:08<38:49,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 573/1535 [23:10<38:47,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 574/1535 [23:13<38:45,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 575/1535 [23:15<38:43,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 576/1535 [23:18<38:40,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 577/1535 [23:20<38:37,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 578/1535 [23:23<38:34,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 579/1535 [23:25<38:31,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1535 [23:27<38:28,  2.42s/it]                                                  {'loss': 0.6758, 'grad_norm': 0.4724443554878235, 'learning_rate': 0.0004422854145669198, 'epoch': 1.89}
 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1535 [23:27<38:28,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 581/1535 [23:30<38:26,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 582/1535 [23:32<38:24,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 583/1535 [23:35<38:21,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 584/1535 [23:37<38:19,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 585/1535 [23:40<38:23,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 586/1535 [23:42<38:18,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 587/1535 [23:44<38:14,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 588/1535 [23:47<38:13,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 589/1535 [23:49<38:10,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 590/1535 [23:52<38:06,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 591/1535 [23:54<38:03,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 592/1535 [23:56<38:01,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 593/1535 [23:59<37:58,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 594/1535 [24:01<37:55,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 595/1535 [24:04<37:53,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 596/1535 [24:06<37:50,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 597/1535 [24:09<37:48,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 598/1535 [24:11<37:53,  2.43s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 599/1535 [24:13<37:48,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1535 [24:16<37:44,  2.42s/it]                                                  {'loss': 0.7034, 'grad_norm': 0.526114821434021, 'learning_rate': 0.00043386256702270773, 'epoch': 1.95}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1535 [24:16<37:44,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 601/1535 [24:18<37:40,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 602/1535 [24:21<37:37,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 603/1535 [24:23<37:34,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 604/1535 [24:25<37:32,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 605/1535 [24:28<37:29,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 606/1535 [24:30<37:27,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 607/1535 [24:33<37:24,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 608/1535 [24:35<37:21,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 609/1535 [24:38<37:19,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 610/1535 [24:40<37:16,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 611/1535 [24:42<37:14,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 612/1535 [24:45<37:21,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 613/1535 [24:47<37:16,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 614/1535 [24:50<37:11,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 615/1535 [24:52<37:06,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 616/1535 [24:55<37:04,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 617/1535 [24:57<37:00,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 618/1535 [24:59<36:57,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 619/1535 [25:02<36:55,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1535 [25:04<36:52,  2.42s/it]                                                  {'loss': 0.6429, 'grad_norm': 0.39615413546562195, 'learning_rate': 0.0004249584796390903, 'epoch': 2.02}
 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1535 [25:04<36:52,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 621/1535 [25:07<36:50,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 622/1535 [25:09<36:47,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 623/1535 [25:11<36:44,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 624/1535 [25:14<36:43,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 625/1535 [25:16<36:40,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 626/1535 [25:19<36:44,  2.43s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 627/1535 [25:21<36:39,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 628/1535 [25:24<36:35,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 629/1535 [25:26<36:32,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 630/1535 [25:28<36:29,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 631/1535 [25:31<36:26,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 632/1535 [25:33<36:23,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 633/1535 [25:36<36:24,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 634/1535 [25:38<36:21,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 635/1535 [25:40<36:17,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 636/1535 [25:43<36:14,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 637/1535 [25:45<36:11,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 638/1535 [25:48<36:09,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 639/1535 [25:50<36:12,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1535 [25:53<36:08,  2.42s/it]                                                  {'loss': 0.5799, 'grad_norm': 0.45962774753570557, 'learning_rate': 0.000415596457875422, 'epoch': 2.08}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1535 [25:53<36:08,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 641/1535 [25:55<36:04,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 642/1535 [25:57<36:01,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 643/1535 [26:00<35:58,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 644/1535 [26:02<35:55,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 645/1535 [26:05<35:52,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 646/1535 [26:07<35:53,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 647/1535 [26:10<35:49,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 648/1535 [26:12<35:45,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 649/1535 [26:14<35:43,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 650/1535 [26:17<35:40,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 651/1535 [26:19<35:37,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 652/1535 [26:22<35:34,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 653/1535 [26:24<35:32,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 654/1535 [26:26<35:34,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 655/1535 [26:29<35:31,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 656/1535 [26:31<35:27,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 657/1535 [26:34<35:24,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 658/1535 [26:36<35:21,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 659/1535 [26:39<35:18,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1535 [26:41<35:15,  2.42s/it]                                                  {'loss': 0.6236, 'grad_norm': 0.4348863959312439, 'learning_rate': 0.00040580100578341385, 'epoch': 2.15}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1535 [26:41<35:15,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 661/1535 [26:43<35:13,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 662/1535 [26:46<35:11,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 663/1535 [26:48<35:08,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 664/1535 [26:51<35:06,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 665/1535 [26:53<35:03,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 666/1535 [26:55<35:01,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 667/1535 [26:58<35:01,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 668/1535 [27:00<34:58,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 669/1535 [27:03<34:55,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 670/1535 [27:05<34:52,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 671/1535 [27:08<34:49,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 672/1535 [27:10<34:47,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 673/1535 [27:12<34:44,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 674/1535 [27:15<34:41,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 675/1535 [27:17<34:40,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 676/1535 [27:20<34:37,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 677/1535 [27:22<34:35,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 678/1535 [27:25<34:32,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 679/1535 [27:27<34:29,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1535 [27:29<34:27,  2.42s/it]                                                  {'loss': 0.5749, 'grad_norm': 0.4455295503139496, 'learning_rate': 0.000395597761870501, 'epoch': 2.21}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1535 [27:29<34:27,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 681/1535 [27:32<34:25,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 682/1535 [27:34<34:44,  2.44s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 683/1535 [27:37<34:35,  2.44s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 684/1535 [27:39<34:28,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 685/1535 [27:42<34:22,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 686/1535 [27:44<34:17,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 687/1535 [27:46<34:13,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 688/1535 [27:49<34:10,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 689/1535 [27:51<34:07,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 690/1535 [27:54<34:04,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 691/1535 [27:56<34:02,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 692/1535 [27:58<33:59,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 693/1535 [28:01<33:56,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 694/1535 [28:03<33:53,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 695/1535 [28:06<33:51,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 696/1535 [28:08<33:48,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 697/1535 [28:11<33:46,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 698/1535 [28:13<33:43,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 699/1535 [28:15<33:41,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1535 [28:18<33:38,  2.42s/it]                                                  {'loss': 0.5641, 'grad_norm': 0.3939966559410095, 'learning_rate': 0.0003850134319938983, 'epoch': 2.28}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1535 [28:18<33:38,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 701/1535 [28:20<33:36,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 702/1535 [28:23<33:33,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 703/1535 [28:25<33:31,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 704/1535 [28:27<33:29,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 705/1535 [28:30<33:26,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 706/1535 [28:32<33:24,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 707/1535 [28:35<33:22,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 708/1535 [28:37<33:21,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 709/1535 [28:40<33:18,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 710/1535 [28:42<33:15,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 711/1535 [28:44<33:12,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 712/1535 [28:47<33:10,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 713/1535 [28:49<33:08,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 714/1535 [28:52<33:05,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 715/1535 [28:54<33:03,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 716/1535 [28:57<33:00,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 717/1535 [28:59<32:57,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 718/1535 [29:01<32:55,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 719/1535 [29:04<32:53,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1535 [29:06<32:50,  2.42s/it]                                                  {'loss': 0.5816, 'grad_norm': 0.5401895046234131, 'learning_rate': 0.0003740757194609865, 'epoch': 2.34}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1535 [29:06<32:50,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 721/1535 [29:09<32:48,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 722/1535 [29:11<32:45,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 723/1535 [29:13<32:43,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 724/1535 [29:16<32:47,  2.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 725/1535 [29:18<32:43,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 726/1535 [29:21<32:39,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 727/1535 [29:23<32:35,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 728/1535 [29:26<32:32,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 729/1535 [29:28<32:29,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 730/1535 [29:30<32:26,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 731/1535 [29:33<32:24,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 732/1535 [29:35<32:21,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 733/1535 [29:38<32:20,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 734/1535 [29:40<32:17,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 735/1535 [29:42<32:14,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 736/1535 [29:45<32:12,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 737/1535 [29:47<32:12,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 738/1535 [29:50<32:08,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 739/1535 [29:52<32:05,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1535 [29:55<32:02,  2.42s/it]                                                  {'loss': 0.5629, 'grad_norm': 0.48406514525413513, 'learning_rate': 0.00036281325251898323, 'epoch': 2.41}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1535 [29:55<32:02,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 741/1535 [29:57<32:00,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 742/1535 [29:59<31:57,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 743/1535 [30:02<31:55,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 744/1535 [30:04<31:53,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 745/1535 [30:07<31:50,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 746/1535 [30:09<31:47,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 747/1535 [30:11<31:45,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 748/1535 [30:14<31:42,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 749/1535 [30:16<31:40,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 750/1535 [30:19<31:37,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 751/1535 [30:21<31:47,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 752/1535 [30:24<31:41,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 753/1535 [30:26<31:36,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 754/1535 [30:28<31:31,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 755/1535 [30:31<31:29,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 756/1535 [30:33<31:25,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 757/1535 [30:36<31:22,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 758/1535 [30:38<31:19,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 759/1535 [30:41<31:17,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1535 [30:43<31:14,  2.42s/it]                                                  {'loss': 0.574, 'grad_norm': 0.591850221157074, 'learning_rate': 0.00035125550942368696, 'epoch': 2.47}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1535 [30:43<31:14,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 761/1535 [30:45<31:12,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 762/1535 [30:48<31:09,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 763/1535 [30:50<31:07,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 764/1535 [30:53<31:04,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 765/1535 [30:55<31:08,  2.43s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 766/1535 [30:58<31:03,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 767/1535 [31:00<31:00,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 768/1535 [31:02<30:56,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 769/1535 [31:05<30:54,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 770/1535 [31:07<30:50,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 771/1535 [31:10<30:48,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 772/1535 [31:12<30:45,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 773/1535 [31:14<30:42,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 774/1535 [31:17<30:39,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 775/1535 [31:19<30:37,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 776/1535 [31:22<30:35,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 777/1535 [31:24<30:32,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 778/1535 [31:27<30:31,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 779/1535 [31:29<30:28,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1535 [31:31<30:26,  2.42s/it]                                                  {'loss': 0.5451, 'grad_norm': 0.47976624965667725, 'learning_rate': 0.0003394327412834182, 'epoch': 2.54}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1535 [31:31<30:26,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 781/1535 [31:34<30:23,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 782/1535 [31:36<30:21,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 783/1535 [31:39<30:18,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 784/1535 [31:41<30:16,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 785/1535 [31:43<30:13,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 786/1535 [31:46<30:11,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 787/1535 [31:48<30:08,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 788/1535 [31:51<30:06,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 789/1535 [31:53<30:03,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 790/1535 [31:56<30:01,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 791/1535 [31:58<29:58,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 792/1535 [32:00<29:56,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 793/1535 [32:03<29:57,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 794/1535 [32:05<29:53,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 795/1535 [32:08<29:50,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 796/1535 [32:10<29:47,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 797/1535 [32:12<29:45,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 798/1535 [32:15<29:42,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 799/1535 [32:17<29:39,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1535 [32:20<29:37,  2.42s/it]                                                  {'loss': 0.5824, 'grad_norm': 0.5507333278656006, 'learning_rate': 0.0003273758928801043, 'epoch': 2.6}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1535 [32:20<29:37,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 06:50:49,707 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-800
[INFO|configuration_utils.py:726] 2024-05-25 06:50:51,189 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:50:51,192 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 06:50:52,144 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 06:50:52,146 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 06:50:52,197 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 06:50:52,197 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-800/special_tokens_map.json
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 801/1535 [32:25<39:12,  3.21s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 802/1535 [32:27<36:16,  2.97s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 803/1535 [32:30<34:12,  2.80s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 804/1535 [32:32<32:44,  2.69s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 805/1535 [32:34<31:42,  2.61s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 806/1535 [32:37<31:04,  2.56s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 807/1535 [32:39<30:36,  2.52s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 808/1535 [32:42<30:10,  2.49s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 809/1535 [32:44<29:52,  2.47s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 810/1535 [32:47<29:38,  2.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 811/1535 [32:49<29:28,  2.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 812/1535 [32:51<29:20,  2.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 813/1535 [32:54<29:14,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 814/1535 [32:56<29:09,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 815/1535 [32:59<29:04,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 816/1535 [33:01<29:00,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 817/1535 [33:04<28:57,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 818/1535 [33:06<28:54,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 819/1535 [33:08<28:52,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1535 [33:11<28:49,  2.42s/it]                                                  {'loss': 0.5513, 'grad_norm': 0.38561123609542847, 'learning_rate': 0.0003151165216747518, 'epoch': 2.67}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1535 [33:11<28:49,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 821/1535 [33:13<29:17,  2.46s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 822/1535 [33:16<29:05,  2.45s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 823/1535 [33:18<28:56,  2.44s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 824/1535 [33:21<28:49,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 825/1535 [33:23<28:44,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 826/1535 [33:25<28:39,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 827/1535 [33:28<28:35,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 828/1535 [33:30<28:32,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 829/1535 [33:33<28:29,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 830/1535 [33:35<28:26,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 831/1535 [33:38<28:23,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 832/1535 [33:40<28:20,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 833/1535 [33:42<28:17,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 834/1535 [33:45<28:15,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 835/1535 [33:47<28:15,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 836/1535 [33:50<28:12,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 837/1535 [33:52<28:09,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 838/1535 [33:54<28:06,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 839/1535 [33:57<28:03,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1535 [33:59<28:00,  2.42s/it]                                                  {'loss': 0.5499, 'grad_norm': 0.5119378566741943, 'learning_rate': 0.00030268671520929807, 'epoch': 2.73}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1535 [33:59<28:00,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 841/1535 [34:02<27:58,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 842/1535 [34:04<27:55,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 843/1535 [34:07<27:53,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 844/1535 [34:09<27:50,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 845/1535 [34:11<27:48,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 846/1535 [34:14<27:45,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 847/1535 [34:16<27:44,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 848/1535 [34:19<27:41,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 849/1535 [34:21<27:39,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 850/1535 [34:23<27:36,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 851/1535 [34:26<27:34,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 852/1535 [34:28<27:31,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 853/1535 [34:31<27:29,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 854/1535 [34:33<27:26,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 855/1535 [34:36<27:23,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 856/1535 [34:38<27:21,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 857/1535 [34:40<27:19,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 858/1535 [34:43<27:16,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 859/1535 [34:45<27:14,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1535 [34:48<27:11,  2.42s/it]                                                  {'loss': 0.5382, 'grad_norm': 0.4674646556377411, 'learning_rate': 0.0002901190071210361, 'epoch': 2.8}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1535 [34:48<27:11,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 861/1535 [34:50<27:09,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 862/1535 [34:52<27:07,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 863/1535 [34:55<27:10,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 864/1535 [34:57<27:06,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 865/1535 [35:00<27:02,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 866/1535 [35:02<26:59,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 867/1535 [35:05<26:56,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 868/1535 [35:07<26:53,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 869/1535 [35:09<26:50,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 870/1535 [35:12<26:48,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 871/1535 [35:14<26:45,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 872/1535 [35:17<26:43,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 873/1535 [35:19<26:40,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 874/1535 [35:22<26:38,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 875/1535 [35:24<26:35,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 876/1535 [35:26<26:33,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 877/1535 [35:29<26:30,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 878/1535 [35:31<26:30,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 879/1535 [35:34<26:27,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1535 [35:36<26:24,  2.42s/it]                                                  {'loss': 0.5698, 'grad_norm': 0.48014169931411743, 'learning_rate': 0.00027744629198943376, 'epoch': 2.86}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1535 [35:36<26:24,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 881/1535 [35:38<26:22,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 882/1535 [35:41<26:19,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 883/1535 [35:43<26:16,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 884/1535 [35:46<26:14,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 885/1535 [35:48<26:11,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 886/1535 [35:51<26:09,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 887/1535 [35:53<26:06,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 888/1535 [35:55<26:04,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 889/1535 [35:58<26:02,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 890/1535 [36:00<26:06,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 891/1535 [36:03<26:01,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 892/1535 [36:05<25:57,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 893/1535 [36:07<25:54,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 894/1535 [36:10<25:51,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 895/1535 [36:12<25:48,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 896/1535 [36:15<25:45,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 897/1535 [36:17<25:43,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 898/1535 [36:20<25:40,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 899/1535 [36:22<25:37,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1535 [36:24<25:35,  2.42s/it]                                                  {'loss': 0.5278, 'grad_norm': 0.4659918546676636, 'learning_rate': 0.0002647017392382271, 'epoch': 2.93}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1535 [36:24<25:35,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 901/1535 [36:27<25:33,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 902/1535 [36:29<25:30,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 903/1535 [36:32<25:28,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 904/1535 [36:34<25:25,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 905/1535 [36:37<25:23,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 906/1535 [36:39<25:21,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 907/1535 [36:41<25:21,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 908/1535 [36:44<25:18,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 909/1535 [36:46<25:15,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 910/1535 [36:49<25:12,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 911/1535 [36:51<25:09,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 912/1535 [36:53<25:06,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 913/1535 [36:56<25:04,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 914/1535 [36:58<25:01,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 915/1535 [37:01<24:59,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 916/1535 [37:03<24:56,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 917/1535 [37:06<24:55,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 918/1535 [37:08<24:52,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 919/1535 [37:10<24:50,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1535 [37:13<24:47,  2.42s/it]                                                  {'loss': 0.5232, 'grad_norm': 0.493157297372818, 'learning_rate': 0.000251918706318139, 'epoch': 2.99}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1535 [37:13<24:47,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 921/1535 [37:15<24:45,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 922/1535 [37:18<24:47,  2.43s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 923/1535 [37:20<24:43,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 924/1535 [37:22<24:39,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 925/1535 [37:25<24:36,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 926/1535 [37:27<24:33,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 927/1535 [37:30<24:30,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 928/1535 [37:32<24:28,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 929/1535 [37:35<24:25,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 930/1535 [37:37<24:23,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 931/1535 [37:39<24:20,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 932/1535 [37:42<24:22,  2.43s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 933/1535 [37:44<24:18,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 934/1535 [37:47<24:15,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 935/1535 [37:49<24:12,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 936/1535 [37:52<24:09,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 937/1535 [37:54<24:06,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 938/1535 [37:56<24:04,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 939/1535 [37:59<24:01,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1535 [38:01<23:59,  2.42s/it]                                                  {'loss': 0.5097, 'grad_norm': 0.45879796147346497, 'learning_rate': 0.00023913065139745916, 'epoch': 3.06}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1535 [38:01<23:59,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 941/1535 [38:04<23:56,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 942/1535 [38:06<23:54,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 943/1535 [38:08<23:51,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 944/1535 [38:11<23:49,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 945/1535 [38:13<23:48,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 946/1535 [38:16<23:45,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 947/1535 [38:18<23:42,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 948/1535 [38:21<23:40,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 949/1535 [38:23<23:37,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 950/1535 [38:25<23:34,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 951/1535 [38:28<23:36,  2.43s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 952/1535 [38:30<23:32,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 953/1535 [38:33<23:29,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 954/1535 [38:35<23:26,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 955/1535 [38:38<23:23,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 956/1535 [38:40<23:20,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 957/1535 [38:42<23:17,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 958/1535 [38:45<23:15,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 959/1535 [38:47<23:12,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 960/1535 [38:50<23:15,  2.43s/it]                                                  {'loss': 0.455, 'grad_norm': 0.45278510451316833, 'learning_rate': 0.00022637104578900538, 'epoch': 3.12}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 960/1535 [38:50<23:15,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 961/1535 [38:52<23:12,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 962/1535 [38:54<23:08,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 963/1535 [38:57<23:05,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 964/1535 [38:59<23:01,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 965/1535 [39:02<22:59,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 966/1535 [39:04<22:57,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 967/1535 [39:07<22:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 968/1535 [39:09<22:51,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 969/1535 [39:11<22:48,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 970/1535 [39:14<22:46,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 971/1535 [39:16<22:43,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 972/1535 [39:19<22:41,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 973/1535 [39:21<22:39,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 974/1535 [39:23<22:36,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 975/1535 [39:26<22:34,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 976/1535 [39:28<22:31,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 977/1535 [39:31<22:29,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 978/1535 [39:33<22:26,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 979/1535 [39:36<22:24,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 980/1535 [39:38<22:23,  2.42s/it]                                                  {'loss': 0.4357, 'grad_norm': 0.4659072160720825, 'learning_rate': 0.00021367328634268212, 'epoch': 3.19}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 980/1535 [39:38<22:23,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 981/1535 [39:40<22:20,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 982/1535 [39:43<22:17,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 983/1535 [39:45<22:15,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 984/1535 [39:48<22:12,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 985/1535 [39:50<22:10,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 986/1535 [39:53<22:09,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 987/1535 [39:55<22:06,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 988/1535 [39:57<22:03,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 989/1535 [40:00<22:00,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 990/1535 [40:02<21:58,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 991/1535 [40:05<21:55,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 992/1535 [40:07<21:53,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 993/1535 [40:09<21:50,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 994/1535 [40:12<21:49,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 995/1535 [40:14<21:46,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 996/1535 [40:17<21:43,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 997/1535 [40:19<21:41,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 998/1535 [40:22<21:38,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 999/1535 [40:24<21:36,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1000/1535 [40:26<21:33,  2.42s/it]                                                   {'loss': 0.457, 'grad_norm': 0.5247214436531067, 'learning_rate': 0.0002010706080329363, 'epoch': 3.25}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1000/1535 [40:26<21:33,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1001/1535 [40:29<21:31,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1002/1535 [40:31<21:36,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1003/1535 [40:34<21:31,  2.43s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1004/1535 [40:36<21:27,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1005/1535 [40:39<21:23,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1006/1535 [40:41<21:20,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1007/1535 [40:43<21:17,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1008/1535 [40:46<21:14,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1009/1535 [40:48<21:12,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1010/1535 [40:51<21:09,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1011/1535 [40:53<21:06,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1012/1535 [40:55<21:04,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1013/1535 [40:58<21:02,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1014/1535 [41:00<20:59,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1015/1535 [41:03<20:58,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1016/1535 [41:05<20:55,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1017/1535 [41:08<20:52,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1018/1535 [41:10<20:50,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1019/1535 [41:12<20:47,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1020/1535 [41:15<20:45,  2.42s/it]                                                   {'loss': 0.5105, 'grad_norm': 0.3935543894767761, 'learning_rate': 0.00018859599696990486, 'epoch': 3.32}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1020/1535 [41:15<20:45,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1021/1535 [41:17<20:43,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1022/1535 [41:20<20:40,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1023/1535 [41:22<20:38,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1024/1535 [41:24<20:35,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1025/1535 [41:27<20:33,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1026/1535 [41:29<20:30,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1027/1535 [41:32<20:28,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1028/1535 [41:34<20:25,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1029/1535 [41:37<20:29,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1030/1535 [41:39<20:25,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1031/1535 [41:41<20:21,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1032/1535 [41:44<20:18,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1033/1535 [41:46<20:15,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1034/1535 [41:49<20:12,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1035/1535 [41:51<20:09,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1036/1535 [41:54<20:07,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1037/1535 [41:56<20:04,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1038/1535 [41:58<20:02,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1039/1535 [42:01<19:59,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1535 [42:03<19:57,  2.42s/it]                                                   {'loss': 0.4544, 'grad_norm': 0.39053478837013245, 'learning_rate': 0.00017628210406193647, 'epoch': 3.38}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1535 [42:03<19:57,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1041/1535 [42:06<19:55,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1042/1535 [42:08<19:52,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1043/1535 [42:10<19:49,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1044/1535 [42:13<19:47,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1045/1535 [42:15<19:45,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1046/1535 [42:18<19:42,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1047/1535 [42:20<19:40,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1048/1535 [42:23<19:37,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1049/1535 [42:25<19:35,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1050/1535 [42:27<19:32,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1051/1535 [42:30<19:30,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1052/1535 [42:32<19:29,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1053/1535 [42:35<19:26,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1054/1535 [42:37<19:23,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1055/1535 [42:39<19:21,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1056/1535 [42:42<19:18,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1057/1535 [42:44<19:15,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1058/1535 [42:47<19:13,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1059/1535 [42:49<19:11,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1535 [42:52<19:08,  2.42s/it]                                                   {'loss': 0.4542, 'grad_norm': 0.4207398593425751, 'learning_rate': 0.00016416115955546705, 'epoch': 3.45}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1535 [42:52<19:08,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1061/1535 [42:54<19:06,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1062/1535 [42:56<19:05,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1063/1535 [42:59<19:02,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1064/1535 [43:01<18:59,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1065/1535 [43:04<18:57,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1066/1535 [43:06<18:54,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1067/1535 [43:09<18:55,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1068/1535 [43:11<18:51,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1069/1535 [43:13<18:48,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1070/1535 [43:16<18:45,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1071/1535 [43:18<18:46,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1072/1535 [43:21<18:42,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1073/1535 [43:23<18:39,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1074/1535 [43:25<18:36,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1075/1535 [43:28<18:33,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1076/1535 [43:30<18:30,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1077/1535 [43:33<18:28,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1078/1535 [43:35<18:25,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1079/1535 [43:38<18:22,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1535 [43:40<18:20,  2.42s/it]                                                   {'loss': 0.4475, 'grad_norm': 0.4223670959472656, 'learning_rate': 0.00015226488867593104, 'epoch': 3.51}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1535 [43:40<18:20,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1081/1535 [43:42<18:21,  2.43s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1082/1535 [43:45<18:18,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1083/1535 [43:47<18:14,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1084/1535 [43:50<18:13,  2.43s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1085/1535 [43:52<18:10,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1086/1535 [43:55<18:07,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1087/1535 [43:57<18:04,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1088/1535 [43:59<18:01,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1089/1535 [44:02<17:58,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1090/1535 [44:04<17:56,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1091/1535 [44:07<17:53,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1092/1535 [44:09<17:51,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1093/1535 [44:11<17:49,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1094/1535 [44:14<17:46,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1095/1535 [44:16<17:44,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1096/1535 [44:19<17:45,  2.43s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1097/1535 [44:21<17:41,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1098/1535 [44:24<17:38,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1099/1535 [44:26<17:39,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1535 [44:28<17:35,  2.43s/it]                                                   {'loss': 0.4446, 'grad_norm': 0.43527165055274963, 'learning_rate': 0.00014062442859050868, 'epoch': 3.58}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1535 [44:28<17:35,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1101/1535 [44:31<17:32,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1102/1535 [44:33<17:29,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1103/1535 [44:36<17:26,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1104/1535 [44:38<17:23,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1105/1535 [44:41<17:20,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1106/1535 [44:43<17:17,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1107/1535 [44:45<17:15,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1108/1535 [44:48<17:12,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1109/1535 [44:50<17:10,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1110/1535 [44:53<17:07,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1111/1535 [44:55<17:05,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1112/1535 [44:57<17:02,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1113/1535 [45:00<17:00,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1114/1535 [45:02<16:57,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1115/1535 [45:05<16:55,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1116/1535 [45:07<16:53,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1117/1535 [45:10<16:51,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1118/1535 [45:12<16:48,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1119/1535 [45:14<16:45,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1535 [45:17<16:43,  2.42s/it]                                                   {'loss': 0.4744, 'grad_norm': 0.46019798517227173, 'learning_rate': 0.00012927024691005096, 'epoch': 3.64}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1535 [45:17<16:43,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1121/1535 [45:19<16:41,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1122/1535 [45:22<16:38,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1123/1535 [45:24<16:36,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1124/1535 [45:27<16:33,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1125/1535 [45:29<16:34,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1126/1535 [45:31<16:31,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1127/1535 [45:34<16:28,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1128/1535 [45:36<16:25,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1129/1535 [45:39<16:22,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1130/1535 [45:41<16:19,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1131/1535 [45:43<16:17,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1132/1535 [45:46<16:14,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1133/1535 [45:48<16:12,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1134/1535 [45:51<16:09,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1135/1535 [45:53<16:07,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1136/1535 [45:56<16:04,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1137/1535 [45:58<16:02,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1138/1535 [46:00<15:59,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1139/1535 [46:03<15:57,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1535 [46:05<15:55,  2.42s/it]                                                   {'loss': 0.4446, 'grad_norm': 0.38022130727767944, 'learning_rate': 0.00011823206194349351, 'epoch': 3.71}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1535 [46:05<15:55,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1141/1535 [46:08<15:55,  2.43s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1142/1535 [46:10<15:52,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1143/1535 [46:13<15:49,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1144/1535 [46:15<15:46,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1145/1535 [46:17<15:43,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1146/1535 [46:20<15:40,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1147/1535 [46:22<15:38,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1148/1535 [46:25<15:35,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1149/1535 [46:27<15:33,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1150/1535 [46:29<15:30,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1151/1535 [46:32<15:28,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1152/1535 [46:34<15:26,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1153/1535 [46:37<15:23,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1154/1535 [46:39<15:21,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1155/1535 [46:42<15:18,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1156/1535 [46:44<15:16,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1157/1535 [46:46<15:13,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1158/1535 [46:49<15:11,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1159/1535 [46:51<15:09,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1535 [46:54<15:06,  2.42s/it]                                                   {'loss': 0.4185, 'grad_norm': 0.3914676010608673, 'learning_rate': 0.00010753876491348524, 'epoch': 3.77}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1535 [46:54<15:06,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1161/1535 [46:56<15:04,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1162/1535 [46:58<15:02,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1163/1535 [47:01<14:59,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1164/1535 [47:03<14:57,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1165/1535 [47:06<14:54,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1166/1535 [47:08<14:52,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1167/1535 [47:11<14:49,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1168/1535 [47:13<14:51,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1169/1535 [47:15<14:47,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1170/1535 [47:18<14:44,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1171/1535 [47:20<14:41,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1172/1535 [47:23<14:38,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1173/1535 [47:25<14:35,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1174/1535 [47:27<14:33,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1175/1535 [47:30<14:30,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1176/1535 [47:32<14:28,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1177/1535 [47:35<14:26,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1178/1535 [47:37<14:23,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1179/1535 [47:40<14:21,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1535 [47:42<14:18,  2.42s/it]                                                   {'loss': 0.4574, 'grad_norm': 0.46706423163414, 'learning_rate': 9.721834433682289e-05, 'epoch': 3.84}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1535 [47:42<14:18,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1181/1535 [47:44<14:16,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1182/1535 [47:47<14:15,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1183/1535 [47:49<14:14,  2.43s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1184/1535 [47:52<14:11,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1185/1535 [47:54<14:08,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1186/1535 [47:57<14:05,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1187/1535 [47:59<14:02,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1188/1535 [48:01<13:59,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1189/1535 [48:04<13:57,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1190/1535 [48:06<13:54,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1191/1535 [48:09<13:51,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1192/1535 [48:11<13:49,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1193/1535 [48:13<13:47,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1194/1535 [48:16<13:44,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1195/1535 [48:18<13:44,  2.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1196/1535 [48:21<13:41,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1197/1535 [48:23<13:38,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1198/1535 [48:26<13:35,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1199/1535 [48:28<13:33,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1535 [48:30<13:30,  2.42s/it]                                                   {'loss': 0.4456, 'grad_norm': 1.3085664510726929, 'learning_rate': 8.729781276761883e-05, 'epoch': 3.9}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1535 [48:30<13:30,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 07:07:00,400 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-1200
[INFO|configuration_utils.py:726] 2024-05-25 07:07:01,086 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:07:01,089 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 07:07:02,005 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:07:02,008 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 07:07:02,058 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 07:07:02,059 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_length/checkpoint-1200/special_tokens_map.json
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1201/1535 [48:35<16:26,  2.95s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1202/1535 [48:37<15:29,  2.79s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1203/1535 [48:39<14:49,  2.68s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1204/1535 [48:42<14:21,  2.60s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1205/1535 [48:44<14:00,  2.55s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1206/1535 [48:47<13:45,  2.51s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1207/1535 [48:49<13:34,  2.48s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1208/1535 [48:52<13:25,  2.46s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1209/1535 [48:54<13:18,  2.45s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1210/1535 [48:56<13:13,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1211/1535 [48:59<13:08,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1212/1535 [49:01<13:08,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1213/1535 [49:04<13:03,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1214/1535 [49:06<12:59,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1215/1535 [49:09<12:56,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1216/1535 [49:11<12:53,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1217/1535 [49:13<12:50,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1218/1535 [49:16<12:47,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1219/1535 [49:18<12:44,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1535 [49:21<12:42,  2.42s/it]                                                   {'loss': 0.4504, 'grad_norm': 0.41601622104644775, 'learning_rate': 7.780313609494147e-05, 'epoch': 3.97}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1535 [49:21<12:42,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1221/1535 [49:23<12:39,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1222/1535 [49:25<12:37,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1223/1535 [49:28<12:36,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1224/1535 [49:30<12:33,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1225/1535 [49:33<12:30,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1226/1535 [49:35<12:30,  2.43s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1227/1535 [49:38<12:27,  2.43s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1228/1535 [49:40<12:24,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1229/1535 [49:42<12:21,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1230/1535 [49:45<12:18,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1231/1535 [49:47<12:15,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1232/1535 [49:50<12:13,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1233/1535 [49:52<12:10,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1234/1535 [49:55<12:08,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1235/1535 [49:57<12:05,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1236/1535 [49:59<12:03,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1237/1535 [50:02<12:00,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1238/1535 [50:04<12:02,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1239/1535 [50:07<11:58,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1535 [50:09<11:55,  2.43s/it]                                                   {'loss': 0.4322, 'grad_norm': 0.40095609426498413, 'learning_rate': 6.875916557998654e-05, 'epoch': 4.03}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1535 [50:09<11:55,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1241/1535 [50:12<11:54,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1242/1535 [50:14<11:51,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1243/1535 [50:16<11:48,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1244/1535 [50:19<11:45,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1245/1535 [50:21<11:42,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1246/1535 [50:24<11:39,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1247/1535 [50:26<11:37,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1248/1535 [50:28<11:34,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1249/1535 [50:31<11:31,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1250/1535 [50:33<11:29,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1251/1535 [50:36<11:27,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1252/1535 [50:38<11:24,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1253/1535 [50:41<11:22,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1254/1535 [50:43<11:19,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1255/1535 [50:45<11:19,  2.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1256/1535 [50:48<11:16,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1257/1535 [50:50<11:13,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1258/1535 [50:53<11:10,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1259/1535 [50:55<11:07,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1535 [50:58<11:05,  2.42s/it]                                                   {'loss': 0.3806, 'grad_norm': 0.3949951231479645, 'learning_rate': 6.018957281066151e-05, 'epoch': 4.1}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1535 [50:58<11:05,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1261/1535 [51:00<11:03,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1262/1535 [51:02<11:00,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1263/1535 [51:05<10:57,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1264/1535 [51:07<10:57,  2.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1265/1535 [51:10<10:54,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1266/1535 [51:12<10:51,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1267/1535 [51:14<10:48,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1268/1535 [51:17<10:46,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1269/1535 [51:19<10:43,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1270/1535 [51:22<10:42,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1271/1535 [51:24<10:39,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1272/1535 [51:27<10:36,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1273/1535 [51:29<10:34,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1274/1535 [51:31<10:31,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1275/1535 [51:34<10:28,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1276/1535 [51:36<10:26,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1277/1535 [51:39<10:23,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1278/1535 [51:41<10:21,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1279/1535 [51:44<10:19,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1535 [51:46<10:17,  2.42s/it]                                                   {'loss': 0.4192, 'grad_norm': 0.35507866740226746, 'learning_rate': 5.2116787743835217e-05, 'epoch': 4.16}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1535 [51:46<10:17,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1281/1535 [51:48<10:15,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1282/1535 [51:51<10:12,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1283/1535 [51:53<10:09,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1284/1535 [51:56<10:10,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1285/1535 [51:58<10:06,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1286/1535 [52:00<10:03,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1287/1535 [52:03<10:00,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1288/1535 [52:05<09:58,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1289/1535 [52:08<09:55,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1290/1535 [52:10<09:52,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1291/1535 [52:13<09:50,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1292/1535 [52:15<09:47,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1293/1535 [52:17<09:45,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1294/1535 [52:20<09:42,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1295/1535 [52:22<09:40,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1296/1535 [52:25<09:37,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1297/1535 [52:27<09:35,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1298/1535 [52:30<09:33,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1299/1535 [52:32<09:32,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1535 [52:34<09:29,  2.42s/it]                                                   {'loss': 0.4002, 'grad_norm': 0.4046410918235779, 'learning_rate': 4.456193999741731e-05, 'epoch': 4.23}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1535 [52:34<09:29,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1301/1535 [52:37<09:26,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1302/1535 [52:39<09:24,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1303/1535 [52:42<09:21,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1304/1535 [52:44<09:18,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1305/1535 [52:46<09:16,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1306/1535 [52:49<09:13,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1307/1535 [52:51<09:13,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1308/1535 [52:54<09:10,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1309/1535 [52:56<09:07,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1310/1535 [52:59<09:04,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1311/1535 [53:01<09:02,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1312/1535 [53:03<08:59,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1313/1535 [53:06<08:58,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1314/1535 [53:08<08:55,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1315/1535 [53:11<08:52,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1316/1535 [53:13<08:50,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1317/1535 [53:16<08:47,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1318/1535 [53:18<08:45,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1319/1535 [53:20<08:42,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1535 [53:23<08:40,  2.42s/it]                                                   {'loss': 0.4263, 'grad_norm': 0.40331679582595825, 'learning_rate': 3.7544803545931927e-05, 'epoch': 4.29}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1535 [53:23<08:40,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1321/1535 [53:25<08:39,  2.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1322/1535 [53:28<08:36,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1323/1535 [53:30<08:33,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1324/1535 [53:32<08:30,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1325/1535 [53:35<08:28,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1326/1535 [53:37<08:25,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1327/1535 [53:40<08:23,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1328/1535 [53:42<08:20,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1329/1535 [53:45<08:18,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1330/1535 [53:47<08:15,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1331/1535 [53:49<08:13,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1332/1535 [53:52<08:10,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1333/1535 [53:54<08:08,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1334/1535 [53:57<08:07,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1335/1535 [53:59<08:04,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1336/1535 [54:02<08:02,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1337/1535 [54:04<07:59,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1338/1535 [54:06<07:56,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1339/1535 [54:09<07:54,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1535 [54:11<07:51,  2.42s/it]                                                   {'loss': 0.422, 'grad_norm': 0.3808134198188782, 'learning_rate': 3.1083744964335886e-05, 'epoch': 4.36}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1535 [54:11<07:51,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1341/1535 [54:14<07:49,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1342/1535 [54:16<07:48,  2.43s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1343/1535 [54:18<07:45,  2.43s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1344/1535 [54:21<07:42,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1345/1535 [54:23<07:40,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1346/1535 [54:26<07:37,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1347/1535 [54:28<07:34,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1348/1535 [54:31<07:32,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1349/1535 [54:33<07:30,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1350/1535 [54:35<07:28,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1351/1535 [54:38<07:25,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1352/1535 [54:40<07:22,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1353/1535 [54:43<07:20,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1354/1535 [54:45<07:17,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1355/1535 [54:48<07:15,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1356/1535 [54:50<07:12,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1357/1535 [54:52<07:11,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1358/1535 [54:55<07:08,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1359/1535 [54:57<07:05,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1535 [55:00<07:03,  2.42s/it]                                                   {'loss': 0.4041, 'grad_norm': 0.36392152309417725, 'learning_rate': 2.5195675355550037e-05, 'epoch': 4.42}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1535 [55:00<07:03,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1361/1535 [55:02<07:01,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1362/1535 [55:04<06:59,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1363/1535 [55:07<06:56,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1364/1535 [55:09<06:54,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1365/1535 [55:12<06:51,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1366/1535 [55:14<06:48,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1367/1535 [55:17<06:46,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1368/1535 [55:19<06:44,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1369/1535 [55:21<06:41,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1370/1535 [55:24<06:39,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1371/1535 [55:26<06:36,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1372/1535 [55:29<06:34,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1373/1535 [55:31<06:31,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1374/1535 [55:34<06:29,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1375/1535 [55:36<06:26,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1376/1535 [55:38<06:24,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1377/1535 [55:41<06:24,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1378/1535 [55:43<06:21,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1379/1535 [55:46<06:18,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1535 [55:48<06:15,  2.42s/it]                                                   {'loss': 0.4115, 'grad_norm': 0.3705468475818634, 'learning_rate': 1.9896006087526036e-05, 'epoch': 4.49}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1535 [55:48<06:15,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1381/1535 [55:50<06:13,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1382/1535 [55:53<06:10,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1383/1535 [55:55<06:07,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1384/1535 [55:58<06:05,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1385/1535 [56:00<06:02,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1386/1535 [56:03<06:00,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1387/1535 [56:05<05:58,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1388/1535 [56:07<05:55,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1389/1535 [56:10<05:53,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1390/1535 [56:12<05:51,  2.43s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1391/1535 [56:15<05:49,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1392/1535 [56:17<05:46,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1393/1535 [56:20<05:43,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1394/1535 [56:22<05:41,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1395/1535 [56:24<05:38,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1396/1535 [56:27<05:36,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1397/1535 [56:29<05:33,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1398/1535 [56:32<05:31,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1399/1535 [56:34<05:28,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1535 [56:36<05:27,  2.43s/it]                                                   {'loss': 0.4197, 'grad_norm': 0.37341904640197754, 'learning_rate': 1.519860845570356e-05, 'epoch': 4.55}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1535 [56:36<05:27,  2.43s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1401/1535 [56:39<05:24,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1402/1535 [56:41<05:22,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1403/1535 [56:44<05:21,  2.43s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1404/1535 [56:46<05:18,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1405/1535 [56:49<05:15,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1406/1535 [56:51<05:12,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1407/1535 [56:53<05:09,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1408/1535 [56:56<05:07,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1409/1535 [56:58<05:04,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1410/1535 [57:01<05:02,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1411/1535 [57:03<04:59,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1412/1535 [57:06<04:57,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1413/1535 [57:08<04:54,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1414/1535 [57:10<04:52,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1415/1535 [57:13<04:50,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1416/1535 [57:15<04:47,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1417/1535 [57:18<04:45,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1418/1535 [57:20<04:42,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1419/1535 [57:22<04:40,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1420/1535 [57:25<04:38,  2.42s/it]                                                   {'loss': 0.3975, 'grad_norm': 0.36578062176704407, 'learning_rate': 1.1115777376435292e-05, 'epoch': 4.62}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1420/1535 [57:25<04:38,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1421/1535 [57:27<04:35,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1422/1535 [57:30<04:33,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1423/1535 [57:32<04:30,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1424/1535 [57:35<04:28,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1425/1535 [57:37<04:25,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1426/1535 [57:39<04:23,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1427/1535 [57:42<04:21,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1428/1535 [57:44<04:18,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1429/1535 [57:47<04:16,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1430/1535 [57:49<04:13,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1431/1535 [57:51<04:11,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1432/1535 [57:54<04:09,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1433/1535 [57:56<04:06,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1434/1535 [57:59<04:04,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1435/1535 [58:01<04:01,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1436/1535 [58:04<03:59,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1437/1535 [58:06<03:56,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1438/1535 [58:08<03:54,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1439/1535 [58:11<03:52,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1440/1535 [58:13<03:49,  2.42s/it]                                                   {'loss': 0.4019, 'grad_norm': 0.3417545557022095, 'learning_rate': 7.658199206410004e-06, 'epoch': 4.68}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1440/1535 [58:13<03:49,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1441/1535 [58:16<03:47,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1442/1535 [58:18<03:44,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1443/1535 [58:21<03:42,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1444/1535 [58:23<03:40,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1445/1535 [58:25<03:37,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1446/1535 [58:28<03:36,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1447/1535 [58:30<03:33,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1448/1535 [58:33<03:30,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1449/1535 [58:35<03:28,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1450/1535 [58:37<03:25,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1451/1535 [58:40<03:23,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1452/1535 [58:42<03:20,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1453/1535 [58:45<03:18,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1454/1535 [58:47<03:15,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1455/1535 [58:50<03:13,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1456/1535 [58:52<03:11,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1457/1535 [58:54<03:08,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1458/1535 [58:57<03:06,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1459/1535 [58:59<03:03,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1460/1535 [59:02<03:01,  2.43s/it]                                                   {'loss': 0.4168, 'grad_norm': 0.39042428135871887, 'learning_rate': 4.834923772301048e-06, 'epoch': 4.75}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1460/1535 [59:02<03:01,  2.43s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1461/1535 [59:04<02:59,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1462/1535 [59:07<02:56,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1463/1535 [59:09<02:54,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1464/1535 [59:11<02:51,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1465/1535 [59:14<02:49,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1466/1535 [59:16<02:46,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1467/1535 [59:19<02:44,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1468/1535 [59:21<02:42,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1469/1535 [59:23<02:39,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1470/1535 [59:26<02:37,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1471/1535 [59:28<02:34,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1472/1535 [59:31<02:32,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1473/1535 [59:33<02:30,  2.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1474/1535 [59:36<02:27,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1475/1535 [59:38<02:25,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1476/1535 [59:40<02:22,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1477/1535 [59:43<02:20,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1478/1535 [59:45<02:17,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1479/1535 [59:48<02:15,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1480/1535 [59:50<02:13,  2.42s/it]                                                   {'loss': 0.4127, 'grad_norm': 0.38263243436813354, 'learning_rate': 2.6533406838507022e-06, 'epoch': 4.81}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1480/1535 [59:50<02:13,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1481/1535 [59:52<02:10,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1482/1535 [59:55<02:08,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1483/1535 [59:57<02:05,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1484/1535 [1:00:00<02:03,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1485/1535 [1:00:02<02:00,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1486/1535 [1:00:05<01:58,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1487/1535 [1:00:07<01:56,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1488/1535 [1:00:09<01:53,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1489/1535 [1:00:12<01:51,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1490/1535 [1:00:14<01:48,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1491/1535 [1:00:17<01:46,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1492/1535 [1:00:19<01:43,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1493/1535 [1:00:22<01:41,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1494/1535 [1:00:24<01:39,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1495/1535 [1:00:26<01:36,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1496/1535 [1:00:29<01:34,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1497/1535 [1:00:31<01:31,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1498/1535 [1:00:34<01:29,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1499/1535 [1:00:36<01:27,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1500/1535 [1:00:38<01:24,  2.42s/it]                                                     {'loss': 0.3969, 'grad_norm': 0.43129515647888184, 'learning_rate': 1.1191599923876806e-06, 'epoch': 4.88}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1500/1535 [1:00:38<01:24,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1501/1535 [1:00:41<01:22,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1502/1535 [1:00:43<01:19,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1503/1535 [1:00:46<01:17,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1504/1535 [1:00:48<01:14,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1505/1535 [1:00:51<01:12,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1506/1535 [1:00:53<01:10,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1507/1535 [1:00:55<01:07,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1508/1535 [1:00:58<01:05,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1509/1535 [1:01:00<01:02,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1510/1535 [1:01:03<01:00,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1511/1535 [1:01:05<00:58,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1512/1535 [1:01:07<00:55,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1513/1535 [1:01:10<00:53,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1514/1535 [1:01:12<00:50,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1515/1535 [1:01:15<00:48,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1516/1535 [1:01:17<00:46,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1517/1535 [1:01:20<00:43,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1518/1535 [1:01:22<00:41,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1519/1535 [1:01:24<00:38,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1520/1535 [1:01:27<00:36,  2.42s/it]                                                     {'loss': 0.3787, 'grad_norm': 0.34912529587745667, 'learning_rate': 2.3639724540239217e-07, 'epoch': 4.94}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1520/1535 [1:01:27<00:36,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1521/1535 [1:01:29<00:33,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1522/1535 [1:01:32<00:31,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1523/1535 [1:01:34<00:29,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1524/1535 [1:01:37<00:26,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1525/1535 [1:01:39<00:24,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1526/1535 [1:01:41<00:21,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1527/1535 [1:01:44<00:19,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1528/1535 [1:01:46<00:16,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1529/1535 [1:01:49<00:14,  2.43s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1530/1535 [1:01:51<00:12,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1531/1535 [1:01:53<00:09,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1532/1535 [1:01:56<00:07,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1533/1535 [1:01:58<00:04,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1534/1535 [1:02:01<00:02,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1535/1535 [1:02:03<00:00,  2.42s/it][INFO|trainer.py:2231] 2024-05-25 07:20:33,115 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 3745.7111, 'train_samples_per_second': 3.282, 'train_steps_per_second': 0.41, 'train_loss': 0.6102952242674191, 'epoch': 4.99}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1535/1535 [1:02:03<00:00,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1535/1535 [1:02:03<00:00,  2.43s/it]
***** train metrics *****
  epoch                    =       4.99
  train_loss               =     0.6103
  train_runtime            = 1:02:25.71
  train_samples_per_second =      3.282
  train_steps_per_second   =       0.41
[INFO|trainer.py:3203] 2024-05-25 07:20:33,122 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_length
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-05-25 07:20:34,280 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:20:34,283 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 07:20:35,565 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:20:35,570 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 07:20:35,625 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_length/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 07:20:35,626 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_length/special_tokens_map.json
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:471] 2024-05-25 07:20:36,308 >> Configuration saved in /scratch/tathagato/adapter_experiments/topic_then_length/final_merged_model/config.json
[INFO|configuration_utils.py:697] 2024-05-25 07:20:36,310 >> Configuration saved in /scratch/tathagato/adapter_experiments/topic_then_length/final_merged_model/generation_config.json
[INFO|modeling_utils.py:2474] 2024-05-25 07:20:42,573 >> Model weights saved in /scratch/tathagato/adapter_experiments/topic_then_length/final_merged_model/model.safetensors
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.034 MB uploadedwandb: / 0.006 MB of 0.038 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb: train/learning_rate ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 1.567843226180649e+17
wandb:              train/epoch 4.99
wandb:        train/global_step 1535
wandb:          train/grad_norm 0.34913
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.3787
wandb:               train_loss 0.6103
wandb:            train_runtime 3745.7111
wandb: train_samples_per_second 3.282
wandb:   train_steps_per_second 0.41
wandb: 
wandb: üöÄ View run denim-snowflake-102 at: https://wandb.ai/ihub-drug-discovery/huggingface/runs/mzcv67nv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ihub-drug-discovery/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240525_061813-mzcv67nv/logs
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-05-25 07:21:28 - WARNING - __main__ - Process rank: 2, device: cuda:2, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 07:21:28 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 07:21:28 - WARNING - __main__ - Process rank: 3, device: cuda:3, n_gpu: 1 distributed training: True, 16-bits training: True
2024-05-25 07:21:28 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0005,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/tathagato/adapter_experiments/topic_then_extractiveness/runs/May25_07-21-28_gnode081,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=20,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/tathagato/adapter_experiments/topic_then_extractiveness,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/tathagato/adapter_experiments/topic_then_extractiveness,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=400,
save_strategy=steps,
save_total_limit=400,
seed=0,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.2,
warmup_steps=0,
weight_decay=0.0,
)
2024-05-25 07:21:28 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'q_proj', 'o_proj', 'v_proj', 'k_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)
2024-05-25 07:21:28 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1 distributed training: True, 16-bits training: True
[INFO|configuration_utils.py:726] 2024-05-25 07:21:28,471 >> loading configuration file config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:21:28,537 >> Model config LlamaConfig {
  "_name_or_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": false,
  "vocab_size": 32000
}

[INFO|quantizer_bnb_4bit.py:247] 2024-05-25 07:21:29,272 >> The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' 
[WARNING|modeling_utils.py:3058] 2024-05-25 07:21:29,272 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 07:21:29,272 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:3283] 2024-05-25 07:21:29,273 >> loading weights file model.safetensors from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors
[WARNING|modeling_utils.py:3058] 2024-05-25 07:21:29,275 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[WARNING|modeling_utils.py:3058] 2024-05-25 07:21:29,275 >> `low_cpu_mem_usage` was None, now set to True since model is quantized.
[INFO|modeling_utils.py:1417] 2024-05-25 07:21:29,292 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:928] 2024-05-25 07:21:29,294 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[INFO|modeling_utils.py:4024] 2024-05-25 07:21:32,314 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-05-25 07:21:32,315 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-05-25 07:21:32,931 >> loading configuration file generation_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json
[INFO|configuration_utils.py:928] 2024-05-25 07:21:32,932 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

loading model from : /scratch/tathagato/adapter_experiments/topic/topic
[INFO|tokenization_utils_base.py:2084] 2024-05-25 07:21:33,346 >> loading file tokenizer.model from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-05-25 07:21:33,347 >> loading file tokenizer.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 07:21:33,347 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-05-25 07:21:33,347 >> loading file special_tokens_map.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-05-25 07:21:33,347 >> loading file tokenizer_config.json from cache at /scratch/tathagato/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json
loading model from : /scratch/tathagato/adapter_experiments/topic/topic
loading model from : /scratch/tathagato/adapter_experiments/topic/topic
loading model from : /scratch/tathagato/adapter_experiments/topic/topic
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
train dataset size 4278
test dataset size 554
4278
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
Spawning 10 processes
2024-05-25 07:21:36 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]trainable params: 4505600 || all params: 620111872 || trainable%: 0.7265785745188894
total model parameters : 4505600
train dataset size 4278
test dataset size 554
4278
train dataset size 4278
test dataset size 554
4278
train dataset size 4278
test dataset size 554
4278
Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:11:58,  1.01s/ examples]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:07, 524.36 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 0/4278 [00:00<?, ? examples/s]Applying chat template to train_sft (num_proc=10):  16%|‚ñà‚ñå        | 682/4278 [00:01<00:05, 602.81 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:01<00:05, 603.69 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:01<00:02, 1035.01 examples/s]Applying chat template to train_sft (num_proc=10):  35%|‚ñà‚ñà‚ñà‚ñå      | 1513/4278 [00:02<00:03, 841.93 examples/s] Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:19:26,  1.11s/ examples]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:07, 483.51 examples/s]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:22:42,  1.16s/ examples]Applying chat template to train_sft (num_proc=10):   0%|          | 1/4278 [00:01<1:26:02,  1.21s/ examples]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 428/4278 [00:01<00:08, 442.01 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:02<00:03, 643.41 examples/s]Applying chat template to train_sft (num_proc=10):  16%|‚ñà‚ñå        | 682/4278 [00:01<00:06, 541.15 examples/s]Applying chat template to train_sft (num_proc=10):  10%|‚ñà         | 429/4278 [00:01<00:11, 335.51 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:02<00:02, 1010.94 examples/s]Applying chat template to train_sft (num_proc=10):  16%|‚ñà‚ñå        | 678/4278 [00:01<00:06, 548.85 examples/s]Applying chat template to train_sft (num_proc=10):  17%|‚ñà‚ñã        | 718/4278 [00:01<00:07, 457.69 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:02<00:07, 440.47 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:02<00:03, 816.98 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:02<00:07, 453.88 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1284/4278 [00:02<00:03, 844.67 examples/s]Applying chat template to train_sft (num_proc=10):  35%|‚ñà‚ñà‚ñà‚ñå      | 1517/4278 [00:02<00:03, 715.68 examples/s]Applying chat template to train_sft (num_proc=10):  20%|‚ñà‚ñà        | 857/4278 [00:02<00:10, 341.05 examples/s]Applying chat template to train_sft (num_proc=10):  35%|‚ñà‚ñà‚ñà‚ñå      | 1517/4278 [00:02<00:04, 688.56 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1713/4278 [00:03<00:04, 621.23 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1712/4278 [00:02<00:03, 825.12 examples/s]Applying chat template to train_sft (num_proc=10):  30%|‚ñà‚ñà‚ñà       | 1285/4278 [00:03<00:05, 500.92 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2140/4278 [00:03<00:02, 971.85 examples/s]Applying chat template to train_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 1712/4278 [00:03<00:03, 789.08 examples/s]Applying chat template to train_sft (num_proc=10):  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1914/4278 [00:03<00:02, 844.73 examples/s]Applying chat template to train_sft (num_proc=10):  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2346/4278 [00:04<00:05, 331.95 examples/s] Applying chat template to train_sft (num_proc=10):  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2377/4278 [00:03<00:02, 772.91 examples/s]Applying chat template to train_sft (num_proc=10):  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1943/4278 [00:03<00:03, 706.79 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2568/4278 [00:05<00:04, 418.54 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2568/4278 [00:03<00:01, 878.75 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2141/4278 [00:03<00:03, 660.70 examples/s]Applying chat template to train_sft (num_proc=10):  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2782/4278 [00:05<00:02, 518.09 examples/s]Applying chat template to train_sft (num_proc=10):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2141/4278 [00:04<00:03, 667.54 examples/s]Applying chat template to train_sft (num_proc=10):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2810/4278 [00:04<00:01, 843.61 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2569/4278 [00:04<00:02, 799.87 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2996/4278 [00:04<00:01, 916.76 examples/s]Applying chat template to train_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 2568/4278 [00:04<00:01, 910.52 examples/s]Applying chat template to train_sft (num_proc=10):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2844/4278 [00:04<00:01, 941.42 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:05<00:02, 427.28 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:04<00:01, 1004.16 examples/s]Applying chat template to train_sft (num_proc=10):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3208/4278 [00:04<00:01, 729.65 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/4278 [00:06<00:01, 693.85 examples/s]Applying chat template to train_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2997/4278 [00:04<00:01, 794.72 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/4278 [00:04<00:00, 888.32 examples/s]Applying chat template to train_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/4278 [00:04<00:00, 1118.01 examples/s]Applying chat template to train_sft (num_proc=10):  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 3199/4278 [00:05<00:01, 742.34 examples/s] Applying chat template to train_sft (num_proc=10):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3636/4278 [00:05<00:00, 1021.07 examples/s]Applying chat template to train_sft (num_proc=10):  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3610/4278 [00:05<00:00, 692.28 examples/s]Applying chat template to train_sft (num_proc=10):  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3680/4278 [00:05<00:00, 1161.52 examples/s]Applying chat template to train_sft (num_proc=10):  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3646/4278 [00:06<00:01, 578.37 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3851/4278 [00:05<00:00, 895.33 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3852/4278 [00:05<00:00, 865.98 examples/s] Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 1220.13 examples/s]Applying chat template to train_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3852/4278 [00:07<00:00, 574.15 examples/s]Applying chat template to train_sft (num_proc=10):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4106/4278 [00:05<00:00, 819.36 examples/s]Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:07<00:00, 879.95 examples/s]Applying chat template to train_sft (num_proc=10):  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4117/4278 [00:05<00:00, 922.51 examples/s] Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:05<00:00, 728.50 examples/s] 
Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:06<00:00, 693.54 examples/s]
Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:07<00:00, 572.51 examples/s]
Concatenating 10 shards
2024-05-25 07:21:44 - INFO - datasets.arrow_dataset - Concatenating 10 shards
Applying chat template to train_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4278/4278 [00:06<00:00, 673.74 examples/s]
Spawning 10 processes
2024-05-25 07:21:44 - INFO - datasets.arrow_dataset - Spawning 10 processes
Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 0/554 [00:00<?, ? examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<04:10,  2.20 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:03, 134.49 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:17,  1.74 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<05:24,  1.70 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:01, 221.02 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 189.05 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:04, 107.21 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:00, 358.12 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:00<00:01, 296.14 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 383.78 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 153.89 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 389/554 [00:01<00:00, 548.21 examples/s]Applying chat template to test_sft (num_proc=10):  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 280/554 [00:01<00:00, 336.76 examples/s]Applying chat template to test_sft (num_proc=10):   0%|          | 1/554 [00:00<06:51,  1.34 examples/s]Applying chat template to test_sft (num_proc=10):  41%|‚ñà‚ñà‚ñà‚ñà      | 225/554 [00:01<00:01, 304.15 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 389/554 [00:01<00:00, 488.59 examples/s]Applying chat template to test_sft (num_proc=10):  10%|‚ñà         | 57/554 [00:00<00:05, 89.22 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 569.80 examples/s]Applying chat template to test_sft (num_proc=10):  20%|‚ñà‚ñà        | 113/554 [00:00<00:02, 168.57 examples/s]Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 335/554 [00:01<00:00, 396.34 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 499/554 [00:01<00:00, 489.70 examples/s]Applying chat template to test_sft (num_proc=10):  40%|‚ñà‚ñà‚ñà‚ñà      | 224/554 [00:01<00:00, 345.73 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 390/554 [00:01<00:00, 391.76 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 347.38 examples/s]
Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 445/554 [00:01<00:00, 413.43 examples/s]Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 325.94 examples/s]
Applying chat template to test_sft (num_proc=10):  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 334/554 [00:01<00:00, 396.45 examples/s]Concatenating 10 shards
2024-05-25 07:21:46 - INFO - datasets.arrow_dataset - Concatenating 10 shards
tokenizer padding side left
Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 500/554 [00:01<00:00, 436.80 examples/s]Applying chat template to test_sft (num_proc=10):  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 390/554 [00:01<00:00, 413.81 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 292.94 examples/s]
Applying chat template to test_sft (num_proc=10):  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 445/554 [00:01<00:00, 394.33 examples/s]Applying chat template to test_sft (num_proc=10):  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 500/554 [00:01<00:00, 402.08 examples/s]tokenizer padding side left
Applying chat template to test_sft (num_proc=10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 554/554 [00:01<00:00, 281.97 examples/s]
Using custom data configuration default-37faee928f8259ce
2024-05-25 07:21:47 - INFO - datasets.builder - Using custom data configuration default-37faee928f8259ce
Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
2024-05-25 07:21:47 - INFO - datasets.info - Loading Dataset Infos from /home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/datasets/packaged_modules/generator
Overwrite dataset info from restored data version if exists.
2024-05-25 07:21:47 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
2024-05-25 07:21:47 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0)
2024-05-25 07:21:47 - INFO - datasets.builder - Found cached dataset generator (/home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0)
Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
2024-05-25 07:21:47 - INFO - datasets.info - Loading Dataset info from /home2/tathagato/.cache/huggingface/datasets/generator/default-37faee928f8259ce/0.0.0
tokenizer padding side left
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
2024-05-25 07:21:48 - WARNING - accelerate.utils.other - Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:607] 2024-05-25 07:21:50,956 >> Using auto half precision backend
is  model parallelism  ParallelMode.DISTRIBUTED
is  model parallelism  ParallelMode.DISTRIBUTED
[INFO|trainer.py:1969] 2024-05-25 07:21:51,208 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-05-25 07:21:51,208 >>   Num examples = 2,462
[INFO|trainer.py:1971] 2024-05-25 07:21:51,208 >>   Num Epochs = 5
[INFO|trainer.py:1972] 2024-05-25 07:21:51,208 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-05-25 07:21:51,208 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-05-25 07:21:51,208 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-05-25 07:21:51,208 >>   Total optimization steps = 1,540
[INFO|trainer.py:1978] 2024-05-25 07:21:51,210 >>   Number of trainable parameters = 4,505,600
[INFO|integration_utils.py:723] 2024-05-25 07:21:51,275 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: roy3 (ihub-drug-discovery). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home2/tathagato/summarization/MACSum/experiments/wandb/run-20240525_072157-d65347to
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-microwave-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ihub-drug-discovery/huggingface
wandb: üöÄ View run at https://wandb.ai/ihub-drug-discovery/huggingface/runs/d65347to
  0%|          | 0/1540 [00:00<?, ?it/s][W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
  0%|          | 1/1540 [00:02<1:03:24,  2.47s/it]  0%|          | 2/1540 [00:04<1:02:14,  2.43s/it]  0%|          | 3/1540 [00:07<1:01:52,  2.42s/it]  0%|          | 4/1540 [00:09<1:01:40,  2.41s/it]  0%|          | 5/1540 [00:12<1:01:36,  2.41s/it]  0%|          | 6/1540 [00:14<1:01:32,  2.41s/it]  0%|          | 7/1540 [00:16<1:01:31,  2.41s/it]  1%|          | 8/1540 [00:19<1:01:28,  2.41s/it]  1%|          | 9/1540 [00:21<1:01:33,  2.41s/it]  1%|          | 10/1540 [00:24<1:01:27,  2.41s/it]  1%|          | 11/1540 [00:26<1:01:22,  2.41s/it]  1%|          | 12/1540 [00:29<1:01:56,  2.43s/it]  1%|          | 13/1540 [00:31<1:02:16,  2.45s/it]  1%|          | 14/1540 [00:33<1:01:56,  2.44s/it]  1%|          | 15/1540 [00:36<1:01:41,  2.43s/it]  1%|          | 16/1540 [00:38<1:01:29,  2.42s/it]  1%|          | 17/1540 [00:41<1:01:21,  2.42s/it]  1%|          | 18/1540 [00:43<1:01:14,  2.41s/it]  1%|          | 19/1540 [00:45<1:01:09,  2.41s/it]  1%|‚ñè         | 20/1540 [00:48<1:01:06,  2.41s/it]                                                   {'loss': 0.9627, 'grad_norm': 0.3349049687385559, 'learning_rate': 3.246753246753247e-05, 'epoch': 0.06}
  1%|‚ñè         | 20/1540 [00:48<1:01:06,  2.41s/it]  1%|‚ñè         | 21/1540 [00:50<1:01:12,  2.42s/it]  1%|‚ñè         | 22/1540 [00:53<1:01:10,  2.42s/it]  1%|‚ñè         | 23/1540 [00:55<1:01:05,  2.42s/it]  2%|‚ñè         | 24/1540 [00:58<1:01:01,  2.42s/it]  2%|‚ñè         | 25/1540 [01:00<1:01:00,  2.42s/it]  2%|‚ñè         | 26/1540 [01:02<1:01:09,  2.42s/it]  2%|‚ñè         | 27/1540 [01:05<1:01:02,  2.42s/it]  2%|‚ñè         | 28/1540 [01:07<1:00:58,  2.42s/it]  2%|‚ñè         | 29/1540 [01:10<1:01:08,  2.43s/it]  2%|‚ñè         | 30/1540 [01:12<1:01:01,  2.42s/it]  2%|‚ñè         | 31/1540 [01:15<1:00:56,  2.42s/it]  2%|‚ñè         | 32/1540 [01:17<1:00:52,  2.42s/it]  2%|‚ñè         | 33/1540 [01:19<1:00:48,  2.42s/it]  2%|‚ñè         | 34/1540 [01:22<1:00:43,  2.42s/it]  2%|‚ñè         | 35/1540 [01:24<1:00:39,  2.42s/it]  2%|‚ñè         | 36/1540 [01:27<1:00:37,  2.42s/it]  2%|‚ñè         | 37/1540 [01:29<1:00:35,  2.42s/it]  2%|‚ñè         | 38/1540 [01:31<1:00:33,  2.42s/it]  3%|‚ñé         | 39/1540 [01:34<1:00:32,  2.42s/it]  3%|‚ñé         | 40/1540 [01:36<1:00:29,  2.42s/it]                                                   {'loss': 0.9265, 'grad_norm': 0.37487247586250305, 'learning_rate': 6.493506493506494e-05, 'epoch': 0.13}
  3%|‚ñé         | 40/1540 [01:36<1:00:29,  2.42s/it]  3%|‚ñé         | 41/1540 [01:39<1:00:27,  2.42s/it]  3%|‚ñé         | 42/1540 [01:41<1:00:36,  2.43s/it]  3%|‚ñé         | 43/1540 [01:44<1:00:29,  2.42s/it]  3%|‚ñé         | 44/1540 [01:46<1:00:23,  2.42s/it]  3%|‚ñé         | 45/1540 [01:48<1:00:20,  2.42s/it]  3%|‚ñé         | 46/1540 [01:51<1:00:17,  2.42s/it]  3%|‚ñé         | 47/1540 [01:53<1:00:14,  2.42s/it]  3%|‚ñé         | 48/1540 [01:56<1:00:11,  2.42s/it]  3%|‚ñé         | 49/1540 [01:58<1:00:08,  2.42s/it]  3%|‚ñé         | 50/1540 [02:00<1:00:05,  2.42s/it]  3%|‚ñé         | 51/1540 [02:03<1:00:03,  2.42s/it]  3%|‚ñé         | 52/1540 [02:05<1:00:00,  2.42s/it]  3%|‚ñé         | 53/1540 [02:08<59:58,  2.42s/it]    4%|‚ñé         | 54/1540 [02:10<1:00:05,  2.43s/it]  4%|‚ñé         | 55/1540 [02:13<59:59,  2.42s/it]    4%|‚ñé         | 56/1540 [02:15<1:00:27,  2.44s/it]  4%|‚ñé         | 57/1540 [02:18<1:00:14,  2.44s/it]  4%|‚ñç         | 58/1540 [02:20<1:00:04,  2.43s/it]  4%|‚ñç         | 59/1540 [02:22<59:57,  2.43s/it]    4%|‚ñç         | 60/1540 [02:25<59:51,  2.43s/it]                                                 {'loss': 0.9137, 'grad_norm': 0.45463690161705017, 'learning_rate': 9.577922077922078e-05, 'epoch': 0.19}
  4%|‚ñç         | 60/1540 [02:25<59:51,  2.43s/it]  4%|‚ñç         | 61/1540 [02:27<59:47,  2.43s/it]  4%|‚ñç         | 62/1540 [02:30<59:43,  2.42s/it]  4%|‚ñç         | 63/1540 [02:32<59:39,  2.42s/it]  4%|‚ñç         | 64/1540 [02:34<59:36,  2.42s/it]  4%|‚ñç         | 65/1540 [02:37<59:33,  2.42s/it]  4%|‚ñç         | 66/1540 [02:39<59:29,  2.42s/it]  4%|‚ñç         | 67/1540 [02:42<59:26,  2.42s/it]  4%|‚ñç         | 68/1540 [02:44<59:24,  2.42s/it]  4%|‚ñç         | 69/1540 [02:47<59:21,  2.42s/it]  5%|‚ñç         | 70/1540 [02:49<59:38,  2.43s/it]  5%|‚ñç         | 71/1540 [02:51<59:31,  2.43s/it]  5%|‚ñç         | 72/1540 [02:54<59:24,  2.43s/it]  5%|‚ñç         | 73/1540 [02:56<59:19,  2.43s/it]  5%|‚ñç         | 74/1540 [02:59<59:15,  2.43s/it]  5%|‚ñç         | 75/1540 [03:01<59:15,  2.43s/it]  5%|‚ñç         | 76/1540 [03:04<59:10,  2.43s/it]  5%|‚ñå         | 77/1540 [03:06<59:07,  2.42s/it]  5%|‚ñå         | 78/1540 [03:08<59:03,  2.42s/it]  5%|‚ñå         | 79/1540 [03:11<58:59,  2.42s/it]  5%|‚ñå         | 80/1540 [03:13<58:57,  2.42s/it]                                                 {'loss': 0.9388, 'grad_norm': 0.39316368103027344, 'learning_rate': 0.00012824675324675324, 'epoch': 0.26}
  5%|‚ñå         | 80/1540 [03:13<58:57,  2.42s/it]  5%|‚ñå         | 81/1540 [03:16<58:56,  2.42s/it]  5%|‚ñå         | 82/1540 [03:18<58:52,  2.42s/it]  5%|‚ñå         | 83/1540 [03:21<59:02,  2.43s/it]  5%|‚ñå         | 84/1540 [03:23<58:55,  2.43s/it]  6%|‚ñå         | 85/1540 [03:25<58:49,  2.43s/it]  6%|‚ñå         | 86/1540 [03:28<58:47,  2.43s/it]  6%|‚ñå         | 87/1540 [03:30<58:43,  2.43s/it]  6%|‚ñå         | 88/1540 [03:33<58:40,  2.42s/it]  6%|‚ñå         | 89/1540 [03:35<58:37,  2.42s/it]  6%|‚ñå         | 90/1540 [03:38<58:33,  2.42s/it]  6%|‚ñå         | 91/1540 [03:40<58:31,  2.42s/it]  6%|‚ñå         | 92/1540 [03:42<58:28,  2.42s/it]  6%|‚ñå         | 93/1540 [03:45<58:26,  2.42s/it]  6%|‚ñå         | 94/1540 [03:47<58:25,  2.42s/it]  6%|‚ñå         | 95/1540 [03:50<58:22,  2.42s/it]  6%|‚ñå         | 96/1540 [03:52<58:19,  2.42s/it]  6%|‚ñã         | 97/1540 [03:55<58:17,  2.42s/it]  6%|‚ñã         | 98/1540 [03:57<58:24,  2.43s/it]  6%|‚ñã         | 99/1540 [03:59<58:18,  2.43s/it]  6%|‚ñã         | 100/1540 [04:02<58:13,  2.43s/it]                                                  {'loss': 0.9712, 'grad_norm': 0.315456360578537, 'learning_rate': 0.00016071428571428573, 'epoch': 0.32}
  6%|‚ñã         | 100/1540 [04:02<58:13,  2.43s/it]  7%|‚ñã         | 101/1540 [04:04<58:10,  2.43s/it]  7%|‚ñã         | 102/1540 [04:07<58:08,  2.43s/it]  7%|‚ñã         | 103/1540 [04:09<58:04,  2.43s/it]  7%|‚ñã         | 104/1540 [04:11<58:00,  2.42s/it]  7%|‚ñã         | 105/1540 [04:14<57:58,  2.42s/it]  7%|‚ñã         | 106/1540 [04:16<57:55,  2.42s/it]  7%|‚ñã         | 107/1540 [04:19<57:52,  2.42s/it]  7%|‚ñã         | 108/1540 [04:21<57:49,  2.42s/it]  7%|‚ñã         | 109/1540 [04:24<57:47,  2.42s/it]  7%|‚ñã         | 110/1540 [04:26<57:44,  2.42s/it]  7%|‚ñã         | 111/1540 [04:28<57:48,  2.43s/it]  7%|‚ñã         | 112/1540 [04:31<57:44,  2.43s/it]  7%|‚ñã         | 113/1540 [04:33<57:41,  2.43s/it]  7%|‚ñã         | 114/1540 [04:36<57:38,  2.43s/it]  7%|‚ñã         | 115/1540 [04:38<57:34,  2.42s/it]  8%|‚ñä         | 116/1540 [04:41<57:31,  2.42s/it]  8%|‚ñä         | 117/1540 [04:43<57:28,  2.42s/it]  8%|‚ñä         | 118/1540 [04:45<57:25,  2.42s/it]  8%|‚ñä         | 119/1540 [04:48<57:22,  2.42s/it]  8%|‚ñä         | 120/1540 [04:50<57:19,  2.42s/it]                                                  {'loss': 0.913, 'grad_norm': 0.2901560366153717, 'learning_rate': 0.00019318181818181817, 'epoch': 0.39}
  8%|‚ñä         | 120/1540 [04:50<57:19,  2.42s/it]  8%|‚ñä         | 121/1540 [04:53<57:19,  2.42s/it]  8%|‚ñä         | 122/1540 [04:55<57:16,  2.42s/it]  8%|‚ñä         | 123/1540 [04:58<57:13,  2.42s/it]  8%|‚ñä         | 124/1540 [05:00<57:10,  2.42s/it]  8%|‚ñä         | 125/1540 [05:02<57:08,  2.42s/it]  8%|‚ñä         | 126/1540 [05:05<57:41,  2.45s/it]  8%|‚ñä         | 127/1540 [05:07<57:28,  2.44s/it]  8%|‚ñä         | 128/1540 [05:10<57:18,  2.43s/it]  8%|‚ñä         | 129/1540 [05:12<57:09,  2.43s/it]  8%|‚ñä         | 130/1540 [05:15<57:03,  2.43s/it]  9%|‚ñä         | 131/1540 [05:17<56:59,  2.43s/it]  9%|‚ñä         | 132/1540 [05:19<56:54,  2.43s/it]  9%|‚ñä         | 133/1540 [05:22<56:51,  2.42s/it]  9%|‚ñä         | 134/1540 [05:24<56:47,  2.42s/it]  9%|‚ñâ         | 135/1540 [05:27<56:44,  2.42s/it]  9%|‚ñâ         | 136/1540 [05:29<56:41,  2.42s/it]  9%|‚ñâ         | 137/1540 [05:32<56:39,  2.42s/it]  9%|‚ñâ         | 138/1540 [05:34<56:36,  2.42s/it]  9%|‚ñâ         | 139/1540 [05:36<56:39,  2.43s/it]  9%|‚ñâ         | 140/1540 [05:39<56:34,  2.42s/it]                                                  {'loss': 0.8695, 'grad_norm': 0.3249622583389282, 'learning_rate': 0.00022564935064935067, 'epoch': 0.45}
  9%|‚ñâ         | 140/1540 [05:39<56:34,  2.42s/it]  9%|‚ñâ         | 141/1540 [05:41<56:31,  2.42s/it]  9%|‚ñâ         | 142/1540 [05:44<56:27,  2.42s/it]  9%|‚ñâ         | 143/1540 [05:46<56:24,  2.42s/it]  9%|‚ñâ         | 144/1540 [05:49<56:21,  2.42s/it]  9%|‚ñâ         | 145/1540 [05:51<56:18,  2.42s/it]  9%|‚ñâ         | 146/1540 [05:53<56:16,  2.42s/it] 10%|‚ñâ         | 147/1540 [05:56<56:13,  2.42s/it] 10%|‚ñâ         | 148/1540 [05:58<56:10,  2.42s/it] 10%|‚ñâ         | 149/1540 [06:01<56:08,  2.42s/it] 10%|‚ñâ         | 150/1540 [06:03<56:05,  2.42s/it] 10%|‚ñâ         | 151/1540 [06:05<56:03,  2.42s/it] 10%|‚ñâ         | 152/1540 [06:08<56:13,  2.43s/it] 10%|‚ñâ         | 153/1540 [06:10<56:07,  2.43s/it] 10%|‚ñà         | 154/1540 [06:13<56:01,  2.43s/it] 10%|‚ñà         | 155/1540 [06:15<55:57,  2.42s/it] 10%|‚ñà         | 156/1540 [06:18<55:54,  2.42s/it] 10%|‚ñà         | 157/1540 [06:20<55:51,  2.42s/it] 10%|‚ñà         | 158/1540 [06:22<55:48,  2.42s/it] 10%|‚ñà         | 159/1540 [06:25<55:46,  2.42s/it] 10%|‚ñà         | 160/1540 [06:27<55:42,  2.42s/it]                                                  {'loss': 0.9055, 'grad_norm': 0.3224767744541168, 'learning_rate': 0.00025811688311688314, 'epoch': 0.52}
 10%|‚ñà         | 160/1540 [06:27<55:42,  2.42s/it] 10%|‚ñà         | 161/1540 [06:30<55:41,  2.42s/it] 11%|‚ñà         | 162/1540 [06:32<55:38,  2.42s/it] 11%|‚ñà         | 163/1540 [06:35<55:35,  2.42s/it] 11%|‚ñà         | 164/1540 [06:37<55:32,  2.42s/it] 11%|‚ñà         | 165/1540 [06:39<55:30,  2.42s/it] 11%|‚ñà         | 166/1540 [06:42<55:27,  2.42s/it] 11%|‚ñà         | 167/1540 [06:44<55:24,  2.42s/it] 11%|‚ñà         | 168/1540 [06:47<55:31,  2.43s/it] 11%|‚ñà         | 169/1540 [06:49<55:26,  2.43s/it] 11%|‚ñà         | 170/1540 [06:52<55:22,  2.43s/it] 11%|‚ñà         | 171/1540 [06:54<55:18,  2.42s/it] 11%|‚ñà         | 172/1540 [06:56<55:14,  2.42s/it] 11%|‚ñà         | 173/1540 [06:59<55:11,  2.42s/it] 11%|‚ñà‚ñè        | 174/1540 [07:01<55:08,  2.42s/it] 11%|‚ñà‚ñè        | 175/1540 [07:04<55:05,  2.42s/it] 11%|‚ñà‚ñè        | 176/1540 [07:06<55:02,  2.42s/it] 11%|‚ñà‚ñè        | 177/1540 [07:08<55:00,  2.42s/it] 12%|‚ñà‚ñè        | 178/1540 [07:11<54:58,  2.42s/it] 12%|‚ñà‚ñè        | 179/1540 [07:13<54:55,  2.42s/it] 12%|‚ñà‚ñè        | 180/1540 [07:16<54:53,  2.42s/it]                                                  {'loss': 0.8572, 'grad_norm': 0.2940329313278198, 'learning_rate': 0.0002905844155844156, 'epoch': 0.58}
 12%|‚ñà‚ñè        | 180/1540 [07:16<54:53,  2.42s/it] 12%|‚ñà‚ñè        | 181/1540 [07:18<54:52,  2.42s/it] 12%|‚ñà‚ñè        | 182/1540 [07:21<54:49,  2.42s/it] 12%|‚ñà‚ñè        | 183/1540 [07:23<54:47,  2.42s/it] 12%|‚ñà‚ñè        | 184/1540 [07:25<54:51,  2.43s/it] 12%|‚ñà‚ñè        | 185/1540 [07:28<54:46,  2.43s/it] 12%|‚ñà‚ñè        | 186/1540 [07:30<54:41,  2.42s/it] 12%|‚ñà‚ñè        | 187/1540 [07:33<54:38,  2.42s/it] 12%|‚ñà‚ñè        | 188/1540 [07:35<54:34,  2.42s/it] 12%|‚ñà‚ñè        | 189/1540 [07:38<54:31,  2.42s/it] 12%|‚ñà‚ñè        | 190/1540 [07:40<54:28,  2.42s/it] 12%|‚ñà‚ñè        | 191/1540 [07:42<54:26,  2.42s/it] 12%|‚ñà‚ñè        | 192/1540 [07:45<54:23,  2.42s/it] 13%|‚ñà‚ñé        | 193/1540 [07:47<54:21,  2.42s/it] 13%|‚ñà‚ñé        | 194/1540 [07:50<54:18,  2.42s/it] 13%|‚ñà‚ñé        | 195/1540 [07:52<54:44,  2.44s/it] 13%|‚ñà‚ñé        | 196/1540 [07:55<54:32,  2.44s/it] 13%|‚ñà‚ñé        | 197/1540 [07:57<54:25,  2.43s/it] 13%|‚ñà‚ñé        | 198/1540 [07:59<54:18,  2.43s/it] 13%|‚ñà‚ñé        | 199/1540 [08:02<54:13,  2.43s/it] 13%|‚ñà‚ñé        | 200/1540 [08:04<54:08,  2.42s/it]                                                  {'loss': 0.8406, 'grad_norm': 0.3517863154411316, 'learning_rate': 0.000323051948051948, 'epoch': 0.65}
 13%|‚ñà‚ñé        | 200/1540 [08:04<54:08,  2.42s/it] 13%|‚ñà‚ñé        | 201/1540 [08:07<54:05,  2.42s/it] 13%|‚ñà‚ñé        | 202/1540 [08:09<54:01,  2.42s/it] 13%|‚ñà‚ñé        | 203/1540 [08:12<53:57,  2.42s/it] 13%|‚ñà‚ñé        | 204/1540 [08:14<53:54,  2.42s/it] 13%|‚ñà‚ñé        | 205/1540 [08:16<53:52,  2.42s/it] 13%|‚ñà‚ñé        | 206/1540 [08:19<53:49,  2.42s/it] 13%|‚ñà‚ñé        | 207/1540 [08:21<53:46,  2.42s/it] 14%|‚ñà‚ñé        | 208/1540 [08:24<53:44,  2.42s/it] 14%|‚ñà‚ñé        | 209/1540 [08:26<53:47,  2.42s/it] 14%|‚ñà‚ñé        | 210/1540 [08:28<53:42,  2.42s/it] 14%|‚ñà‚ñé        | 211/1540 [08:31<53:39,  2.42s/it] 14%|‚ñà‚ñç        | 212/1540 [08:33<53:35,  2.42s/it] 14%|‚ñà‚ñç        | 213/1540 [08:36<53:32,  2.42s/it] 14%|‚ñà‚ñç        | 214/1540 [08:38<53:29,  2.42s/it] 14%|‚ñà‚ñç        | 215/1540 [08:41<53:27,  2.42s/it] 14%|‚ñà‚ñç        | 216/1540 [08:43<53:25,  2.42s/it] 14%|‚ñà‚ñç        | 217/1540 [08:45<53:22,  2.42s/it] 14%|‚ñà‚ñç        | 218/1540 [08:48<53:20,  2.42s/it] 14%|‚ñà‚ñç        | 219/1540 [08:50<53:17,  2.42s/it] 14%|‚ñà‚ñç        | 220/1540 [08:53<53:15,  2.42s/it]                                                  {'loss': 0.899, 'grad_norm': 0.4229690134525299, 'learning_rate': 0.00035551948051948054, 'epoch': 0.71}
 14%|‚ñà‚ñç        | 220/1540 [08:53<53:15,  2.42s/it] 14%|‚ñà‚ñç        | 221/1540 [08:55<53:13,  2.42s/it] 14%|‚ñà‚ñç        | 222/1540 [08:58<53:14,  2.42s/it] 14%|‚ñà‚ñç        | 223/1540 [09:00<53:10,  2.42s/it] 15%|‚ñà‚ñç        | 224/1540 [09:02<53:07,  2.42s/it] 15%|‚ñà‚ñç        | 225/1540 [09:05<53:03,  2.42s/it] 15%|‚ñà‚ñç        | 226/1540 [09:07<53:00,  2.42s/it] 15%|‚ñà‚ñç        | 227/1540 [09:10<52:58,  2.42s/it] 15%|‚ñà‚ñç        | 228/1540 [09:12<52:56,  2.42s/it] 15%|‚ñà‚ñç        | 229/1540 [09:14<52:53,  2.42s/it] 15%|‚ñà‚ñç        | 230/1540 [09:17<52:50,  2.42s/it] 15%|‚ñà‚ñå        | 231/1540 [09:19<52:48,  2.42s/it] 15%|‚ñà‚ñå        | 232/1540 [09:22<52:45,  2.42s/it] 15%|‚ñà‚ñå        | 233/1540 [09:24<52:43,  2.42s/it] 15%|‚ñà‚ñå        | 234/1540 [09:27<52:41,  2.42s/it] 15%|‚ñà‚ñå        | 235/1540 [09:29<52:38,  2.42s/it] 15%|‚ñà‚ñå        | 236/1540 [09:31<52:36,  2.42s/it] 15%|‚ñà‚ñå        | 237/1540 [09:34<52:45,  2.43s/it] 15%|‚ñà‚ñå        | 238/1540 [09:36<52:38,  2.43s/it] 16%|‚ñà‚ñå        | 239/1540 [09:39<52:33,  2.42s/it] 16%|‚ñà‚ñå        | 240/1540 [09:41<52:29,  2.42s/it]                                                  {'loss': 0.8269, 'grad_norm': 0.3053847551345825, 'learning_rate': 0.000387987012987013, 'epoch': 0.78}
 16%|‚ñà‚ñå        | 240/1540 [09:41<52:29,  2.42s/it] 16%|‚ñà‚ñå        | 241/1540 [09:44<52:27,  2.42s/it] 16%|‚ñà‚ñå        | 242/1540 [09:46<52:35,  2.43s/it] 16%|‚ñà‚ñå        | 243/1540 [09:48<52:28,  2.43s/it] 16%|‚ñà‚ñå        | 244/1540 [09:51<52:23,  2.43s/it] 16%|‚ñà‚ñå        | 245/1540 [09:53<52:18,  2.42s/it] 16%|‚ñà‚ñå        | 246/1540 [09:56<52:14,  2.42s/it] 16%|‚ñà‚ñå        | 247/1540 [09:58<52:13,  2.42s/it] 16%|‚ñà‚ñå        | 248/1540 [10:01<52:09,  2.42s/it] 16%|‚ñà‚ñå        | 249/1540 [10:03<52:05,  2.42s/it] 16%|‚ñà‚ñå        | 250/1540 [10:05<52:02,  2.42s/it] 16%|‚ñà‚ñã        | 251/1540 [10:08<51:59,  2.42s/it] 16%|‚ñà‚ñã        | 252/1540 [10:10<51:57,  2.42s/it] 16%|‚ñà‚ñã        | 253/1540 [10:13<51:54,  2.42s/it] 16%|‚ñà‚ñã        | 254/1540 [10:15<51:52,  2.42s/it] 17%|‚ñà‚ñã        | 255/1540 [10:17<51:49,  2.42s/it] 17%|‚ñà‚ñã        | 256/1540 [10:20<51:47,  2.42s/it] 17%|‚ñà‚ñã        | 257/1540 [10:22<51:45,  2.42s/it] 17%|‚ñà‚ñã        | 258/1540 [10:25<51:42,  2.42s/it] 17%|‚ñà‚ñã        | 259/1540 [10:27<51:40,  2.42s/it] 17%|‚ñà‚ñã        | 260/1540 [10:30<51:37,  2.42s/it]                                                  {'loss': 0.8515, 'grad_norm': 0.26355016231536865, 'learning_rate': 0.0004204545454545455, 'epoch': 0.84}
 17%|‚ñà‚ñã        | 260/1540 [10:30<51:37,  2.42s/it] 17%|‚ñà‚ñã        | 261/1540 [10:32<51:36,  2.42s/it] 17%|‚ñà‚ñã        | 262/1540 [10:34<51:33,  2.42s/it] 17%|‚ñà‚ñã        | 263/1540 [10:37<51:31,  2.42s/it] 17%|‚ñà‚ñã        | 264/1540 [10:39<51:28,  2.42s/it] 17%|‚ñà‚ñã        | 265/1540 [10:42<51:50,  2.44s/it] 17%|‚ñà‚ñã        | 266/1540 [10:44<51:40,  2.43s/it] 17%|‚ñà‚ñã        | 267/1540 [10:47<51:33,  2.43s/it] 17%|‚ñà‚ñã        | 268/1540 [10:49<51:27,  2.43s/it] 17%|‚ñà‚ñã        | 269/1540 [10:51<51:22,  2.43s/it] 18%|‚ñà‚ñä        | 270/1540 [10:54<51:17,  2.42s/it] 18%|‚ñà‚ñä        | 271/1540 [10:56<51:14,  2.42s/it] 18%|‚ñà‚ñä        | 272/1540 [10:59<51:11,  2.42s/it] 18%|‚ñà‚ñä        | 273/1540 [11:01<51:08,  2.42s/it] 18%|‚ñà‚ñä        | 274/1540 [11:03<51:05,  2.42s/it] 18%|‚ñà‚ñä        | 275/1540 [11:06<51:02,  2.42s/it] 18%|‚ñà‚ñä        | 276/1540 [11:08<50:59,  2.42s/it] 18%|‚ñà‚ñä        | 277/1540 [11:11<50:57,  2.42s/it] 18%|‚ñà‚ñä        | 278/1540 [11:13<51:02,  2.43s/it] 18%|‚ñà‚ñä        | 279/1540 [11:16<50:57,  2.42s/it] 18%|‚ñà‚ñä        | 280/1540 [11:18<50:53,  2.42s/it]                                                  {'loss': 0.8241, 'grad_norm': 0.28401023149490356, 'learning_rate': 0.00045292207792207794, 'epoch': 0.91}
 18%|‚ñà‚ñä        | 280/1540 [11:18<50:53,  2.42s/it] 18%|‚ñà‚ñä        | 281/1540 [11:20<50:50,  2.42s/it] 18%|‚ñà‚ñä        | 282/1540 [11:23<50:46,  2.42s/it] 18%|‚ñà‚ñä        | 283/1540 [11:25<50:43,  2.42s/it] 18%|‚ñà‚ñä        | 284/1540 [11:28<50:40,  2.42s/it] 19%|‚ñà‚ñä        | 285/1540 [11:30<50:38,  2.42s/it] 19%|‚ñà‚ñä        | 286/1540 [11:33<50:43,  2.43s/it] 19%|‚ñà‚ñä        | 287/1540 [11:35<50:38,  2.42s/it] 19%|‚ñà‚ñä        | 288/1540 [11:37<50:34,  2.42s/it] 19%|‚ñà‚ñâ        | 289/1540 [11:40<50:30,  2.42s/it] 19%|‚ñà‚ñâ        | 290/1540 [11:42<50:27,  2.42s/it] 19%|‚ñà‚ñâ        | 291/1540 [11:45<50:24,  2.42s/it] 19%|‚ñà‚ñâ        | 292/1540 [11:47<50:21,  2.42s/it] 19%|‚ñà‚ñâ        | 293/1540 [11:50<50:18,  2.42s/it] 19%|‚ñà‚ñâ        | 294/1540 [11:52<50:16,  2.42s/it] 19%|‚ñà‚ñâ        | 295/1540 [11:54<50:13,  2.42s/it] 19%|‚ñà‚ñâ        | 296/1540 [11:57<50:10,  2.42s/it] 19%|‚ñà‚ñâ        | 297/1540 [11:59<50:09,  2.42s/it] 19%|‚ñà‚ñâ        | 298/1540 [12:02<50:06,  2.42s/it] 19%|‚ñà‚ñâ        | 299/1540 [12:04<50:04,  2.42s/it] 19%|‚ñà‚ñâ        | 300/1540 [12:06<50:01,  2.42s/it]                                                  {'loss': 0.8575, 'grad_norm': 0.3434644341468811, 'learning_rate': 0.00048538961038961035, 'epoch': 0.97}
 19%|‚ñà‚ñâ        | 300/1540 [12:06<50:01,  2.42s/it] 20%|‚ñà‚ñâ        | 301/1540 [12:09<49:59,  2.42s/it] 20%|‚ñà‚ñâ        | 302/1540 [12:11<49:56,  2.42s/it] 20%|‚ñà‚ñâ        | 303/1540 [12:14<49:54,  2.42s/it] 20%|‚ñà‚ñâ        | 304/1540 [12:16<49:52,  2.42s/it] 20%|‚ñà‚ñâ        | 305/1540 [12:19<49:49,  2.42s/it] 20%|‚ñà‚ñâ        | 306/1540 [12:21<49:46,  2.42s/it] 20%|‚ñà‚ñâ        | 307/1540 [12:23<49:56,  2.43s/it] 20%|‚ñà‚ñà        | 308/1540 [12:26<49:49,  2.43s/it] 20%|‚ñà‚ñà        | 309/1540 [12:28<49:45,  2.42s/it] 20%|‚ñà‚ñà        | 310/1540 [12:31<49:41,  2.42s/it] 20%|‚ñà‚ñà        | 311/1540 [12:33<49:37,  2.42s/it] 20%|‚ñà‚ñà        | 312/1540 [12:36<49:33,  2.42s/it] 20%|‚ñà‚ñà        | 313/1540 [12:38<49:30,  2.42s/it] 20%|‚ñà‚ñà        | 314/1540 [12:40<49:28,  2.42s/it] 20%|‚ñà‚ñà        | 315/1540 [12:43<49:25,  2.42s/it] 21%|‚ñà‚ñà        | 316/1540 [12:45<49:22,  2.42s/it] 21%|‚ñà‚ñà        | 317/1540 [12:48<49:19,  2.42s/it] 21%|‚ñà‚ñà        | 318/1540 [12:50<49:17,  2.42s/it] 21%|‚ñà‚ñà        | 319/1540 [12:52<49:14,  2.42s/it] 21%|‚ñà‚ñà        | 320/1540 [12:55<49:11,  2.42s/it]                                                  {'loss': 0.8292, 'grad_norm': 0.42198610305786133, 'learning_rate': 0.0004999016565957633, 'epoch': 1.04}
 21%|‚ñà‚ñà        | 320/1540 [12:55<49:11,  2.42s/it] 21%|‚ñà‚ñà        | 321/1540 [12:57<49:10,  2.42s/it] 21%|‚ñà‚ñà        | 322/1540 [13:00<49:07,  2.42s/it] 21%|‚ñà‚ñà        | 323/1540 [13:02<49:05,  2.42s/it] 21%|‚ñà‚ñà        | 324/1540 [13:05<49:02,  2.42s/it] 21%|‚ñà‚ñà        | 325/1540 [13:07<49:00,  2.42s/it] 21%|‚ñà‚ñà        | 326/1540 [13:09<48:57,  2.42s/it] 21%|‚ñà‚ñà        | 327/1540 [13:12<48:54,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 328/1540 [13:14<48:53,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 329/1540 [13:17<48:50,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 330/1540 [13:19<48:48,  2.42s/it] 21%|‚ñà‚ñà‚ñè       | 331/1540 [13:22<48:45,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 332/1540 [13:24<48:44,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 333/1540 [13:26<48:41,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 334/1540 [13:29<49:05,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 335/1540 [13:31<48:55,  2.44s/it] 22%|‚ñà‚ñà‚ñè       | 336/1540 [13:34<48:47,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 337/1540 [13:36<48:40,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 338/1540 [13:39<48:35,  2.43s/it] 22%|‚ñà‚ñà‚ñè       | 339/1540 [13:41<48:30,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 340/1540 [13:43<48:26,  2.42s/it]                                                  {'loss': 0.7857, 'grad_norm': 0.3553069531917572, 'learning_rate': 0.0004992192975102804, 'epoch': 1.1}
 22%|‚ñà‚ñà‚ñè       | 340/1540 [13:43<48:26,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 341/1540 [13:46<48:24,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 342/1540 [13:48<48:20,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 343/1540 [13:51<48:17,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 344/1540 [13:53<48:14,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 345/1540 [13:55<48:11,  2.42s/it] 22%|‚ñà‚ñà‚ñè       | 346/1540 [13:58<48:09,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 347/1540 [14:00<48:06,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 348/1540 [14:03<48:12,  2.43s/it] 23%|‚ñà‚ñà‚ñé       | 349/1540 [14:05<48:07,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 350/1540 [14:08<48:03,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 351/1540 [14:10<48:00,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 352/1540 [14:12<47:56,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 353/1540 [14:15<47:55,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 354/1540 [14:17<47:51,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 355/1540 [14:20<47:48,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 356/1540 [14:22<47:45,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 357/1540 [14:25<47:42,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 358/1540 [14:27<47:41,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 359/1540 [14:29<47:38,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 360/1540 [14:32<47:36,  2.42s/it]                                                  {'loss': 0.7297, 'grad_norm': 0.40408095717430115, 'learning_rate': 0.0004978888625516589, 'epoch': 1.17}
 23%|‚ñà‚ñà‚ñé       | 360/1540 [14:32<47:36,  2.42s/it] 23%|‚ñà‚ñà‚ñé       | 361/1540 [14:34<47:35,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 362/1540 [14:37<47:33,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 363/1540 [14:39<47:30,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 364/1540 [14:41<47:27,  2.42s/it] 24%|‚ñà‚ñà‚ñé       | 365/1540 [14:44<47:24,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 366/1540 [14:46<47:21,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 367/1540 [14:49<47:19,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 368/1540 [14:51<47:16,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 369/1540 [14:54<47:14,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 370/1540 [14:56<47:11,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 371/1540 [14:58<47:09,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 372/1540 [15:01<47:06,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 373/1540 [15:03<47:13,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 374/1540 [15:06<47:08,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 375/1540 [15:08<47:03,  2.42s/it] 24%|‚ñà‚ñà‚ñç       | 376/1540 [15:11<47:07,  2.43s/it] 24%|‚ñà‚ñà‚ñç       | 377/1540 [15:13<47:01,  2.43s/it] 25%|‚ñà‚ñà‚ñç       | 378/1540 [15:15<46:56,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 379/1540 [15:18<46:52,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 380/1540 [15:20<46:49,  2.42s/it]                                                  {'loss': 0.7709, 'grad_norm': 0.4290267825126648, 'learning_rate': 0.0004959138114150592, 'epoch': 1.23}
 25%|‚ñà‚ñà‚ñç       | 380/1540 [15:20<46:49,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 381/1540 [15:23<46:47,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 382/1540 [15:25<46:43,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 383/1540 [15:28<46:40,  2.42s/it] 25%|‚ñà‚ñà‚ñç       | 384/1540 [15:30<46:38,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 385/1540 [15:32<46:35,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 386/1540 [15:35<46:32,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 387/1540 [15:37<46:30,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 388/1540 [15:40<46:28,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 389/1540 [15:42<46:32,  2.43s/it] 25%|‚ñà‚ñà‚ñå       | 390/1540 [15:44<46:27,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 391/1540 [15:47<46:23,  2.42s/it] 25%|‚ñà‚ñà‚ñå       | 392/1540 [15:49<46:20,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 393/1540 [15:52<46:17,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 394/1540 [15:54<46:14,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 395/1540 [15:57<46:11,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 396/1540 [15:59<46:09,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 397/1540 [16:01<46:06,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 398/1540 [16:04<46:04,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 399/1540 [16:06<46:02,  2.42s/it] 26%|‚ñà‚ñà‚ñå       | 400/1540 [16:09<45:59,  2.42s/it]                                                  {'loss': 0.7286, 'grad_norm': 0.41215240955352783, 'learning_rate': 0.0004932992800711009, 'epoch': 1.3}
 26%|‚ñà‚ñà‚ñå       | 400/1540 [16:09<45:59,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 07:38:22,536 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-400
[INFO|configuration_utils.py:726] 2024-05-25 07:38:23,421 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:38:23,423 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 07:38:23,494 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 07:38:23,494 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-400/special_tokens_map.json
 26%|‚ñà‚ñà‚ñå       | 401/1540 [16:12<52:13,  2.75s/it] 26%|‚ñà‚ñà‚ñå       | 402/1540 [16:15<50:18,  2.65s/it] 26%|‚ñà‚ñà‚ñå       | 403/1540 [16:17<48:56,  2.58s/it] 26%|‚ñà‚ñà‚ñå       | 404/1540 [16:20<48:20,  2.55s/it] 26%|‚ñà‚ñà‚ñã       | 405/1540 [16:22<47:32,  2.51s/it] 26%|‚ñà‚ñà‚ñã       | 406/1540 [16:24<46:57,  2.48s/it] 26%|‚ñà‚ñà‚ñã       | 407/1540 [16:27<46:32,  2.47s/it] 26%|‚ñà‚ñà‚ñã       | 408/1540 [16:29<46:15,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 409/1540 [16:32<46:02,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 410/1540 [16:34<45:52,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 411/1540 [16:36<45:45,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 412/1540 [16:39<45:38,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 413/1540 [16:41<45:33,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 414/1540 [16:44<45:29,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 415/1540 [16:46<46:01,  2.45s/it] 27%|‚ñà‚ñà‚ñã       | 416/1540 [16:49<45:46,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 417/1540 [16:51<45:44,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 418/1540 [16:54<45:33,  2.44s/it] 27%|‚ñà‚ñà‚ñã       | 419/1540 [16:56<45:25,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 420/1540 [16:58<45:19,  2.43s/it]                                                  {'loss': 0.7794, 'grad_norm': 0.345782995223999, 'learning_rate': 0.0004900520674101607, 'epoch': 1.36}
 27%|‚ñà‚ñà‚ñã       | 420/1540 [16:58<45:19,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 421/1540 [17:01<45:15,  2.43s/it] 27%|‚ñà‚ñà‚ñã       | 422/1540 [17:03<45:10,  2.42s/it] 27%|‚ñà‚ñà‚ñã       | 423/1540 [17:06<45:07,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 424/1540 [17:08<45:03,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 425/1540 [17:10<45:00,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 426/1540 [17:13<44:57,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 427/1540 [17:15<44:54,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 428/1540 [17:18<44:51,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 429/1540 [17:20<44:48,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 430/1540 [17:23<44:46,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 431/1540 [17:25<44:43,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 432/1540 [17:27<44:41,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 433/1540 [17:30<44:39,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 434/1540 [17:32<44:37,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 435/1540 [17:35<44:34,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 436/1540 [17:37<44:31,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 437/1540 [17:40<44:32,  2.42s/it] 28%|‚ñà‚ñà‚ñä       | 438/1540 [17:42<44:29,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 439/1540 [17:44<44:26,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 440/1540 [17:47<44:24,  2.42s/it]                                                  {'loss': 0.7158, 'grad_norm': 0.4016563594341278, 'learning_rate': 0.0004861806175623745, 'epoch': 1.43}
 29%|‚ñà‚ñà‚ñä       | 440/1540 [17:47<44:24,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 441/1540 [17:49<44:21,  2.42s/it] 29%|‚ñà‚ñà‚ñä       | 442/1540 [17:52<44:18,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 443/1540 [17:54<44:20,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 444/1540 [17:56<44:15,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 445/1540 [17:59<44:12,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 446/1540 [18:01<44:18,  2.43s/it] 29%|‚ñà‚ñà‚ñâ       | 447/1540 [18:04<44:13,  2.43s/it] 29%|‚ñà‚ñà‚ñâ       | 448/1540 [18:06<44:08,  2.43s/it] 29%|‚ñà‚ñà‚ñâ       | 449/1540 [18:09<44:04,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 450/1540 [18:11<44:00,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 451/1540 [18:13<43:57,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 452/1540 [18:16<43:55,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 453/1540 [18:18<43:53,  2.42s/it] 29%|‚ñà‚ñà‚ñâ       | 454/1540 [18:21<43:50,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 455/1540 [18:23<43:47,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 456/1540 [18:26<43:44,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 457/1540 [18:28<43:41,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 458/1540 [18:30<43:39,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 459/1540 [18:33<43:41,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 460/1540 [18:35<43:37,  2.42s/it]                                                  {'loss': 0.7686, 'grad_norm': 0.43257206678390503, 'learning_rate': 0.0004816949979393171, 'epoch': 1.49}
 30%|‚ñà‚ñà‚ñâ       | 460/1540 [18:35<43:37,  2.42s/it] 30%|‚ñà‚ñà‚ñâ       | 461/1540 [18:38<43:34,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 462/1540 [18:40<43:30,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 463/1540 [18:43<43:28,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 464/1540 [18:45<43:25,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 465/1540 [18:47<43:22,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 466/1540 [18:50<43:19,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 467/1540 [18:52<43:17,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 468/1540 [18:55<43:14,  2.42s/it] 30%|‚ñà‚ñà‚ñà       | 469/1540 [18:57<43:12,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 470/1540 [18:59<43:09,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 471/1540 [19:02<43:07,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 472/1540 [19:04<43:04,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 473/1540 [19:07<43:23,  2.44s/it] 31%|‚ñà‚ñà‚ñà       | 474/1540 [19:09<43:14,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 475/1540 [19:12<43:07,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 476/1540 [19:14<43:01,  2.43s/it] 31%|‚ñà‚ñà‚ñà       | 477/1540 [19:16<42:56,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 478/1540 [19:19<42:52,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 479/1540 [19:21<42:49,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 480/1540 [19:24<42:46,  2.42s/it]                                                  {'loss': 0.7616, 'grad_norm': 0.4735579192638397, 'learning_rate': 0.00047660687305446235, 'epoch': 1.56}
 31%|‚ñà‚ñà‚ñà       | 480/1540 [19:24<42:46,  2.42s/it] 31%|‚ñà‚ñà‚ñà       | 481/1540 [19:26<42:44,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 482/1540 [19:29<42:41,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 483/1540 [19:31<42:38,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 484/1540 [19:33<42:36,  2.42s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 485/1540 [19:36<42:33,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 486/1540 [19:38<42:30,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 487/1540 [19:41<42:32,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 488/1540 [19:43<42:28,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 489/1540 [19:46<42:25,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 490/1540 [19:48<42:22,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 491/1540 [19:50<42:19,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 492/1540 [19:53<42:16,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 493/1540 [19:55<42:14,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 494/1540 [19:58<42:13,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 495/1540 [20:00<42:10,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 496/1540 [20:02<42:07,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 497/1540 [20:05<42:04,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 498/1540 [20:07<42:02,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 499/1540 [20:10<41:59,  2.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 500/1540 [20:12<41:56,  2.42s/it]                                                  {'loss': 0.7442, 'grad_norm': nan, 'learning_rate': 0.0004712271175980134, 'epoch': 1.62}
 32%|‚ñà‚ñà‚ñà‚ñè      | 500/1540 [20:12<41:56,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 501/1540 [20:15<41:55,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 502/1540 [20:17<41:52,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 503/1540 [20:19<41:50,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 504/1540 [20:22<41:47,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 505/1540 [20:24<41:44,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 506/1540 [20:27<41:42,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 507/1540 [20:29<41:40,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 508/1540 [20:32<41:37,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 509/1540 [20:34<41:35,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 510/1540 [20:36<41:32,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 511/1540 [20:39<41:30,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 512/1540 [20:41<41:27,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 513/1540 [20:44<41:25,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 514/1540 [20:46<41:22,  2.42s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 515/1540 [20:48<41:27,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 516/1540 [20:51<41:22,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 517/1540 [20:53<41:22,  2.43s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 518/1540 [20:56<41:17,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 519/1540 [20:58<41:13,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1540 [21:01<41:10,  2.42s/it]                                                  {'loss': 0.6686, 'grad_norm': 0.3766549825668335, 'learning_rate': 0.0004650035600519251, 'epoch': 1.69}
 34%|‚ñà‚ñà‚ñà‚ñç      | 520/1540 [21:01<41:10,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 521/1540 [21:03<41:07,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 522/1540 [21:05<41:04,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 523/1540 [21:08<41:01,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 524/1540 [21:10<40:59,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 525/1540 [21:13<40:56,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 526/1540 [21:15<40:53,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 527/1540 [21:18<40:51,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 528/1540 [21:20<40:50,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 529/1540 [21:22<40:47,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 530/1540 [21:25<40:44,  2.42s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 531/1540 [21:27<40:41,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 532/1540 [21:30<40:39,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 533/1540 [21:32<40:36,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 534/1540 [21:34<40:34,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 535/1540 [21:37<40:32,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 536/1540 [21:39<40:30,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 537/1540 [21:42<40:27,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 538/1540 [21:44<40:25,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 539/1540 [21:47<40:22,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1540 [21:49<40:20,  2.42s/it]                                                  {'loss': 0.7021, 'grad_norm': 0.4114067554473877, 'learning_rate': 0.0004582209020617679, 'epoch': 1.75}
 35%|‚ñà‚ñà‚ñà‚ñå      | 540/1540 [21:49<40:20,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 541/1540 [21:51<40:18,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 542/1540 [21:54<40:15,  2.42s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 543/1540 [21:56<40:31,  2.44s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 544/1540 [21:59<40:23,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 545/1540 [22:01<40:17,  2.43s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 546/1540 [22:04<40:12,  2.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 547/1540 [22:06<40:07,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 548/1540 [22:08<40:03,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 549/1540 [22:11<40:00,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 550/1540 [22:13<39:57,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 551/1540 [22:16<39:54,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 552/1540 [22:18<39:51,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 553/1540 [22:21<39:48,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 554/1540 [22:23<39:46,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 555/1540 [22:25<39:43,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 556/1540 [22:28<39:44,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 557/1540 [22:30<39:41,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 558/1540 [22:33<39:37,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 559/1540 [22:35<39:35,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1540 [22:37<39:32,  2.42s/it]                                                  {'loss': 0.6596, 'grad_norm': 0.4850960075855255, 'learning_rate': 0.0004508967814149967, 'epoch': 1.82}
 36%|‚ñà‚ñà‚ñà‚ñã      | 560/1540 [22:37<39:32,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 561/1540 [22:40<39:30,  2.42s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 562/1540 [22:42<39:27,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 563/1540 [22:45<39:25,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 564/1540 [22:47<39:22,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 565/1540 [22:50<39:19,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 566/1540 [22:52<39:17,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 567/1540 [22:54<39:15,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 568/1540 [22:57<39:13,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 569/1540 [22:59<39:11,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 570/1540 [23:02<39:08,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 571/1540 [23:04<39:05,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 572/1540 [23:07<39:03,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 573/1540 [23:09<39:00,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 574/1540 [23:11<38:57,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 575/1540 [23:14<38:55,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 576/1540 [23:16<38:53,  2.42s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 577/1540 [23:19<38:50,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 578/1540 [23:21<38:47,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 579/1540 [23:23<38:45,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1540 [23:26<38:43,  2.42s/it]                                                  {'loss': 0.6934, 'grad_norm': 0.4100537598133087, 'learning_rate': 0.0004430502439316204, 'epoch': 1.88}
 38%|‚ñà‚ñà‚ñà‚ñä      | 580/1540 [23:26<38:43,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 581/1540 [23:28<38:41,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 582/1540 [23:31<38:39,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 583/1540 [23:33<38:36,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 584/1540 [23:36<38:33,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 585/1540 [23:38<38:31,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 586/1540 [23:40<38:29,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 587/1540 [23:43<38:27,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 588/1540 [23:45<38:24,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 589/1540 [23:48<38:22,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 590/1540 [23:50<38:19,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 591/1540 [23:52<38:16,  2.42s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 592/1540 [23:55<38:14,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 593/1540 [23:57<38:11,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 594/1540 [24:00<38:09,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 595/1540 [24:02<38:07,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 596/1540 [24:05<38:04,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 597/1540 [24:07<38:02,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 598/1540 [24:09<38:01,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 599/1540 [24:12<37:58,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1540 [24:14<37:55,  2.42s/it]                                                  {'loss': 0.7308, 'grad_norm': 0.4114418923854828, 'learning_rate': 0.000434701693936992, 'epoch': 1.95}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 600/1540 [24:14<37:55,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 601/1540 [24:17<37:53,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 602/1540 [24:19<37:50,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 603/1540 [24:22<37:47,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 604/1540 [24:24<37:48,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 605/1540 [24:26<37:45,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 606/1540 [24:29<37:42,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 607/1540 [24:31<37:38,  2.42s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 608/1540 [24:34<37:35,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 609/1540 [24:36<37:33,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 610/1540 [24:38<37:30,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 611/1540 [24:41<37:28,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 612/1540 [24:43<37:47,  2.44s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 613/1540 [24:46<37:38,  2.44s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 614/1540 [24:48<37:31,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 615/1540 [24:51<37:25,  2.43s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 616/1540 [24:53<37:20,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 617/1540 [24:56<37:17,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 618/1540 [24:58<37:13,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 619/1540 [25:00<37:10,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1540 [25:03<37:07,  2.42s/it]                                                  {'loss': 0.6242, 'grad_norm': 0.4817900061607361, 'learning_rate': 0.00042587284120190896, 'epoch': 2.01}
 40%|‚ñà‚ñà‚ñà‚ñà      | 620/1540 [25:03<37:07,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 621/1540 [25:05<37:05,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 622/1540 [25:08<37:02,  2.42s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 623/1540 [25:10<36:59,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 624/1540 [25:12<36:57,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 625/1540 [25:15<36:54,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 626/1540 [25:17<36:54,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 627/1540 [25:20<36:51,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 628/1540 [25:22<36:48,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 629/1540 [25:25<36:45,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 630/1540 [25:27<36:43,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 631/1540 [25:29<36:40,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 632/1540 [25:32<36:37,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 633/1540 [25:34<36:35,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 634/1540 [25:37<36:32,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 635/1540 [25:39<36:30,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 636/1540 [25:42<36:27,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 637/1540 [25:44<36:25,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 638/1540 [25:46<36:23,  2.42s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 639/1540 [25:49<36:23,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1540 [25:51<36:20,  2.42s/it]                                                  {'loss': 0.6025, 'grad_norm': 0.38645270466804504, 'learning_rate': 0.000416586644488001, 'epoch': 2.08}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 640/1540 [25:51<36:20,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 641/1540 [25:54<36:17,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 642/1540 [25:56<36:14,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 643/1540 [25:58<36:11,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 644/1540 [26:01<36:08,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 645/1540 [26:03<36:05,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 646/1540 [26:06<36:03,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 647/1540 [26:08<36:00,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 648/1540 [26:11<35:58,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 649/1540 [26:13<35:55,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 650/1540 [26:15<35:53,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 651/1540 [26:18<35:51,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 652/1540 [26:20<35:49,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 653/1540 [26:23<35:46,  2.42s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 654/1540 [26:25<35:44,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 655/1540 [26:27<35:41,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 656/1540 [26:30<35:39,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 657/1540 [26:32<35:36,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 658/1540 [26:35<35:34,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 659/1540 [26:37<35:31,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1540 [26:40<35:29,  2.42s/it]                                                  {'loss': 0.6377, 'grad_norm': 0.4365008473396301, 'learning_rate': 0.000406867251845213, 'epoch': 2.14}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 660/1540 [26:40<35:29,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 661/1540 [26:42<35:27,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 662/1540 [26:44<35:25,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 663/1540 [26:47<35:22,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 664/1540 [26:49<35:20,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 665/1540 [26:52<35:17,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 666/1540 [26:54<35:15,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 667/1540 [26:57<35:16,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 668/1540 [26:59<35:12,  2.42s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 669/1540 [27:01<35:09,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 670/1540 [27:04<35:06,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 671/1540 [27:06<35:03,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 672/1540 [27:09<35:01,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 673/1540 [27:11<34:58,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 674/1540 [27:13<34:56,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 675/1540 [27:16<34:53,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 676/1540 [27:18<34:51,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 677/1540 [27:21<34:48,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 678/1540 [27:23<34:45,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 679/1540 [27:26<34:44,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1540 [27:28<34:41,  2.42s/it]                                                  {'loss': 0.5872, 'grad_norm': 0.3745628893375397, 'learning_rate': 0.0003967399378166333, 'epoch': 2.21}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 680/1540 [27:28<34:41,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 681/1540 [27:30<34:39,  2.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 682/1540 [27:33<34:57,  2.44s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 683/1540 [27:35<34:48,  2.44s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 684/1540 [27:38<34:41,  2.43s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 685/1540 [27:40<34:36,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 686/1540 [27:43<34:31,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 687/1540 [27:45<34:27,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 688/1540 [27:47<34:24,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 689/1540 [27:50<34:20,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 690/1540 [27:52<34:17,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 691/1540 [27:55<34:21,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 692/1540 [27:57<34:16,  2.43s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 693/1540 [28:00<34:12,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 694/1540 [28:02<34:09,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 695/1540 [28:04<34:06,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 696/1540 [28:07<34:03,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 697/1540 [28:09<34:00,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 698/1540 [28:12<33:57,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 699/1540 [28:14<33:55,  2.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1540 [28:17<33:54,  2.42s/it]                                                  {'loss': 0.5611, 'grad_norm': 0.45378556847572327, 'learning_rate': 0.00038623103771396195, 'epoch': 2.27}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 700/1540 [28:17<33:54,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 701/1540 [28:19<33:52,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 702/1540 [28:21<33:49,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 703/1540 [28:24<33:46,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 704/1540 [28:26<33:43,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 705/1540 [28:29<33:41,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 706/1540 [28:31<33:38,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 707/1540 [28:33<33:36,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 708/1540 [28:36<33:33,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 709/1540 [28:38<33:31,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 710/1540 [28:41<33:28,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 711/1540 [28:43<33:26,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 712/1540 [28:46<33:23,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 713/1540 [28:48<33:21,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 714/1540 [28:50<33:19,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 715/1540 [28:53<33:16,  2.42s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 716/1540 [28:55<33:14,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 717/1540 [28:58<33:11,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 718/1540 [29:00<33:08,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 719/1540 [29:03<33:06,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1540 [29:05<33:04,  2.42s/it]                                                  {'loss': 0.5538, 'grad_norm': 0.4519694447517395, 'learning_rate': 0.00037536787913453106, 'epoch': 2.34}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 720/1540 [29:05<33:04,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 721/1540 [29:07<33:02,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 722/1540 [29:10<32:59,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 723/1540 [29:12<32:56,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 724/1540 [29:15<32:59,  2.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 725/1540 [29:17<32:55,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 726/1540 [29:19<32:52,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 727/1540 [29:22<32:48,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 728/1540 [29:24<32:46,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 729/1540 [29:27<32:43,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 730/1540 [29:29<32:40,  2.42s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 731/1540 [29:32<32:38,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 732/1540 [29:34<32:36,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 733/1540 [29:36<32:33,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 734/1540 [29:39<32:30,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 735/1540 [29:41<32:28,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 736/1540 [29:44<32:25,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 737/1540 [29:46<32:25,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 738/1540 [29:49<32:22,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 739/1540 [29:51<32:19,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1540 [29:53<32:16,  2.42s/it]                                                  {'loss': 0.5662, 'grad_norm': 0.47021204233169556, 'learning_rate': 0.0003641787108979617, 'epoch': 2.4}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 740/1540 [29:53<32:16,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 741/1540 [29:56<32:14,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 742/1540 [29:58<32:11,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 743/1540 [30:01<32:08,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 744/1540 [30:03<32:06,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 745/1540 [30:05<32:03,  2.42s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 746/1540 [30:08<32:01,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 747/1540 [30:10<31:58,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 748/1540 [30:13<31:56,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 749/1540 [30:15<31:54,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 750/1540 [30:18<31:51,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 751/1540 [30:20<32:06,  2.44s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 752/1540 [30:22<31:58,  2.44s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 753/1540 [30:25<31:52,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 754/1540 [30:27<31:47,  2.43s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 755/1540 [30:30<31:43,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 756/1540 [30:32<31:39,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 757/1540 [30:35<31:36,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 758/1540 [30:37<31:33,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 759/1540 [30:39<31:30,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1540 [30:42<31:27,  2.42s/it]                                                  {'loss': 0.584, 'grad_norm': 0.41844773292541504, 'learning_rate': 0.00035269262958725125, 'epoch': 2.47}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 760/1540 [30:42<31:27,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 761/1540 [30:44<31:25,  2.42s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 762/1540 [30:47<31:23,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 763/1540 [30:49<31:20,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 764/1540 [30:51<31:18,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 765/1540 [30:54<31:15,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 766/1540 [30:56<31:13,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 767/1540 [30:59<31:10,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 768/1540 [31:01<31:08,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 769/1540 [31:04<31:05,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 770/1540 [31:06<31:03,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 771/1540 [31:08<31:00,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 772/1540 [31:11<30:58,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 773/1540 [31:13<30:55,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 774/1540 [31:16<30:53,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 775/1540 [31:18<30:50,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 776/1540 [31:21<30:48,  2.42s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 777/1540 [31:23<30:46,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 778/1540 [31:25<30:46,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 779/1540 [31:28<30:42,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1540 [31:30<30:39,  2.42s/it]                                                  {'loss': 0.5634, 'grad_norm': 0.40611985325813293, 'learning_rate': 0.00034093950388531787, 'epoch': 2.53}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 780/1540 [31:30<30:39,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 781/1540 [31:33<30:37,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 782/1540 [31:35<30:35,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 783/1540 [31:37<30:32,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 784/1540 [31:40<30:29,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 785/1540 [31:42<30:27,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 786/1540 [31:45<30:24,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 787/1540 [31:47<30:22,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 788/1540 [31:50<30:19,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 789/1540 [31:52<30:17,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 790/1540 [31:54<30:14,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 791/1540 [31:57<30:12,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 792/1540 [31:59<30:10,  2.42s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 793/1540 [32:02<30:12,  2.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 794/1540 [32:04<30:08,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 795/1540 [32:07<30:04,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 796/1540 [32:09<30:01,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 797/1540 [32:11<29:58,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 798/1540 [32:14<29:56,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 799/1540 [32:16<29:53,  2.42s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1540 [32:19<29:50,  2.42s/it]                                                  {'loss': 0.5555, 'grad_norm': 0.4489195644855499, 'learning_rate': 0.00032894989690375627, 'epoch': 2.6}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 800/1540 [32:19<29:50,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 07:54:32,494 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-800
[INFO|configuration_utils.py:726] 2024-05-25 07:54:33,141 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:54:33,143 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 07:54:34,036 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 07:54:34,039 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 07:54:34,084 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 07:54:34,085 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-800/special_tokens_map.json
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 801/1540 [32:23<36:20,  2.95s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 802/1540 [32:25<34:18,  2.79s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 803/1540 [32:28<32:53,  2.68s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 804/1540 [32:30<31:52,  2.60s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 805/1540 [32:32<31:10,  2.54s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 806/1540 [32:35<30:42,  2.51s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 807/1540 [32:37<30:19,  2.48s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 808/1540 [32:40<30:02,  2.46s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 809/1540 [32:42<29:50,  2.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 810/1540 [32:45<29:40,  2.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 811/1540 [32:47<29:33,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 812/1540 [32:49<29:27,  2.43s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 813/1540 [32:52<29:22,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 814/1540 [32:54<29:18,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 815/1540 [32:57<29:15,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 816/1540 [32:59<29:11,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 817/1540 [33:02<29:08,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 818/1540 [33:04<29:06,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 819/1540 [33:06<29:03,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1540 [33:09<29:01,  2.42s/it]                                                  {'loss': 0.5482, 'grad_norm': 0.4105282425880432, 'learning_rate': 0.0003167549867057854, 'epoch': 2.66}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 820/1540 [33:09<29:01,  2.42s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 821/1540 [33:11<29:19,  2.45s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 822/1540 [33:14<29:10,  2.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 823/1540 [33:16<29:03,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 824/1540 [33:19<28:58,  2.43s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 825/1540 [33:21<28:53,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 826/1540 [33:23<28:49,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 827/1540 [33:26<28:45,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 828/1540 [33:28<28:42,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 829/1540 [33:31<28:39,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 830/1540 [33:33<28:36,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 831/1540 [33:35<28:33,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 832/1540 [33:38<28:31,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 833/1540 [33:40<28:28,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 834/1540 [33:43<28:25,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 835/1540 [33:45<28:23,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 836/1540 [33:48<28:21,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 837/1540 [33:50<28:18,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 838/1540 [33:52<28:16,  2.42s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 839/1540 [33:55<28:15,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1540 [33:57<28:13,  2.42s/it]                                                  {'loss': 0.5384, 'grad_norm': 0.46498122811317444, 'learning_rate': 0.00030438648523006085, 'epoch': 2.73}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 840/1540 [33:57<28:13,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 841/1540 [34:00<28:11,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 842/1540 [34:02<28:09,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 843/1540 [34:04<28:06,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 844/1540 [34:07<28:04,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 845/1540 [34:09<28:01,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 846/1540 [34:12<27:59,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 847/1540 [34:14<27:58,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 848/1540 [34:17<27:55,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 849/1540 [34:19<27:53,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 850/1540 [34:21<27:50,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 851/1540 [34:24<27:47,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 852/1540 [34:26<27:45,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 853/1540 [34:29<27:42,  2.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 854/1540 [34:31<27:40,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 855/1540 [34:34<27:37,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 856/1540 [34:36<27:35,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 857/1540 [34:38<27:32,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 858/1540 [34:41<27:30,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 859/1540 [34:43<27:27,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1540 [34:46<27:25,  2.42s/it]                                                  {'loss': 0.5397, 'grad_norm': 0.4631447494029999, 'learning_rate': 0.0002918765558261841, 'epoch': 2.79}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 860/1540 [34:46<27:25,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 861/1540 [34:48<27:23,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 862/1540 [34:50<27:20,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 863/1540 [34:53<27:22,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 864/1540 [34:55<27:21,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 865/1540 [34:58<27:16,  2.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 866/1540 [35:00<27:13,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 867/1540 [35:03<27:10,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 868/1540 [35:05<27:07,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 869/1540 [35:07<27:04,  2.42s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 870/1540 [35:10<27:01,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 871/1540 [35:12<26:59,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 872/1540 [35:15<26:56,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 873/1540 [35:17<26:53,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 874/1540 [35:20<26:51,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 875/1540 [35:22<26:49,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 876/1540 [35:24<26:47,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 877/1540 [35:27<26:44,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 878/1540 [35:29<26:41,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 879/1540 [35:32<26:39,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1540 [35:34<26:37,  2.42s/it]                                                  {'loss': 0.5697, 'grad_norm': 0.46023181080818176, 'learning_rate': 0.00027925772961635294, 'epoch': 2.86}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 880/1540 [35:34<26:37,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 881/1540 [35:36<26:35,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 882/1540 [35:39<26:32,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 883/1540 [35:41<26:30,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 884/1540 [35:44<26:27,  2.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 885/1540 [35:46<26:25,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 886/1540 [35:49<26:22,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 887/1540 [35:51<26:20,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 888/1540 [35:53<26:17,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 889/1540 [35:56<26:15,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 890/1540 [35:58<26:28,  2.44s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 891/1540 [36:01<26:21,  2.44s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 892/1540 [36:03<26:15,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 893/1540 [36:06<26:10,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 894/1540 [36:08<26:06,  2.43s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 895/1540 [36:10<26:03,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 896/1540 [36:13<26:00,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 897/1540 [36:15<25:57,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 898/1540 [36:18<25:54,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 899/1540 [36:20<25:51,  2.42s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1540 [36:23<25:48,  2.42s/it]                                                  {'loss': 0.5232, 'grad_norm': 0.36580970883369446, 'learning_rate': 0.000266562820900646, 'epoch': 2.92}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 900/1540 [36:23<25:48,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 901/1540 [36:25<25:46,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 902/1540 [36:27<25:44,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 903/1540 [36:30<25:41,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 904/1540 [36:32<25:39,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 905/1540 [36:35<25:36,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 906/1540 [36:37<25:34,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 907/1540 [36:39<25:31,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 908/1540 [36:42<25:29,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 909/1540 [36:44<25:26,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 910/1540 [36:47<25:24,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 911/1540 [36:49<25:21,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 912/1540 [36:52<25:19,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 913/1540 [36:54<25:17,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 914/1540 [36:56<25:15,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 915/1540 [36:59<25:12,  2.42s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 916/1540 [37:01<25:10,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 917/1540 [37:04<25:10,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 918/1540 [37:06<25:06,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 919/1540 [37:08<25:03,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1540 [37:11<25:00,  2.42s/it]                                                  {'loss': 0.5268, 'grad_norm': 0.43213218450546265, 'learning_rate': 0.00025382484182592563, 'epoch': 2.99}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 920/1540 [37:11<25:00,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 921/1540 [37:13<24:58,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 922/1540 [37:16<24:56,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 923/1540 [37:18<24:53,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 924/1540 [37:21<24:50,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 925/1540 [37:23<24:48,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 926/1540 [37:25<24:45,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 927/1540 [37:28<24:43,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 928/1540 [37:30<24:41,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 929/1540 [37:33<24:38,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 930/1540 [37:35<24:35,  2.42s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 931/1540 [37:38<24:33,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 932/1540 [37:40<24:31,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 933/1540 [37:42<24:29,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 934/1540 [37:45<24:26,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 935/1540 [37:47<24:23,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 936/1540 [37:50<24:21,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 937/1540 [37:52<24:19,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 938/1540 [37:54<24:16,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 939/1540 [37:57<24:14,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1540 [37:59<24:12,  2.42s/it]                                                  {'loss': 0.4629, 'grad_norm': 0.40692535042762756, 'learning_rate': 0.0002410769165402549, 'epoch': 3.05}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 940/1540 [37:59<24:12,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 941/1540 [38:02<24:10,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 942/1540 [38:04<24:07,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 943/1540 [38:07<24:04,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 944/1540 [38:09<24:02,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 945/1540 [38:11<23:59,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 946/1540 [38:14<23:57,  2.42s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 947/1540 [38:16<23:54,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 948/1540 [38:19<23:52,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 949/1540 [38:21<23:50,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 950/1540 [38:24<23:47,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 951/1540 [38:26<23:49,  2.43s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 952/1540 [38:28<23:46,  2.43s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 953/1540 [38:31<23:42,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 954/1540 [38:33<23:39,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 955/1540 [38:36<23:36,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 956/1540 [38:38<23:33,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 957/1540 [38:40<23:31,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 958/1540 [38:43<23:28,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 959/1540 [38:45<23:26,  2.42s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 960/1540 [38:48<23:34,  2.44s/it]                                                  {'loss': 0.4661, 'grad_norm': 0.4512575566768646, 'learning_rate': 0.00022835219505606353, 'epoch': 3.12}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 960/1540 [38:48<23:34,  2.44s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 961/1540 [38:50<23:29,  2.43s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 962/1540 [38:53<23:24,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 963/1540 [38:55<23:19,  2.43s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 964/1540 [38:57<23:16,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 965/1540 [39:00<23:13,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 966/1540 [39:02<23:10,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 967/1540 [39:05<23:07,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 968/1540 [39:07<23:04,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 969/1540 [39:10<23:02,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 970/1540 [39:12<22:59,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 971/1540 [39:14<22:57,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 972/1540 [39:17<22:54,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 973/1540 [39:19<22:52,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 974/1540 [39:22<22:49,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 975/1540 [39:24<22:47,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 976/1540 [39:27<22:44,  2.42s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 977/1540 [39:29<22:42,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 978/1540 [39:31<22:40,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 979/1540 [39:34<22:38,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 980/1540 [39:36<22:35,  2.42s/it]                                                  {'loss': 0.4767, 'grad_norm': 0.4526023268699646, 'learning_rate': 0.00021568376704605635, 'epoch': 3.18}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 980/1540 [39:36<22:35,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 981/1540 [39:39<22:33,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 982/1540 [39:41<22:30,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 983/1540 [39:43<22:27,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 984/1540 [39:46<22:25,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 985/1540 [39:48<22:23,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 986/1540 [39:51<22:23,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 987/1540 [39:53<22:19,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 988/1540 [39:56<22:16,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 989/1540 [39:58<22:13,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 990/1540 [40:00<22:11,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 991/1540 [40:03<22:08,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 992/1540 [40:05<22:06,  2.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 993/1540 [40:08<22:03,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 994/1540 [40:10<22:01,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 995/1540 [40:13<21:58,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 996/1540 [40:15<21:56,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 997/1540 [40:17<21:53,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 998/1540 [40:20<21:51,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 999/1540 [40:22<21:48,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1000/1540 [40:25<21:46,  2.42s/it]                                                   {'loss': 0.4616, 'grad_norm': 0.4819333255290985, 'learning_rate': 0.0002031045757960297, 'epoch': 3.25}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1000/1540 [40:25<21:46,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1001/1540 [40:27<21:44,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1002/1540 [40:29<21:42,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1003/1540 [40:32<21:39,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1004/1540 [40:34<21:37,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1005/1540 [40:37<21:34,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1006/1540 [40:39<21:32,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1007/1540 [40:42<21:29,  2.42s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1008/1540 [40:44<21:27,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1009/1540 [40:46<21:24,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1010/1540 [40:49<21:22,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1011/1540 [40:51<21:20,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1012/1540 [40:54<21:17,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1013/1540 [40:56<21:14,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1014/1540 [40:58<21:12,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1015/1540 [41:01<21:10,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1016/1540 [41:03<21:07,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1017/1540 [41:06<21:05,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1018/1540 [41:08<21:03,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1019/1540 [41:11<21:01,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1020/1540 [41:13<20:58,  2.42s/it]                                                   {'loss': 0.4691, 'grad_norm': 0.4204781949520111, 'learning_rate': 0.0001906473325383568, 'epoch': 3.31}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1020/1540 [41:13<20:58,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1021/1540 [41:15<20:56,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1022/1540 [41:18<20:53,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1023/1540 [41:20<20:51,  2.42s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1024/1540 [41:23<20:48,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1025/1540 [41:25<20:46,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1026/1540 [41:28<20:43,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1027/1540 [41:30<20:41,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1028/1540 [41:32<20:39,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1029/1540 [41:35<20:46,  2.44s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1030/1540 [41:37<20:40,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1031/1540 [41:40<20:36,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1032/1540 [41:42<20:32,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1033/1540 [41:45<20:29,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1034/1540 [41:47<20:26,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1035/1540 [41:49<20:23,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1036/1540 [41:52<20:20,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1037/1540 [41:54<20:17,  2.42s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1038/1540 [41:57<20:17,  2.43s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1039/1540 [41:59<20:14,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1540 [42:01<20:11,  2.42s/it]                                                   {'loss': 0.4918, 'grad_norm': 0.448316752910614, 'learning_rate': 0.00017834443138890977, 'epoch': 3.38}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1040/1540 [42:01<20:11,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1041/1540 [42:04<20:08,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1042/1540 [42:06<20:06,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1043/1540 [42:09<20:05,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1044/1540 [42:11<20:01,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1045/1540 [42:14<19:59,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1046/1540 [42:16<19:56,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1047/1540 [42:18<19:53,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1048/1540 [42:21<19:50,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1049/1540 [42:23<19:48,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1050/1540 [42:26<19:45,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1051/1540 [42:28<19:43,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1052/1540 [42:31<19:41,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1053/1540 [42:33<19:38,  2.42s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1054/1540 [42:35<19:36,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1055/1540 [42:38<19:33,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1056/1540 [42:40<19:33,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1057/1540 [42:43<19:30,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1058/1540 [42:45<19:27,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1059/1540 [42:48<19:24,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1540 [42:50<19:21,  2.42s/it]                                                   {'loss': 0.461, 'grad_norm': 0.5095953941345215, 'learning_rate': 0.00016622786510861942, 'epoch': 3.44}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1060/1540 [42:50<19:21,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1061/1540 [42:52<19:19,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1062/1540 [42:55<19:16,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1063/1540 [42:57<19:14,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1064/1540 [43:00<19:12,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1065/1540 [43:02<19:09,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1066/1540 [43:04<19:06,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1067/1540 [43:07<19:04,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1068/1540 [43:09<19:02,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1069/1540 [43:12<18:59,  2.42s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1070/1540 [43:14<18:57,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1071/1540 [43:17<18:54,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1072/1540 [43:19<18:52,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1073/1540 [43:21<18:49,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1074/1540 [43:24<18:47,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1075/1540 [43:26<18:45,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1076/1540 [43:29<18:42,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1077/1540 [43:31<18:40,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1078/1540 [43:33<18:37,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1079/1540 [43:36<18:35,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1540 [43:38<18:32,  2.42s/it]                                                   {'loss': 0.4617, 'grad_norm': 0.44007888436317444, 'learning_rate': 0.00015432914190872756, 'epoch': 3.51}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1080/1540 [43:38<18:32,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1081/1540 [43:41<18:30,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1082/1540 [43:43<18:28,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1083/1540 [43:46<18:25,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1084/1540 [43:48<18:23,  2.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1085/1540 [43:50<18:21,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1086/1540 [43:53<18:18,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1087/1540 [43:55<18:16,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1088/1540 [43:58<18:13,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1089/1540 [44:00<18:11,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1090/1540 [44:03<18:08,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1091/1540 [44:05<18:06,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1092/1540 [44:07<18:03,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1093/1540 [44:10<18:01,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1094/1540 [44:12<17:59,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1095/1540 [44:15<17:56,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1096/1540 [44:17<17:54,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1097/1540 [44:19<17:51,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1098/1540 [44:22<17:49,  2.42s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1099/1540 [44:24<17:55,  2.44s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1540 [44:27<17:50,  2.43s/it]                                                   {'loss': 0.4292, 'grad_norm': 0.45520439743995667, 'learning_rate': 0.00014267920351607508, 'epoch': 3.57}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1100/1540 [44:27<17:50,  2.43s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1101/1540 [44:29<17:46,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1102/1540 [44:32<17:42,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1103/1540 [44:34<17:39,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1104/1540 [44:36<17:36,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1105/1540 [44:39<17:33,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1106/1540 [44:41<17:30,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1107/1540 [44:44<17:28,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1108/1540 [44:46<17:25,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1109/1540 [44:49<17:23,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1110/1540 [44:51<17:22,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1111/1540 [44:53<17:19,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1112/1540 [44:56<17:18,  2.43s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1113/1540 [44:58<17:15,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1114/1540 [45:01<17:12,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1115/1540 [45:03<17:09,  2.42s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1116/1540 [45:06<17:06,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1117/1540 [45:08<17:03,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1118/1540 [45:10<17:01,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1119/1540 [45:13<16:58,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1540 [45:15<16:56,  2.42s/it]                                                   {'loss': 0.4357, 'grad_norm': 0.44856923818588257, 'learning_rate': 0.0001313083447114886, 'epoch': 3.64}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1120/1540 [45:15<16:56,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1121/1540 [45:18<16:54,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1122/1540 [45:20<16:51,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1123/1540 [45:22<16:49,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1124/1540 [45:25<16:46,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1125/1540 [45:27<16:47,  2.43s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1126/1540 [45:30<16:43,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1127/1540 [45:32<16:40,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1128/1540 [45:35<16:37,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1129/1540 [45:37<16:35,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1130/1540 [45:39<16:32,  2.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1131/1540 [45:42<16:30,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1132/1540 [45:44<16:27,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1133/1540 [45:47<16:24,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1134/1540 [45:49<16:22,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1135/1540 [45:52<16:19,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1136/1540 [45:54<16:17,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1137/1540 [45:56<16:15,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1138/1540 [45:59<16:12,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1139/1540 [46:01<16:10,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1540 [46:04<16:08,  2.42s/it]                                                   {'loss': 0.4405, 'grad_norm': 0.46541497111320496, 'learning_rate': 0.00012024613455050157, 'epoch': 3.7}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1140/1540 [46:04<16:08,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1141/1540 [46:06<16:06,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1142/1540 [46:08<16:03,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1143/1540 [46:11<16:00,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1144/1540 [46:13<15:58,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1145/1540 [46:16<15:55,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1146/1540 [46:18<15:53,  2.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1147/1540 [46:21<15:50,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1148/1540 [46:23<15:48,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1149/1540 [46:25<15:45,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1150/1540 [46:28<15:43,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1151/1540 [46:30<15:41,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1152/1540 [46:33<15:38,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1153/1540 [46:35<15:36,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1154/1540 [46:37<15:34,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1155/1540 [46:40<15:31,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1156/1540 [46:42<15:29,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1157/1540 [46:45<15:26,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1158/1540 [46:47<15:24,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1159/1540 [46:50<15:22,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1540 [46:52<15:19,  2.42s/it]                                                   {'loss': 0.4785, 'grad_norm': 0.4408126473426819, 'learning_rate': 0.00010952133947126928, 'epoch': 3.77}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1160/1540 [46:52<15:19,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1161/1540 [46:54<15:17,  2.42s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1162/1540 [46:57<15:14,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1163/1540 [46:59<15:12,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1164/1540 [47:02<15:09,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1165/1540 [47:04<15:07,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1166/1540 [47:07<15:04,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1167/1540 [47:09<15:02,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1168/1540 [47:11<15:07,  2.44s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1169/1540 [47:14<15:02,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1170/1540 [47:16<14:58,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1171/1540 [47:19<14:55,  2.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1172/1540 [47:21<14:52,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1173/1540 [47:24<14:49,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1174/1540 [47:26<14:46,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1175/1540 [47:28<14:43,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1176/1540 [47:31<14:41,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1177/1540 [47:33<14:38,  2.42s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1178/1540 [47:36<14:36,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1179/1540 [47:38<14:33,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1540 [47:40<14:31,  2.42s/it]                                                   {'loss': 0.4499, 'grad_norm': 0.3866991698741913, 'learning_rate': 9.916184848962892e-05, 'epoch': 3.83}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1180/1540 [47:40<14:31,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1181/1540 [47:43<14:28,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1182/1540 [47:45<14:26,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1183/1540 [47:48<14:24,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1184/1540 [47:50<14:21,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1185/1540 [47:53<14:19,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1186/1540 [47:55<14:16,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1187/1540 [47:57<14:14,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1188/1540 [48:00<14:11,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1189/1540 [48:02<14:09,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1190/1540 [48:05<14:07,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1191/1540 [48:07<14:04,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1192/1540 [48:10<14:02,  2.42s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1193/1540 [48:12<13:59,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1194/1540 [48:14<13:57,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1195/1540 [48:17<13:57,  2.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1196/1540 [48:19<13:54,  2.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1197/1540 [48:22<13:51,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1198/1540 [48:24<13:48,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1199/1540 [48:26<13:45,  2.42s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1540 [48:29<13:43,  2.42s/it]                                                   {'loss': 0.4196, 'grad_norm': 0.43729981780052185, 'learning_rate': 8.919460067583032e-05, 'epoch': 3.9}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1200/1540 [48:29<13:43,  2.42s/it][INFO|trainer.py:3203] 2024-05-25 08:10:42,751 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-1200
[INFO|configuration_utils.py:726] 2024-05-25 08:10:43,823 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 08:10:43,825 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 08:10:44,353 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 08:10:44,355 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 08:10:44,398 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 08:10:44,398 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/checkpoint-1200/special_tokens_map.json
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1201/1540 [48:33<16:40,  2.95s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1202/1540 [48:36<15:43,  2.79s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1203/1540 [48:38<15:02,  2.68s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1204/1540 [48:40<14:33,  2.60s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1205/1540 [48:43<14:12,  2.54s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1206/1540 [48:45<13:56,  2.51s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1207/1540 [48:48<13:45,  2.48s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1208/1540 [48:50<13:36,  2.46s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1209/1540 [48:52<13:29,  2.45s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1210/1540 [48:55<13:25,  2.44s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1211/1540 [48:57<13:20,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1212/1540 [49:00<13:17,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1213/1540 [49:02<13:13,  2.43s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1214/1540 [49:05<13:10,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1215/1540 [49:07<13:06,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1216/1540 [49:09<13:04,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1217/1540 [49:12<13:01,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1218/1540 [49:14<12:58,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1219/1540 [49:17<12:56,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1540 [49:19<12:53,  2.42s/it]                                                   {'loss': 0.433, 'grad_norm': 0.4047577679157257, 'learning_rate': 7.96455151015272e-05, 'epoch': 3.96}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1220/1540 [49:19<12:53,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1221/1540 [49:21<12:51,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1222/1540 [49:24<12:49,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1223/1540 [49:26<12:46,  2.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1224/1540 [49:29<12:44,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1225/1540 [49:31<12:41,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1226/1540 [49:34<12:39,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1227/1540 [49:36<12:36,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1228/1540 [49:38<12:34,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1229/1540 [49:41<12:31,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1230/1540 [49:43<12:29,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1231/1540 [49:46<12:27,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1232/1540 [49:48<12:24,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1233/1540 [49:50<12:22,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1234/1540 [49:53<12:20,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1235/1540 [49:55<12:17,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1236/1540 [49:58<12:15,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1237/1540 [50:00<12:13,  2.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1238/1540 [50:03<12:15,  2.44s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1239/1540 [50:05<12:11,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1540 [50:07<12:08,  2.43s/it]                                                   {'loss': 0.4138, 'grad_norm': 0.36105766892433167, 'learning_rate': 7.053942343919881e-05, 'epoch': 4.03}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1240/1540 [50:07<12:08,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1241/1540 [50:10<12:05,  2.43s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1242/1540 [50:12<12:02,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1243/1540 [50:15<11:59,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1244/1540 [50:17<11:56,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1245/1540 [50:20<11:54,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1246/1540 [50:22<11:51,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1247/1540 [50:24<11:49,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1248/1540 [50:27<11:46,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1249/1540 [50:29<11:44,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1250/1540 [50:32<11:41,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1251/1540 [50:34<11:39,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1252/1540 [50:36<11:37,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1253/1540 [50:39<11:34,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1254/1540 [50:41<11:32,  2.42s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1255/1540 [50:44<11:29,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1256/1540 [50:46<11:27,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1257/1540 [50:49<11:24,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1258/1540 [50:51<11:22,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1259/1540 [50:53<11:20,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1540 [50:56<11:17,  2.42s/it]                                                   {'loss': 0.4246, 'grad_norm': 0.39792585372924805, 'learning_rate': 6.190000538926915e-05, 'epoch': 4.09}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1260/1540 [50:56<11:17,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1261/1540 [50:58<11:15,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1262/1540 [51:01<11:12,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1263/1540 [51:03<11:10,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1264/1540 [51:06<11:09,  2.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1265/1540 [51:08<11:06,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1266/1540 [51:10<11:03,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1267/1540 [51:13<11:01,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1268/1540 [51:15<10:58,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1269/1540 [51:18<10:56,  2.42s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1270/1540 [51:20<10:53,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1271/1540 [51:22<10:51,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1272/1540 [51:25<10:48,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1273/1540 [51:27<10:46,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1274/1540 [51:30<10:43,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1275/1540 [51:32<10:41,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1276/1540 [51:35<10:38,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1277/1540 [51:37<10:36,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1278/1540 [51:39<10:34,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1279/1540 [51:42<10:31,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1540 [51:44<10:29,  2.42s/it]                                                   {'loss': 0.4351, 'grad_norm': 0.37512290477752686, 'learning_rate': 5.3749727102843066e-05, 'epoch': 4.16}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1280/1540 [51:44<10:29,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1281/1540 [51:47<10:27,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1282/1540 [51:49<10:24,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1283/1540 [51:52<10:22,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1284/1540 [51:54<10:19,  2.42s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1285/1540 [51:56<10:17,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1286/1540 [51:59<10:14,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1287/1540 [52:01<10:12,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1288/1540 [52:04<10:09,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1289/1540 [52:06<10:07,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1290/1540 [52:08<10:04,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1291/1540 [52:11<10:02,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1292/1540 [52:13<10:00,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1293/1540 [52:16<09:57,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1294/1540 [52:18<09:55,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1295/1540 [52:21<09:52,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1296/1540 [52:23<09:50,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1297/1540 [52:25<09:47,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1298/1540 [52:28<09:45,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1299/1540 [52:30<09:44,  2.43s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1540 [52:33<09:41,  2.42s/it]                                                   {'loss': 0.3929, 'grad_norm': 0.3961869180202484, 'learning_rate': 4.610978276018496e-05, 'epoch': 4.22}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1300/1540 [52:33<09:41,  2.42s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1301/1540 [52:35<09:39,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1302/1540 [52:38<09:36,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1303/1540 [52:40<09:33,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1304/1540 [52:42<09:31,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1305/1540 [52:45<09:28,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1306/1540 [52:47<09:26,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1307/1540 [52:50<09:29,  2.44s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1308/1540 [52:52<09:25,  2.44s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1309/1540 [52:55<09:21,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1310/1540 [52:57<09:18,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1311/1540 [52:59<09:15,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1312/1540 [53:02<09:12,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1313/1540 [53:04<09:10,  2.43s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1314/1540 [53:07<09:07,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1315/1540 [53:09<09:05,  2.42s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1316/1540 [53:12<09:02,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1317/1540 [53:14<08:59,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1318/1540 [53:16<08:57,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1319/1540 [53:19<08:54,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1540 [53:21<08:52,  2.42s/it]                                                   {'loss': 0.4156, 'grad_norm': 0.3343645930290222, 'learning_rate': 3.900003945686123e-05, 'epoch': 4.29}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1320/1540 [53:21<08:52,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1321/1540 [53:24<08:50,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1322/1540 [53:26<08:47,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1323/1540 [53:28<08:45,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1324/1540 [53:31<08:42,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1325/1540 [53:33<08:40,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1326/1540 [53:36<08:37,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1327/1540 [53:38<08:35,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1328/1540 [53:41<08:33,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1329/1540 [53:43<08:30,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1330/1540 [53:45<08:28,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1331/1540 [53:48<08:25,  2.42s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1332/1540 [53:50<08:23,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1333/1540 [53:53<08:20,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1334/1540 [53:55<08:18,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1335/1540 [53:57<08:15,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1336/1540 [54:00<08:13,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1337/1540 [54:02<08:11,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1338/1540 [54:05<08:08,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1339/1540 [54:07<08:06,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1540 [54:10<08:03,  2.42s/it]                                                   {'loss': 0.3981, 'grad_norm': 0.35415753722190857, 'learning_rate': 3.243898554086536e-05, 'epoch': 4.35}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1340/1540 [54:10<08:03,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1341/1540 [54:12<08:01,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1342/1540 [54:14<07:59,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1343/1540 [54:17<07:56,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1344/1540 [54:19<07:54,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1345/1540 [54:22<07:51,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1346/1540 [54:24<07:49,  2.42s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1347/1540 [54:27<07:46,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1348/1540 [54:29<07:44,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1349/1540 [54:31<07:43,  2.43s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1350/1540 [54:34<07:40,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1351/1540 [54:36<07:37,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1352/1540 [54:39<07:35,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1353/1540 [54:41<07:32,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1354/1540 [54:43<07:30,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1355/1540 [54:46<07:27,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1356/1540 [54:48<07:25,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1357/1540 [54:51<07:22,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1358/1540 [54:53<07:20,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1359/1540 [54:56<07:18,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1540 [54:58<07:15,  2.42s/it]                                                   {'loss': 0.4064, 'grad_norm': 0.34814226627349854, 'learning_rate': 2.6443682535072176e-05, 'epoch': 4.42}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1360/1540 [54:58<07:15,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1361/1540 [55:00<07:13,  2.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1362/1540 [55:03<07:10,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1363/1540 [55:05<07:08,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1364/1540 [55:08<07:05,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1365/1540 [55:10<07:03,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1366/1540 [55:13<07:00,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1367/1540 [55:15<06:58,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1368/1540 [55:17<06:56,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1369/1540 [55:20<06:53,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1370/1540 [55:22<06:51,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1371/1540 [55:25<06:48,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1372/1540 [55:27<06:46,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1373/1540 [55:29<06:44,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1374/1540 [55:32<06:41,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1375/1540 [55:34<06:39,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1376/1540 [55:37<06:36,  2.42s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1377/1540 [55:39<06:37,  2.44s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1378/1540 [55:42<06:34,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1379/1540 [55:44<06:31,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1540 [55:46<06:28,  2.43s/it]                                                   {'loss': 0.3708, 'grad_norm': 0.44205042719841003, 'learning_rate': 2.1029720770042116e-05, 'epoch': 4.48}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1380/1540 [55:46<06:28,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1381/1540 [55:49<06:25,  2.43s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1382/1540 [55:51<06:22,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1383/1540 [55:54<06:20,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1384/1540 [55:56<06:17,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1385/1540 [55:59<06:15,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1386/1540 [56:01<06:12,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1387/1540 [56:03<06:10,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1388/1540 [56:06<06:07,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1389/1540 [56:08<06:05,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1390/1540 [56:11<06:03,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1391/1540 [56:13<06:00,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1392/1540 [56:15<05:58,  2.42s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1393/1540 [56:18<05:55,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1394/1540 [56:20<05:53,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1395/1540 [56:23<05:50,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1396/1540 [56:25<05:48,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1397/1540 [56:28<05:46,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1398/1540 [56:30<05:43,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1399/1540 [56:32<05:41,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1540 [56:35<05:38,  2.42s/it]                                                   {'loss': 0.3954, 'grad_norm': 0.34614846110343933, 'learning_rate': 1.6211178842549468e-05, 'epoch': 4.55}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1400/1540 [56:35<05:38,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1401/1540 [56:37<05:36,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1402/1540 [56:40<05:34,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1403/1540 [56:42<05:31,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1404/1540 [56:45<05:29,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1405/1540 [56:47<05:26,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1406/1540 [56:49<05:24,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1407/1540 [56:52<05:21,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1408/1540 [56:54<05:19,  2.42s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1409/1540 [56:57<05:17,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1410/1540 [56:59<05:14,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1411/1540 [57:01<05:12,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1412/1540 [57:04<05:09,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1413/1540 [57:06<05:07,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1414/1540 [57:09<05:04,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1415/1540 [57:11<05:02,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1416/1540 [57:14<05:00,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1417/1540 [57:16<04:57,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1418/1540 [57:18<04:55,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1419/1540 [57:21<04:53,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1420/1540 [57:23<04:51,  2.43s/it]                                                   {'loss': 0.4167, 'grad_norm': 0.35199904441833496, 'learning_rate': 1.2000587005259606e-05, 'epoch': 4.61}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1420/1540 [57:23<04:51,  2.43s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1421/1540 [57:26<04:48,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1422/1540 [57:28<04:46,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1423/1540 [57:31<04:43,  2.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1424/1540 [57:33<04:40,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1425/1540 [57:35<04:38,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1426/1540 [57:38<04:36,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1427/1540 [57:40<04:33,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1428/1540 [57:43<04:31,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1429/1540 [57:45<04:28,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1430/1540 [57:47<04:26,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1431/1540 [57:50<04:23,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1432/1540 [57:52<04:21,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1433/1540 [57:55<04:18,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1434/1540 [57:57<04:16,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1435/1540 [58:00<04:14,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1436/1540 [58:02<04:11,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1437/1540 [58:04<04:09,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1438/1540 [58:07<04:06,  2.42s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1439/1540 [58:09<04:04,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1440/1540 [58:12<04:01,  2.42s/it]                                                   {'loss': 0.4217, 'grad_norm': 0.3452942371368408, 'learning_rate': 8.408894582757953e-06, 'epoch': 4.68}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1440/1540 [58:12<04:01,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1441/1540 [58:14<03:59,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1442/1540 [58:17<03:57,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1443/1540 [58:19<03:54,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1444/1540 [58:21<03:52,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1445/1540 [58:24<03:49,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1446/1540 [58:26<03:49,  2.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1447/1540 [58:29<03:46,  2.44s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1448/1540 [58:31<03:43,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1449/1540 [58:34<03:40,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1450/1540 [58:36<03:38,  2.43s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1451/1540 [58:38<03:35,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1452/1540 [58:41<03:33,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1453/1540 [58:43<03:30,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1454/1540 [58:46<03:28,  2.42s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1455/1540 [58:48<03:25,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1456/1540 [58:50<03:23,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1457/1540 [58:53<03:20,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1458/1540 [58:55<03:18,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1459/1540 [58:58<03:15,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1460/1540 [59:00<03:13,  2.42s/it]                                                   {'loss': 0.4109, 'grad_norm': 0.38909912109375, 'learning_rate': 5.445441498662052e-06, 'epoch': 4.74}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1460/1540 [59:00<03:13,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1461/1540 [59:03<03:11,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1462/1540 [59:05<03:08,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1463/1540 [59:07<03:06,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1464/1540 [59:10<03:04,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1465/1540 [59:12<03:01,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1466/1540 [59:15<02:59,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1467/1540 [59:17<02:56,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1468/1540 [59:20<02:54,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1469/1540 [59:22<02:51,  2.42s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1470/1540 [59:24<02:49,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1471/1540 [59:27<02:46,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1472/1540 [59:29<02:44,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1473/1540 [59:32<02:42,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1474/1540 [59:34<02:39,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1475/1540 [59:36<02:37,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1476/1540 [59:39<02:34,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1477/1540 [59:41<02:32,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1478/1540 [59:44<02:30,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1479/1540 [59:46<02:27,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1480/1540 [59:49<02:25,  2.42s/it]                                                   {'loss': 0.4202, 'grad_norm': 0.3741728365421295, 'learning_rate': 3.1179339878588397e-06, 'epoch': 4.81}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1480/1540 [59:49<02:25,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1481/1540 [59:51<02:22,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1482/1540 [59:53<02:20,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1483/1540 [59:56<02:17,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1484/1540 [59:58<02:15,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1485/1540 [1:00:01<02:13,  2.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1486/1540 [1:00:03<02:10,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1487/1540 [1:00:06<02:08,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1488/1540 [1:00:08<02:05,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1489/1540 [1:00:10<02:03,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1490/1540 [1:00:13<02:00,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1491/1540 [1:00:15<01:58,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1492/1540 [1:00:18<01:56,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1493/1540 [1:00:20<01:53,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1494/1540 [1:00:22<01:51,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1495/1540 [1:00:25<01:48,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1496/1540 [1:00:27<01:46,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1497/1540 [1:00:30<01:44,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1498/1540 [1:00:32<01:41,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1499/1540 [1:00:35<01:39,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1500/1540 [1:00:37<01:36,  2.42s/it]                                                     {'loss': 0.3878, 'grad_norm': 0.41138914227485657, 'learning_rate': 1.4324245570256633e-06, 'epoch': 4.87}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1500/1540 [1:00:37<01:36,  2.42s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1501/1540 [1:00:39<01:34,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1502/1540 [1:00:42<01:31,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1503/1540 [1:00:44<01:29,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1504/1540 [1:00:47<01:27,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1505/1540 [1:00:49<01:24,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1506/1540 [1:00:52<01:22,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1507/1540 [1:00:54<01:19,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1508/1540 [1:00:56<01:17,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1509/1540 [1:00:59<01:14,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1510/1540 [1:01:01<01:12,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1511/1540 [1:01:04<01:10,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1512/1540 [1:01:06<01:07,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1513/1540 [1:01:08<01:05,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1514/1540 [1:01:11<01:02,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1515/1540 [1:01:13<01:00,  2.42s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1516/1540 [1:01:16<00:58,  2.44s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1517/1540 [1:01:18<00:55,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1518/1540 [1:01:21<00:53,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1519/1540 [1:01:23<00:50,  2.43s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1520/1540 [1:01:25<00:48,  2.42s/it]                                                     {'loss': 0.4096, 'grad_norm': 0.37005406618118286, 'learning_rate': 3.932962455458489e-07, 'epoch': 4.94}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1520/1540 [1:01:25<00:48,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1521/1540 [1:01:28<00:46,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1522/1540 [1:01:30<00:43,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1523/1540 [1:01:33<00:41,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1524/1540 [1:01:35<00:38,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1525/1540 [1:01:38<00:36,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1526/1540 [1:01:40<00:33,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1527/1540 [1:01:42<00:31,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1528/1540 [1:01:45<00:29,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1529/1540 [1:01:47<00:26,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1530/1540 [1:01:50<00:24,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1531/1540 [1:01:52<00:21,  2.42s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1532/1540 [1:01:54<00:19,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1533/1540 [1:01:57<00:16,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1534/1540 [1:01:59<00:14,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1535/1540 [1:02:02<00:12,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1536/1540 [1:02:04<00:09,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1537/1540 [1:02:07<00:07,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1538/1540 [1:02:09<00:04,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1539/1540 [1:02:11<00:02,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it]                                                     {'loss': 0.3907, 'grad_norm': 0.3646155297756195, 'learning_rate': 3.2512277473584205e-09, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it][INFO|trainer.py:2231] 2024-05-25 08:24:27,683 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 3756.4729, 'train_samples_per_second': 3.277, 'train_steps_per_second': 0.41, 'train_loss': 0.6085033330050382, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1540/1540 [1:02:14<00:00,  2.42s/it]
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     0.6085
  train_runtime            = 1:02:36.47
  train_samples_per_second =      3.277
  train_steps_per_second   =       0.41
[INFO|trainer.py:3203] 2024-05-25 08:24:27,689 >> Saving model checkpoint to /scratch/tathagato/adapter_experiments/topic_then_extractiveness
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:726] 2024-05-25 08:24:29,157 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 08:24:29,160 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|configuration_utils.py:726] 2024-05-25 08:24:30,042 >> loading configuration file config.json from cache at /home2/tathagato/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json
[INFO|configuration_utils.py:789] 2024-05-25 08:24:30,044 >> Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-05-25 08:24:30,098 >> tokenizer config file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-05-25 08:24:30,099 >> Special tokens file saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/special_tokens_map.json
/home2/tathagato/miniconda3/envs/roy/lib/python3.9/site-packages/peft/tuners/lora/bnb.py:325: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[INFO|configuration_utils.py:471] 2024-05-25 08:24:31,054 >> Configuration saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/final_merged_model/config.json
[INFO|configuration_utils.py:697] 2024-05-25 08:24:31,054 >> Configuration saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/final_merged_model/generation_config.json
[INFO|modeling_utils.py:2474] 2024-05-25 08:24:36,644 >> Model weights saved in /scratch/tathagato/adapter_experiments/topic_then_extractiveness/final_merged_model/model.safetensors
wandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.034 MB uploadedwandb: - 0.038 MB of 0.038 MB uploadedwandb: \ 0.038 MB of 0.038 MB uploadedwandb: 
wandb: Run history:
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÑ
wandb: train/learning_rate ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:               total_flos 1.5729502080466944e+17
wandb:              train/epoch 5.0
wandb:        train/global_step 1540
wandb:          train/grad_norm 0.36462
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.3907
wandb:               train_loss 0.6085
wandb:            train_runtime 3756.4729
wandb: train_samples_per_second 3.277
wandb:   train_steps_per_second 0.41
wandb: 
wandb: üöÄ View run sunny-microwave-103 at: https://wandb.ai/ihub-drug-discovery/huggingface/runs/d65347to
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ihub-drug-discovery/huggingface
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240525_072157-d65347to/logs
Completed
